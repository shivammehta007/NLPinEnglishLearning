{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generation of Blanks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "18wNtFnmO3y2d3nSyqb0nTr02PtpTUBS3",
      "authorship_tag": "ABX9TyOB34UcwH1zgBjXpQ/XP2XL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivammehta007/QuestionGenerator/blob/master/Generation_of_Blanks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU4dAfBwhK3b",
        "colab_type": "text"
      },
      "source": [
        "# Fill in the blank Generator With Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZpdPjQ5jSn_",
        "colab_type": "text"
      },
      "source": [
        "## Download Code from Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUDrIopZhIaO",
        "colab_type": "code",
        "outputId": "584c06a0-bc6e-421c-8307-7dd9dc534286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!rm -rf QuestionGenerator\n",
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "import subprocess\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "# repo_name = input('Repo name: ')\n",
        "\n",
        "cmd_string = 'git clone --single-branch --branch master  https://{0}:{1}@github.com/{0}/{2}.git'.format(user, password, 'QuestionGenerator')\n",
        "stdout = subprocess.Popen(cmd_string, shell=True, stdout=subprocess.PIPE)\n",
        "print(stdout.communicate()[0])\n",
        "cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: shivammehta007\n",
            "Password: ··········\n",
            "b''\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7g4AhObih2-",
        "colab_type": "code",
        "outputId": "5a70d4ca-5904-4284-a8e8-c692ccd1b0c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!rm -rf QuestionGenerator/FromScratch\n",
        "!rm -rf QuestionGenerator/classifier\n",
        "%cd QuestionGenerator/FITBGenerator/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/QuestionGenerator/FITBGenerator\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcDcDeTylq76",
        "colab_type": "code",
        "outputId": "6937f7dd-31b6-4d96-f5a8-2a51ef34b369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mconfig\u001b[0m/  datasetloader.py    lossfunction.py  preprocessdata.py  utility.py\n",
            "\u001b[01;34mdata\u001b[0m/    helperfunctions.py  \u001b[01;34mmodel\u001b[0m/           train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvlCMl-LJI1H",
        "colab_type": "text"
      },
      "source": [
        "## Download Glove from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzMieNSOJIFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "kaggle_info = json.load(open(\"/content/drive/My Drive/kaggle.json\"))\n",
        "os.environ['KAGGLE_USERNAME'] = kaggle_info[\"username\"]\n",
        "os.environ['KAGGLE_KEY'] = kaggle_info[\"key\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPfYshuJKWLJ",
        "colab_type": "code",
        "outputId": "f3c04abb-0257-4e61-f96c-dc597b17c274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!kaggle datasets list --user thanakomsn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                        title               size  lastUpdated          downloadCount  \n",
            "-------------------------  -----------------  -----  -------------------  -------------  \n",
            "thanakomsn/glove6b300dtxt  glove.6B.300d.txt  386MB  2017-11-28 07:19:43           2757  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oksPtO8LpYP",
        "colab_type": "code",
        "outputId": "e1224ebd-4147-4e69-fae8-0d1c6f97e722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!kaggle datasets download thanakomsn/glove6b300dtxt "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading glove6b300dtxt.zip to /content/QuestionGenerator/FITBGenerator\n",
            " 99% 384M/386M [00:04<00:00, 96.8MB/s]\n",
            "100% 386M/386M [00:04<00:00, 93.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRjCEyqsL_8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mkdir .vector_cache\n",
        "%mv glove6b300dtxt.zip .vector_cache/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haCNqeqHMUDs",
        "colab_type": "code",
        "outputId": "ce40b3ef-6673-40b6-b6e0-1818ed098708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!unzip .vector_cache/glove6b300dtxt.zip\n",
        "%ls -a .vector_cache/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  .vector_cache/glove6b300dtxt.zip\n",
            "  inflating: glove.6B.300d.txt       \n",
            "\u001b[0m\u001b[01;34m.\u001b[0m/  \u001b[01;34m..\u001b[0m/  glove6b300dtxt.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X3GrnD7jOpx",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSBYYV6qHXFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python preprocessdata.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNJ4_Jw_lp3x",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s6sicYFjuV3",
        "colab_type": "code",
        "outputId": "44b34ef3-19b1-4462-9b54-df92957eee64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py -n 50 --n-layers 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[DEBUG | train.py:221 -             <module>() ] Namespace(batch_size=64, bidirectional=True, dropout=0.7, embedding_dim=300, epochs=50, freeze_embeddings=1, hidden_dim=128, l2_regularization=0.001, learning_rate=0.001, linear_hidden_dim=128, model='RNNHiddenClassifier', model_location=None, n_layers=1, seed=1234)\n",
            "[DEBUG | train.py:222 -             <module>() ] Custom seed set with: 1234\n",
            "[INFO | train.py:224 -             <module>() ] Loading Dataset\n",
            "[DEBUG | datasetloader.py:74 -        get_iterators() ] Data Loaded Successfully!\n",
            "[INFO | vocab.py:386 -                cache() ] Loading vectors from .vector_cache/glove.6B.300d.txt.pt\n",
            "[DEBUG | datasetloader.py:85 -        get_iterators() ] Vocabulary Loaded\n",
            "[DEBUG | datasetloader.py:94 -        get_iterators() ] Created Iterators\n",
            "[INFO | train.py:228 -             <module>() ] Dataset Loaded Successfully\n",
            "[DEBUG | train.py:66 - initialize_new_model() ] Initializing Model\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[DEBUG | train.py:92 - initialize_new_model() ] Freeze Embeddings Value 1: False\n",
            "[INFO | train.py:98 - initialize_new_model() ] Model Initialized with 440,577 trainiable parameters\n",
            "[DEBUG | train.py:110 - initialize_new_model() ] Copied PreTrained Embeddings\n",
            "[INFO | train.py:253 -             <module>() ] RNNHiddenClassifier(\n",
            "  (embedding): Embedding(564, 300, padding_idx=1)\n",
            "  (rnn): LSTMWithPackPaddedSequences(\n",
            "    (rnn): LSTM(300, 128, dropout=0.7, bidirectional=True)\n",
            "  )\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.7, inplace=False)\n",
            ")\n",
            "100% 5/5 [00:00<00:00, 110.71it/s]\n",
            "100% 1/1 [00:00<00:00, 230.18it/s]\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.678 | Train Acc: 58.03%\n",
            "\t Val. Loss: 0.683 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 155.85it/s]\n",
            "100% 1/1 [00:00<00:00, 243.32it/s]\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.640 | Train Acc: 65.10%\n",
            "\t Val. Loss: 0.681 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 157.93it/s]\n",
            "100% 1/1 [00:00<00:00, 236.43it/s]\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.609 | Train Acc: 67.21%\n",
            "\t Val. Loss: 0.676 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 147.85it/s]\n",
            "100% 1/1 [00:00<00:00, 256.03it/s]\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.575 | Train Acc: 71.75%\n",
            "\t Val. Loss: 0.669 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 151.92it/s]\n",
            "100% 1/1 [00:00<00:00, 242.14it/s]\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.546 | Train Acc: 76.29%\n",
            "\t Val. Loss: 0.672 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 157.80it/s]\n",
            "100% 1/1 [00:00<00:00, 252.00it/s]\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.514 | Train Acc: 79.89%\n",
            "\t Val. Loss: 0.648 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 157.08it/s]\n",
            "100% 1/1 [00:00<00:00, 233.89it/s]\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.501 | Train Acc: 79.54%\n",
            "\t Val. Loss: 0.642 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 155.89it/s]\n",
            "100% 1/1 [00:00<00:00, 201.57it/s]\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.474 | Train Acc: 82.27%\n",
            "\t Val. Loss: 0.647 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 161.57it/s]\n",
            "100% 1/1 [00:00<00:00, 258.54it/s]\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.454 | Train Acc: 82.51%\n",
            "\t Val. Loss: 0.647 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 160.13it/s]\n",
            "100% 1/1 [00:00<00:00, 252.61it/s]\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.445 | Train Acc: 82.76%\n",
            "\t Val. Loss: 0.641 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 151.16it/s]\n",
            "100% 1/1 [00:00<00:00, 198.10it/s]\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.431 | Train Acc: 83.33%\n",
            "\t Val. Loss: 0.624 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 154.75it/s]\n",
            "100% 1/1 [00:00<00:00, 254.60it/s]\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.420 | Train Acc: 84.58%\n",
            "\t Val. Loss: 0.624 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 146.98it/s]\n",
            "100% 1/1 [00:00<00:00, 244.35it/s]\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.415 | Train Acc: 84.61%\n",
            "\t Val. Loss: 0.624 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 159.48it/s]\n",
            "100% 1/1 [00:00<00:00, 250.95it/s]\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.404 | Train Acc: 84.33%\n",
            "\t Val. Loss: 0.619 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 124.17it/s]\n",
            "100% 1/1 [00:00<00:00, 211.10it/s]\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.401 | Train Acc: 84.44%\n",
            "\t Val. Loss: 0.618 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 142.03it/s]\n",
            "100% 1/1 [00:00<00:00, 239.31it/s]\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.391 | Train Acc: 85.63%\n",
            "\t Val. Loss: 0.616 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 144.89it/s]\n",
            "100% 1/1 [00:00<00:00, 248.27it/s]\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.383 | Train Acc: 86.23%\n",
            "\t Val. Loss: 0.600 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 158.62it/s]\n",
            "100% 1/1 [00:00<00:00, 251.79it/s]\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.384 | Train Acc: 86.44%\n",
            "\t Val. Loss: 0.608 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 161.34it/s]\n",
            "100% 1/1 [00:00<00:00, 251.73it/s]\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.370 | Train Acc: 87.63%\n",
            "\t Val. Loss: 0.614 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 165.53it/s]\n",
            "100% 1/1 [00:00<00:00, 256.78it/s]\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.368 | Train Acc: 86.89%\n",
            "\t Val. Loss: 0.599 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 159.47it/s]\n",
            "100% 1/1 [00:00<00:00, 248.61it/s]\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.371 | Train Acc: 86.94%\n",
            "\t Val. Loss: 0.616 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 159.02it/s]\n",
            "100% 1/1 [00:00<00:00, 255.28it/s]\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.358 | Train Acc: 87.59%\n",
            "\t Val. Loss: 0.594 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 157.07it/s]\n",
            "100% 1/1 [00:00<00:00, 259.44it/s]\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.354 | Train Acc: 87.94%\n",
            "\t Val. Loss: 0.605 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 148.49it/s]\n",
            "100% 1/1 [00:00<00:00, 236.14it/s]\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.348 | Train Acc: 88.55%\n",
            "\t Val. Loss: 0.610 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 161.64it/s]\n",
            "100% 1/1 [00:00<00:00, 256.13it/s]\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.345 | Train Acc: 88.16%\n",
            "\t Val. Loss: 0.619 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 135.03it/s]\n",
            "100% 1/1 [00:00<00:00, 250.26it/s]\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.347 | Train Acc: 87.96%\n",
            "\t Val. Loss: 0.585 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 160.39it/s]\n",
            "100% 1/1 [00:00<00:00, 249.13it/s]\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.338 | Train Acc: 88.84%\n",
            "\t Val. Loss: 0.612 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 161.19it/s]\n",
            "100% 1/1 [00:00<00:00, 243.40it/s]\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.362 | Train Acc: 86.64%\n",
            "\t Val. Loss: 0.615 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 147.40it/s]\n",
            "100% 1/1 [00:00<00:00, 239.84it/s]\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.345 | Train Acc: 88.48%\n",
            "\t Val. Loss: 0.566 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 155.05it/s]\n",
            "100% 1/1 [00:00<00:00, 246.69it/s]\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.344 | Train Acc: 88.44%\n",
            "\t Val. Loss: 0.592 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 166.71it/s]\n",
            "100% 1/1 [00:00<00:00, 240.82it/s]\n",
            "Epoch: 31 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.328 | Train Acc: 89.07%\n",
            "\t Val. Loss: 0.597 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 159.36it/s]\n",
            "100% 1/1 [00:00<00:00, 239.59it/s]\n",
            "Epoch: 32 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.329 | Train Acc: 88.91%\n",
            "\t Val. Loss: 0.587 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 161.85it/s]\n",
            "100% 1/1 [00:00<00:00, 238.41it/s]\n",
            "Epoch: 33 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.318 | Train Acc: 90.55%\n",
            "\t Val. Loss: 0.584 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 153.83it/s]\n",
            "100% 1/1 [00:00<00:00, 250.53it/s]\n",
            "Epoch: 34 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.327 | Train Acc: 89.11%\n",
            "\t Val. Loss: 0.604 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 160.70it/s]\n",
            "100% 1/1 [00:00<00:00, 234.02it/s]\n",
            "Epoch: 35 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.318 | Train Acc: 88.87%\n",
            "\t Val. Loss: 0.584 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 159.72it/s]\n",
            "100% 1/1 [00:00<00:00, 255.88it/s]\n",
            "Epoch: 36 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.320 | Train Acc: 89.30%\n",
            "\t Val. Loss: 0.611 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 153.60it/s]\n",
            "100% 1/1 [00:00<00:00, 135.39it/s]\n",
            "Epoch: 37 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.314 | Train Acc: 89.30%\n",
            "\t Val. Loss: 0.587 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 147.03it/s]\n",
            "100% 1/1 [00:00<00:00, 234.40it/s]\n",
            "Epoch: 38 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.309 | Train Acc: 89.95%\n",
            "\t Val. Loss: 0.586 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 143.96it/s]\n",
            "100% 1/1 [00:00<00:00, 132.36it/s]\n",
            "Epoch: 39 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.314 | Train Acc: 88.83%\n",
            "\t Val. Loss: 0.594 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 163.20it/s]\n",
            "100% 1/1 [00:00<00:00, 242.66it/s]\n",
            "Epoch: 40 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.303 | Train Acc: 89.99%\n",
            "\t Val. Loss: 0.585 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 157.17it/s]\n",
            "100% 1/1 [00:00<00:00, 254.83it/s]\n",
            "Epoch: 41 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.296 | Train Acc: 89.93%\n",
            "\t Val. Loss: 0.611 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 164.99it/s]\n",
            "100% 1/1 [00:00<00:00, 263.02it/s]\n",
            "Epoch: 42 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.304 | Train Acc: 90.17%\n",
            "\t Val. Loss: 0.586 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 169.07it/s]\n",
            "100% 1/1 [00:00<00:00, 246.46it/s]\n",
            "Epoch: 43 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.298 | Train Acc: 90.41%\n",
            "\t Val. Loss: 0.593 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 163.42it/s]\n",
            "100% 1/1 [00:00<00:00, 252.81it/s]\n",
            "Epoch: 44 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.298 | Train Acc: 89.49%\n",
            "\t Val. Loss: 0.571 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 166.37it/s]\n",
            "100% 1/1 [00:00<00:00, 248.73it/s]\n",
            "Epoch: 45 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.301 | Train Acc: 90.38%\n",
            "\t Val. Loss: 0.594 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 166.53it/s]\n",
            "100% 1/1 [00:00<00:00, 243.35it/s]\n",
            "Epoch: 46 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.295 | Train Acc: 90.48%\n",
            "\t Val. Loss: 0.608 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 165.94it/s]\n",
            "100% 1/1 [00:00<00:00, 259.00it/s]\n",
            "Epoch: 47 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.291 | Train Acc: 90.99%\n",
            "\t Val. Loss: 0.572 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 155.15it/s]\n",
            "100% 1/1 [00:00<00:00, 253.75it/s]\n",
            "Epoch: 48 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.293 | Train Acc: 90.44%\n",
            "\t Val. Loss: 0.612 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 160.41it/s]\n",
            "100% 1/1 [00:00<00:00, 250.38it/s]\n",
            "Epoch: 49 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.308 | Train Acc: 89.04%\n",
            "\t Val. Loss: 0.608 |  Val. Acc: 54.53%\n",
            "100% 5/5 [00:00<00:00, 168.00it/s]\n",
            "100% 1/1 [00:00<00:00, 255.49it/s]\n",
            "Epoch: 50 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.297 | Train Acc: 89.81%\n",
            "\t Val. Loss: 0.549 |  Val. Acc: 54.53%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXHK1gyh2ok9",
        "colab_type": "text"
      },
      "source": [
        "# Seq2Seq To generate Blanks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7EmnZGfKhiO",
        "colab_type": "code",
        "outputId": "8a980b68-112e-4645-ae68-34bcd4fdcc78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/QuestionGenerator/FITBGenerator'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnoJOcu07JrL",
        "colab_type": "code",
        "outputId": "7e3a571f-99a7-4f9f-edfb-815e6d5e632c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%mkdir Seq2Seq\n",
        "%cd Seq2Seq\n",
        "%mkdir data\n",
        "%mkdir data/processed"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/QuestionGenerator/FITBGenerator/Seq2Seq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqx_D6V3X8ZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install fairseq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9BWyC9M3GQR",
        "colab_type": "text"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaTyUwIx7WVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iN9xR7x2vjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train = pd.read_csv(\"../data/processed/train.tsv\", sep='\\t')\n",
        "dataset_test = pd.read_csv(\"../data/processed/test.tsv\", sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcxSXh9BdUL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4GDFmBpdSnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_len(x):\n",
        "    return len([t.text for t in nlp(x)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0Lxihbzc2H3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_len = dataset_train['feature'].apply(get_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1jE0hsMdumj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "key_len = dataset_train[\"key\"].apply(get_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrnEDStDdilP",
        "colab_type": "code",
        "outputId": "64a3d4d9-e7dd-43ae-a084-a118e894d804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence_len.mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.90311418685121"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc-kqqBWdyOy",
        "colab_type": "code",
        "outputId": "283ccb12-f6aa-4c7a-b4d0-d14228cce1ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "key_len.mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.3079584775086506"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYHspG_87VXs",
        "colab_type": "code",
        "outputId": "96131bb9-f3cf-4daf-f6c9-418d51578b2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset_train.shape, dataset_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((289, 2), (51, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4wd0RmHFclk",
        "colab_type": "code",
        "outputId": "16b91a05-3cee-42dd-b76b-7ea62da5ba04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dataset_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>key</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>He is in the garden.</td>\n",
              "      <td>is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have given some money to Julia.</td>\n",
              "      <td>given</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>He is early.</td>\n",
              "      <td>is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You will have been learning about computers fo...</td>\n",
              "      <td>will have been learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We weren't tired when we arrived.</td>\n",
              "      <td>were n't</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             feature                      key\n",
              "0                               He is in the garden.                       is\n",
              "1                  I have given some money to Julia.                    given\n",
              "2                                       He is early.                       is\n",
              "3  You will have been learning about computers fo...  will have been learning\n",
              "4                  We weren't tired when we arrived.                 were n't"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhR2XxsW7m9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train, dataset_valid = train_test_split(dataset_train, random_state=1234, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6wf39iL-S1U",
        "colab_type": "code",
        "outputId": "546ea01a-c4fb-468e-b7b1-d66126be263e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset_train.shape, dataset_valid.shape, dataset_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((260, 2), (29, 2), (51, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQmIlGVFBTlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write(dataframe, dataset_name, folder=\"data/processed\"):\n",
        "    feature = dataframe[\"feature\"]\n",
        "    key = dataframe[\"key\"]\n",
        "    feature.to_csv('{}/{}.feature'.format(folder, dataset_name), index=False, header=False, escapechar=\" \", quoting=csv.QUOTE_NONE)\n",
        "    key.to_csv('{}/{}.key'.format(folder, dataset_name), index=False, header=False, escapechar=\" \", quoting=csv.QUOTE_NONE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwVZ4xy6G4np",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "write(dataset_train, \"train\")\n",
        "write(dataset_valid, \"valid\")\n",
        "write(dataset_test, \"test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHNqVnpLOj4e",
        "colab_type": "text"
      },
      "source": [
        "## FairSeq Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAE2RUwpHKnN",
        "colab_type": "code",
        "outputId": "490297ce-19a5-4ff6-8ce7-1381228d35b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!fairseq-preprocess --source-lang feature --target-lang key \\\n",
        "     --trainpref data/processed/train --testpref data/processed/test --validpref data/processed/valid\\\n",
        "     --destdir preprocessed_data --seed 1234 --nwordssrc 5000 --nwordstgt 5000"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(align_suffix=None, alignfile=None, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='preprocessed_data', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=1000, lr_scheduler='fixed', memory_efficient_fp16=False, min_loss_scale=0.0001, no_progress_bar=False, nwordssrc=5000, nwordstgt=5000, only_source=False, optimizer='nag', padding_factor=8, seed=1234, source_lang='feature', srcdict=None, target_lang='key', task='translation', tensorboard_logdir='', testpref='data/processed/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, trainpref='data/processed/train', user_dir=None, validpref='data/processed/valid', workers=1)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-preprocess\", line 8, in <module>\n",
            "    sys.exit(cli_main())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fairseq_cli/preprocess.py\", line 346, in cli_main\n",
            "    main(args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fairseq_cli/preprocess.py\", line 58, in main\n",
            "    raise FileExistsError(dict_path(args.source_lang))\n",
            "FileExistsError: preprocessed_data/dict.feature.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZjzhRS6OmVk",
        "colab_type": "text"
      },
      "source": [
        "## FairSeq Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfXrTjq-QJRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip ../.vector_cache/glove6b300dtxt.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yEP3sKWbsz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf checkpoints"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9DBmaQYIG6B",
        "colab_type": "code",
        "outputId": "cb6af97e-cf45-473e-ef0a-e425f3f146fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 fairseq-train preprocessed_data/  --clip-norm 5 --batch-size 64 \\\n",
        "                      --save-dir checkpoints/lstm --arch lstm --max-epoch 15 --encoder-hidden-size 258 \\\n",
        "                      --encoder-layers 2  --decoder-hidden-size 258 --decoder-layers 2 --optimizer adam --lr 0.001  \\\n",
        "                      --dropout 0.3 --encoder-embed-path glove.6B.300d.txt --encoder-bidirectional --encoder-embed-dim 300 \\\n",
        "                      --decoder-embed-dim 300 --no-epoch-checkpoints --decoder-embed-path glove.6B.300d.txt --decoder-out-embed-dim 300 \\\n",
        "                      --num-workers 3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(adam_betas='(0.9, 0.999)', adam_eps=1e-08, adaptive_softmax_cutoff='10000,50000,200000', arch='lstm', best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=5.0, cpu=False, criterion='cross_entropy', curriculum=0, data='preprocessed_data/', dataset_impl=None, ddp_backend='c10d', decoder_attention='1', decoder_dropout_in=0.3, decoder_dropout_out=0.3, decoder_embed_dim=300, decoder_embed_path='glove.6B.300d.txt', decoder_freeze_embed=False, decoder_hidden_size=258, decoder_layers=2, decoder_out_embed_dim=300, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_bidirectional=True, encoder_dropout_in=0.3, encoder_dropout_out=0.3, encoder_embed_dim=300, encoder_embed_path='glove.6B.300d.txt', encoder_freeze_embed=False, encoder_hidden_size=258, encoder_layers=2, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format=None, log_interval=1000, lr=[0.001], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=15, max_sentences=64, max_sentences_valid=64, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, num_workers=3, optimizer='adam', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/lstm', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_updates=0, weight_decay=0.0)\n",
            "| [feature] dictionary: 640 types\n",
            "| [key] dictionary: 160 types\n",
            "| loaded 29 examples from: preprocessed_data/valid.feature-key.feature\n",
            "| loaded 29 examples from: preprocessed_data/valid.feature-key.key\n",
            "| preprocessed_data/ valid feature-key 29 examples\n",
            "| Found 358/640 types in embedding file.\n",
            "| Found 143/160 types in embedding file.\n",
            "LSTMModel(\n",
            "  (encoder): LSTMEncoder(\n",
            "    (embed_tokens): Embedding(640, 300, padding_idx=1)\n",
            "    (lstm): LSTM(300, 258, num_layers=2, dropout=0.3, bidirectional=True)\n",
            "  )\n",
            "  (decoder): LSTMDecoder(\n",
            "    (embed_tokens): Embedding(160, 300, padding_idx=1)\n",
            "    (encoder_hidden_proj): Linear(in_features=516, out_features=258, bias=True)\n",
            "    (encoder_cell_proj): Linear(in_features=516, out_features=258, bias=True)\n",
            "    (layers): ModuleList(\n",
            "      (0): LSTMCell(558, 258)\n",
            "      (1): LSTMCell(258, 258)\n",
            "    )\n",
            "    (attention): AttentionLayer(\n",
            "      (input_proj): Linear(in_features=258, out_features=516, bias=False)\n",
            "      (output_proj): Linear(in_features=774, out_features=258, bias=False)\n",
            "    )\n",
            "    (additional_fc): Linear(in_features=258, out_features=300, bias=True)\n",
            "    (fc_out): Linear(in_features=300, out_features=160, bias=True)\n",
            "  )\n",
            ")\n",
            "| model lstm, criterion CrossEntropyCriterion\n",
            "| num. model params: 5101708 (num. trained: 5101708)\n",
            "| training on 1 GPUs\n",
            "| max tokens per GPU = None and max sentences per GPU = 64\n",
            "| no existing checkpoint found checkpoints/lstm/checkpoint_last.pt\n",
            "| loading train data for epoch 0\n",
            "| loaded 260 examples from: preprocessed_data/train.feature-key.feature\n",
            "| loaded 260 examples from: preprocessed_data/train.feature-key.key\n",
            "| preprocessed_data/ train feature-key 260 examples\n",
            "| epoch 001:  20% 1/5 [00:00<00:00,  4.69it/s, loss=7.276, ppl=154.94, wps=1026, ups=5, wpb=226.000, bsz=64.000, num_updates=1, lr=0.001, gnorm=1.055, clip=0.000, oom=0.000, wall=0, train_wall=0]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [11] is 11 which does not match the computed number of elements 20. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (20,).\n",
            "| epoch 001 | loss 6.178 | ppl 72.42 | wps 2184 | ups 14 | wpb 172.400 | bsz 52.000 | num_updates 5 | lr 0.001 | gnorm 2.505 | clip 0.200 | oom 0.000 | wall 1 | train_wall 0\n",
            "| epoch 001 | valid on 'valid' subset | loss 5.256 | ppl 38.2 | num_updates 5\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_best.pt (epoch 1 @ 5 updates) (writing took 0.1761770248413086 seconds)\n",
            "| epoch 002 | loss 5.009 | ppl 32.2 | wps 2267 | ups 15 | wpb 172.400 | bsz 52.000 | num_updates 10 | lr 0.001 | gnorm 2.929 | clip 0.000 | oom 0.000 | wall 1 | train_wall 1\n",
            "| epoch 002 | valid on 'valid' subset | loss 5.133 | ppl 35.08 | num_updates 10 | best_loss 5.13274\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_best.pt (epoch 2 @ 10 updates) (writing took 0.286052942276001 seconds)\n",
            "| epoch 003 | loss 4.611 | ppl 24.43 | wps 2286 | ups 13 | wpb 172.400 | bsz 52.000 | num_updates 15 | lr 0.001 | gnorm 2.429 | clip 0.000 | oom 0.000 | wall 2 | train_wall 1\n",
            "| epoch 003 | valid on 'valid' subset | loss 4.886 | ppl 29.57 | num_updates 15 | best_loss 4.88596\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_best.pt (epoch 3 @ 15 updates) (writing took 0.18532800674438477 seconds)\n",
            "| epoch 004 | loss 4.265 | ppl 19.23 | wps 2848 | ups 13 | wpb 172.400 | bsz 52.000 | num_updates 20 | lr 0.001 | gnorm 2.444 | clip 0.000 | oom 0.000 | wall 3 | train_wall 1\n",
            "| epoch 004 | valid on 'valid' subset | loss 4.527 | ppl 23.06 | num_updates 20 | best_loss 4.52727\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_best.pt (epoch 4 @ 20 updates) (writing took 2.7541706562042236 seconds)\n",
            "| epoch 005 | loss 3.951 | ppl 15.47 | wps 2230 | ups 15 | wpb 172.400 | bsz 52.000 | num_updates 25 | lr 0.001 | gnorm 2.112 | clip 0.000 | oom 0.000 | wall 6 | train_wall 2\n",
            "| epoch 005 | valid on 'valid' subset | loss 4.392 | ppl 21 | num_updates 25 | best_loss 4.39203\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_best.pt (epoch 5 @ 25 updates) (writing took 0.1873486042022705 seconds)\n",
            "| epoch 006 | loss 3.683 | ppl 12.85 | wps 2119 | ups 12 | wpb 172.400 | bsz 52.000 | num_updates 30 | lr 0.001 | gnorm 1.987 | clip 0.000 | oom 0.000 | wall 7 | train_wall 2\n",
            "| epoch 006 | valid on 'valid' subset | loss 4.079 | ppl 16.9 | num_updates 30 | best_loss 4.07887\n",
            "| epoch 007 | loss 3.662 | ppl 12.66 | wps 2810 | ups 13 | wpb 172.400 | bsz 52.000 | num_updates 35 | lr 0.001 | gnorm 2.296 | clip 0.000 | oom 0.000 | wall 10 | train_wall 2\n",
            "| epoch 007 | valid on 'valid' subset | loss 4.096 | ppl 17.1 | num_updates 35 | best_loss 4.07887\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_last.pt (epoch 7 @ 35 updates) (writing took 0.17694807052612305 seconds)\n",
            "| epoch 008 | loss 3.426 | ppl 10.75 | wps 2277 | ups 15 | wpb 172.400 | bsz 52.000 | num_updates 40 | lr 0.001 | gnorm 1.892 | clip 0.000 | oom 0.000 | wall 11 | train_wall 2\n",
            "| epoch 008 | valid on 'valid' subset | loss 4.094 | ppl 17.08 | num_updates 40 | best_loss 4.07887\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_last.pt (epoch 8 @ 40 updates) (writing took 1.144531488418579 seconds)\n",
            "| epoch 009 | loss 3.222 | ppl 9.33 | wps 2300 | ups 14 | wpb 172.400 | bsz 52.000 | num_updates 45 | lr 0.001 | gnorm 1.805 | clip 0.000 | oom 0.000 | wall 13 | train_wall 3\n",
            "| epoch 009 | valid on 'valid' subset | loss 3.932 | ppl 15.27 | num_updates 45 | best_loss 3.93233\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_best.pt (epoch 9 @ 45 updates) (writing took 1.147951602935791 seconds)\n",
            "| epoch 010 | loss 2.922 | ppl 7.58 | wps 2302 | ups 14 | wpb 172.400 | bsz 52.000 | num_updates 50 | lr 0.001 | gnorm 1.539 | clip 0.000 | oom 0.000 | wall 15 | train_wall 3\n",
            "| epoch 010 | valid on 'valid' subset | loss 3.764 | ppl 13.58 | num_updates 50 | best_loss 3.76364\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_best.pt (epoch 10 @ 50 updates) (writing took 1.7931735515594482 seconds)\n",
            "| epoch 011 | loss 2.864 | ppl 7.28 | wps 2310 | ups 14 | wpb 172.400 | bsz 52.000 | num_updates 55 | lr 0.001 | gnorm 1.907 | clip 0.000 | oom 0.000 | wall 17 | train_wall 3\n",
            "| epoch 011 | valid on 'valid' subset | loss 4.014 | ppl 16.16 | num_updates 55 | best_loss 3.76364\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_last.pt (epoch 11 @ 55 updates) (writing took 1.1388449668884277 seconds)\n",
            "| epoch 012 | loss 2.690 | ppl 6.45 | wps 2464 | ups 15 | wpb 172.400 | bsz 52.000 | num_updates 60 | lr 0.001 | gnorm 1.794 | clip 0.000 | oom 0.000 | wall 19 | train_wall 4\n",
            "| epoch 012 | valid on 'valid' subset | loss 3.614 | ppl 12.24 | num_updates 60 | best_loss 3.61401\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_best.pt (epoch 12 @ 60 updates) (writing took 0.3047308921813965 seconds)\n",
            "| epoch 013 | loss 2.471 | ppl 5.54 | wps 2513 | ups 15 | wpb 172.400 | bsz 52.000 | num_updates 65 | lr 0.001 | gnorm 1.602 | clip 0.000 | oom 0.000 | wall 19 | train_wall 4\n",
            "| epoch 013 | valid on 'valid' subset | loss 3.611 | ppl 12.22 | num_updates 65 | best_loss 3.61067\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_best.pt (epoch 13 @ 65 updates) (writing took 0.1859426498413086 seconds)\n",
            "| epoch 014 | loss 2.298 | ppl 4.92 | wps 2607 | ups 16 | wpb 172.400 | bsz 52.000 | num_updates 70 | lr 0.001 | gnorm 1.326 | clip 0.000 | oom 0.000 | wall 20 | train_wall 4\n",
            "| epoch 014 | valid on 'valid' subset | loss 3.475 | ppl 11.12 | num_updates 70 | best_loss 3.47482\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_best.pt (epoch 14 @ 70 updates) (writing took 2.751106023788452 seconds)\n",
            "| epoch 015 | loss 2.281 | ppl 4.86 | wps 2549 | ups 15 | wpb 172.400 | bsz 52.000 | num_updates 75 | lr 0.001 | gnorm 1.535 | clip 0.000 | oom 0.000 | wall 23 | train_wall 4\n",
            "| epoch 015 | valid on 'valid' subset | loss 3.740 | ppl 13.37 | num_updates 75 | best_loss 3.47482\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_last.pt (epoch 15 @ 75 updates) (writing took 1.142934799194336 seconds)\n",
            "| done training in 24.7 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-kUZSqxOXtu",
        "colab_type": "code",
        "outputId": "50e99a11-7ec9-46c0-dd50-30b83d6aab49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "!fairseq-generate preprocessed_data \\\n",
        "    --path checkpoints/lstm/checkpoint_last.pt \\\n",
        "    --batch-size 64 --beam 3 > lstm_last.out"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3HtuN6DO8BA",
        "colab_type": "code",
        "outputId": "f2a2a4ea-f78f-4fc0-c4b8-1a46abebfebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!grep ^H lstm_last.out | cut -f3- > lstm_last.out.sys\n",
        "!grep ^T lstm_last.out | cut -f2- > lstm_last.out.ref\n",
        "!fairseq-score --sys lstm_last.out.sys --ref lstm_last.out.ref --ignore-case"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(ignore_case=True, order=4, ref='lstm_last.out.ref', sacrebleu=False, sentence_bleu=False, sys='lstm_last.out.sys')\n",
            "BLEU4 = 0.00, 43.5/23.8/18.2/0.0 (BP=1.000, ratio=1.083, syslen=131, reflen=121)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBlDQxWnZU2w",
        "colab_type": "code",
        "outputId": "3d0678db-1d9c-4b7f-b988-649e2a8d34b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!fairseq-score -h"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: fairseq-score [-h] [-s SYS] -r REF [-o N] [--ignore-case] [--sacrebleu]\n",
            "                     [--sentence-bleu]\n",
            "\n",
            "Command-line script for BLEU scoring.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help         show this help message and exit\n",
            "  -s SYS, --sys SYS  system output\n",
            "  -r REF, --ref REF  references\n",
            "  -o N, --order N    consider ngrams up to this order\n",
            "  --ignore-case      case-insensitive scoring\n",
            "  --sacrebleu        score with sacrebleu\n",
            "  --sentence-bleu    report sentence-level BLEUs (i.e., with +1 smoothing)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfvfTZWAQBSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4lKFYoeaDM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}