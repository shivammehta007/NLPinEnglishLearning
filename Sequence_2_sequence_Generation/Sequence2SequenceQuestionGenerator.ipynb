{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivammehta007/QuestionGenerator/blob/master/Sequence2SequenceQuestionGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLtWBqUscOtx",
        "colab_type": "text"
      },
      "source": [
        "# Question Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T808ilq_g2bm",
        "colab_type": "text"
      },
      "source": [
        "Additional Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LU58nY0cTuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install fairseq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSk9ez44VPd2",
        "colab_type": "code",
        "outputId": "ef0a5bee-c6a2-4491-f359-5b6d3d16a18c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!rm -rf QuestionGenerator\n",
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "from subprocess import Popen\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "# repo_name = input('Repo name: ')\n",
        "\n",
        "cmd_string = 'git clone --single-branch --branch master  https://{0}:{1}@github.com/{0}/{2}.git'.format(user, password, 'QuestionGenerator')\n",
        "print(Popen(cmd_string, shell=True))\n",
        "cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: shivammehta007\n",
            "Password: ··········\n",
            "<subprocess.Popen object at 0x7fe4277e6e80>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YST7xIhop87U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5aa00622-5bc5-4d13-eb77-ff0e2ca38705"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvlCMl-LJI1H",
        "colab_type": "text"
      },
      "source": [
        "## Download Glove from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzMieNSOJIFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "kaggle_info = json.load(open(\"/content/drive/My Drive/kaggle.json\"))\n",
        "os.environ['KAGGLE_USERNAME'] = kaggle_info[\"username\"]\n",
        "os.environ['KAGGLE_KEY'] = kaggle_info[\"key\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPfYshuJKWLJ",
        "colab_type": "code",
        "outputId": "9f1d337b-1046-48b6-fec8-f1750c8e8ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!kaggle datasets list --user thanakomsn"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                        title               size  lastUpdated          downloadCount  \n",
            "-------------------------  -----------------  -----  -------------------  -------------  \n",
            "thanakomsn/glove6b300dtxt  glove.6B.300d.txt  386MB  2017-11-28 07:19:43           2926  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oksPtO8LpYP",
        "colab_type": "code",
        "outputId": "38b4a9ad-993c-4fcd-854c-45874279396c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!kaggle datasets download thanakomsn/glove6b300dtxt "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading glove6b300dtxt.zip to /content/QuestionGenerator/Sequence_2_sequence_Generation/FairSeq_models\n",
            " 99% 381M/386M [00:01<00:00, 242MB/s]\n",
            "100% 386M/386M [00:01<00:00, 237MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRjCEyqsL_8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mkdir .vector_cache\n",
        "%mv glove6b300dtxt.zip .vector_cache/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haCNqeqHMUDs",
        "colab_type": "code",
        "outputId": "ff4e2f85-a83e-46b2-c7f6-37a122301d43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!unzip .vector_cache/glove6b300dtxt.zip\n",
        "%ls -a .vector_cache/"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  .vector_cache/glove6b300dtxt.zip\n",
            "  inflating: glove.6B.300d.txt       \n",
            "\u001b[0m\u001b[01;34m.\u001b[0m/  \u001b[01;34m..\u001b[0m/  glove6b300dtxt.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8P_KmkLuS_K",
        "colab_type": "text"
      },
      "source": [
        "## Training Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vp6priLuScN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13e81d25-8633-4db3-d8cb-41e67eb80795"
      },
      "source": [
        "%cd QuestionGenerator/Sequence_2_sequence_Generation/Baseline"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/QuestionGenerator/Sequence_2_sequence_Generation/Baseline\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8InSCqJsz2t2",
        "colab_type": "text"
      },
      "source": [
        "### Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77-o86yRzqGs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "ec68274c-5ea4-47b7-affc-5587049e2657"
      },
      "source": [
        "!python datadownloader.py --help"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: datadownloader.py [-h] [-d DATASET] [-f]\n",
            "\n",
            "Utility to download datasets currently available datasets: SQUAD\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -d DATASET, --dataset DATASET\n",
            "                        Name of Dataset\n",
            "  -f, --force           Skip Directory check and force override download\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFe8BPEHz5Oq",
        "colab_type": "text"
      },
      "source": [
        "### PreProcess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_7dVFhFuRfr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c39b36ca-89a5-4046-ac54-6c6e5ac93032"
      },
      "source": [
        "!python preprocessing.py --help"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: preprocessing.py [-h] [-d DATASET] [-m MODE] [-f]\n",
            "\n",
            "Utility to Preprocess datasets currently available datasets: SQUAD\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -d DATASET, --dataset DATASET\n",
            "                        Name of Dataset\n",
            "  -m MODE, --mode MODE  Split on ANSWER or QUESTION\n",
            "  -f, --filter          filter the sentences on answers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC3E8GHCz_gT",
        "colab_type": "text"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZORRhCvzJE-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "fcafe119-b9c4-4cbd-935d-9f6a820f75ea"
      },
      "source": [
        "!python train.py --help"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: train.py [-h] [-d DATASET] [-m MODEL] [-c CLIPNORM] [-l LEARNINGRATE]\n",
            "                [-v] [-e EPOCHS] [-t TEACHERFORCING] [-tmp TRAINED_MODEL_PATH]\n",
            "\n",
            "Utility to Train datasets {1: 'VanillaSeq2Seq'}\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -d DATASET, --dataset DATASET\n",
            "                        which dataset to train on\n",
            "  -m MODEL, --model MODEL\n",
            "                        Which Model to Train\n",
            "  -c CLIPNORM, --clipnorm CLIPNORM\n",
            "                        Value to clip gradients\n",
            "  -l LEARNINGRATE, --learningrate LEARNINGRATE\n",
            "                        Learning rate of Adam Optmizer\n",
            "  -v, --validation      Flag to turn validation on and off\n",
            "  -e EPOCHS, --epochs EPOCHS\n",
            "                        Number of Epochs to train\n",
            "  -t TEACHERFORCING, --teacherforcing TEACHERFORCING\n",
            "                        Teacher Forcing\n",
            "  -tmp TRAINED_MODEL_PATH, --trained-model-path TRAINED_MODEL_PATH\n",
            "                        Load the model from the directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx2xIwdY0A97",
        "colab_type": "text"
      },
      "source": [
        "### Inference Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHjlEcrnzmoe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "0925d32e-fb39-42ba-df4b-7845dc6df6c2"
      },
      "source": [
        "!python inference.py --help"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: inference.py [-h] [-d DATASET] [-m MODEL] [-ml MAX_LEN]\n",
            "                    [-l MODEL_LOCATION]\n",
            "\n",
            "Utility to generate Inference\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -d DATASET, --dataset DATASET\n",
            "                        which dataset to train on\n",
            "  -m MODEL, --model MODEL\n",
            "                        Which Model to Train\n",
            "  -ml MAX_LEN, --max-len MAX_LEN\n",
            "                        Max length of the question to be generated\n",
            "  -l MODEL_LOCATION, --model-location MODEL_LOCATION\n",
            "                        Location of Model File\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvWOHszAk_Xf",
        "colab_type": "text"
      },
      "source": [
        "# Other Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCsoDiJ4k9I8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77e33c21-31fa-4b6e-9de2-7e5137a4e4f6"
      },
      "source": [
        "%cd ../FairSeq_models/"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/QuestionGenerator/Sequence_2_sequence_Generation/FairSeq_models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IaIDte6mzQK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "fc86fb0d-5e5c-4114-fbe6-8ee5aa0920f0"
      },
      "source": [
        "!python preprocess.py"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO | preprocess.py:92 -           preprocess() ] Running FairSeq Preprocessing to convert files into fairseq binaries\n",
            "Namespace(align_suffix=None, alignfile=None, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data/fairseq_binaries', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=1000, lr_scheduler='fixed', memory_efficient_fp16=False, min_loss_scale=0.0001, no_progress_bar=False, nwordssrc=45000, nwordstgt=28000, only_source=False, optimizer='nag', padding_factor=8, seed=1234, source_lang='sentence', srcdict=None, target_lang='question', task='translation', tensorboard_logdir='', testpref='data/processed/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, trainpref='data/processed/train', user_dir=None, validpref='data/processed/valid', workers=1)\n",
            "| [sentence] Dictionary: 44999 types\n",
            "| [sentence] data/processed/train.sentence: 70484 sents, 2386532 tokens, 1.32% replaced by <unk>\n",
            "| [sentence] Dictionary: 44999 types\n",
            "| [sentence] data/processed/valid.sentence: 10570 sents, 368586 tokens, 5.17% replaced by <unk>\n",
            "| [sentence] Dictionary: 44999 types\n",
            "| [sentence] data/processed/test.sentence: 11877 sents, 397472 tokens, 5.35% replaced by <unk>\n",
            "| [question] Dictionary: 27999 types\n",
            "| [question] data/processed/train.question: 70484 sents, 866317 tokens, 0.85% replaced by <unk>\n",
            "| [question] Dictionary: 27999 types\n",
            "| [question] data/processed/valid.question: 10570 sents, 131365 tokens, 4.72% replaced by <unk>\n",
            "| [question] Dictionary: 27999 types\n",
            "| [question] data/processed/test.question: 11877 sents, 149804 tokens, 5.33% replaced by <unk>\n",
            "| Wrote preprocessed data to data/fairseq_binaries\n",
            "[DEBUG | preprocess.py:136 -             <module>() ] Utility Finished Execution in: 35.7204ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rVCq14cnS6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "5b0b29af-310f-4e3a-e85b-35a1a7755e21"
      },
      "source": [
        "!python train.py --help"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: train.py [-h] [-m {LSTM,CNN,Transformer}] [-n NUM_EPOCHS]\n",
            "                [-b BATCH_SIZE]\n",
            "\n",
            "Utility to train the models\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -m {LSTM,CNN,Transformer}, --model {LSTM,CNN,Transformer}\n",
            "                        Select the Seq2Seq Model to train\n",
            "  -n NUM_EPOCHS, --num-epochs NUM_EPOCHS\n",
            "                        Number of epochs to train\n",
            "  -b BATCH_SIZE, --batch-size BATCH_SIZE\n",
            "                        Training Batch Size\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duH2P4mKq-nT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "037ab390-f849-4432-b898-543b9a92b3c3"
      },
      "source": [
        "!python generate.py --help"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: generate.py [-h] [-m {LSTM,CNN}] [-sm {best,last}] [-b BATCH_SIZE]\n",
            "\n",
            "Utility to Generate Sentences from Test Set\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -m {LSTM,CNN}, --model {LSTM,CNN}\n",
            "                        Select the Seq2Seq Model to train\n",
            "  -sm {best,last}, --sub-model {best,last}\n",
            "                        Select which model to generate with the one with best\n",
            "                        valid loss or the last epoch trained model\n",
            "  -b BATCH_SIZE, --batch-size BATCH_SIZE\n",
            "                        Training Batch Size\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbCvK5CVtQ42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}