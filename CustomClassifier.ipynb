{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CustomClassifier",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1PQCpSDGct4BTv3x9oH8GD1HIdNihgWj0",
      "authorship_tag": "ABX9TyMkR0XHSrI+mVnxeoQVl3xk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivammehta007/QuestionGenerator/blob/master/CustomClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaCToCs_b4d1",
        "colab_type": "text"
      },
      "source": [
        "# Testing Classifier Deep Learning Architecture Based"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b9CNpxNblqe",
        "colab_type": "code",
        "outputId": "407377ca-f234-4479-d762-bfd67a53a8c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!rm -rf QuestionGenerator\n",
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "# repo_name = input('Repo name: ')\n",
        "\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/{0}/{2}.git'.format(user, password, 'QuestionGenerator')\n",
        "os.system(cmd_string)\n",
        "cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: shivammehta007\n",
            "Password: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW_iNs97b9e9",
        "colab_type": "code",
        "outputId": "9dff12e8-507e-471a-ae30-30971f9a931a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!rm -rf QuestionGenerator/FromScratch\n",
        "%cd QuestionGenerator/classifier/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/QuestionGenerator/classifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxftkthaPIGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "42bcec18-658c-4b07-dd19-f913d2078877"
      },
      "source": [
        "# !rm -rf data/processed/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d480480aad0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -rf data/processed/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAatXS64cdOR",
        "colab_type": "code",
        "outputId": "94912496-615d-4571-82c6-6d05b786b6d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# !python preprocessdata.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[DEBUG | preprocessdata.py:83 -           preprocess() ] Saving the file preprocessed files to : processed\n",
            "[DEBUG | preprocessdata.py:108 -             <module>() ] Utility Finished Execution in: 0.1726ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC0OzHqrpJEx",
        "colab_type": "code",
        "outputId": "af9a3ffa-de30-4815-cc7b-852276c14795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%ls -a"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m.\u001b[0m/   \u001b[01;34mconfig\u001b[0m/  datasetloader.py    \u001b[01;34mmodel\u001b[0m/             \u001b[01;34mtrained\u001b[0m/  utility.py\n",
            "\u001b[01;34m..\u001b[0m/  \u001b[01;34mdata\u001b[0m/    helperfunctions.py  preprocessdata.py  train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvlCMl-LJI1H",
        "colab_type": "text"
      },
      "source": [
        "## Download Glove from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzMieNSOJIFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "kaggle_info = json.load(open(\"/content/drive/My Drive/kaggle.json\"))\n",
        "os.environ['KAGGLE_USERNAME'] = kaggle_info[\"username\"]\n",
        "os.environ['KAGGLE_KEY'] = kaggle_info[\"key\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPfYshuJKWLJ",
        "colab_type": "code",
        "outputId": "a24c4274-d87d-41ca-d0f7-3844e086f11a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!kaggle datasets list --user thanakomsn"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                        title               size  lastUpdated          downloadCount  \n",
            "-------------------------  -----------------  -----  -------------------  -------------  \n",
            "thanakomsn/glove6b300dtxt  glove.6B.300d.txt  386MB  2017-11-28 07:19:43           2621  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oksPtO8LpYP",
        "colab_type": "code",
        "outputId": "6d342ca5-01a7-465d-bc3f-2c9e01ec9e4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!kaggle datasets download thanakomsn/glove6b300dtxt "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading glove6b300dtxt.zip to /content/QuestionGenerator/classifier\n",
            " 96% 369M/386M [00:10<00:00, 38.3MB/s]\n",
            "100% 386M/386M [00:10<00:00, 36.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRjCEyqsL_8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mkdir .vector_cache\n",
        "%mv glove6b300dtxt.zip .vector_cache/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haCNqeqHMUDs",
        "colab_type": "code",
        "outputId": "60fca98b-3c48-4ee0-8b05-e8351f5398d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!unzip .vector_cache/glove6b300dtxt.zip\n",
        "%ls -a .vector_cache/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  .vector_cache/glove6b300dtxt.zip\n",
            "  inflating: glove.6B.300d.txt       \n",
            "\u001b[0m\u001b[01;34m.\u001b[0m/  \u001b[01;34m..\u001b[0m/  glove6b300dtxt.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nhgkJx_ne2G",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIWmWDYBxNI7",
        "colab_type": "code",
        "outputId": "36682de3-e653-4709-a624-450b0d2b2417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "!python train.py -h"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: train.py [-h] [-s SEED] [-loc MODEL_LOCATION] [-b BIDIRECTIONAL]\n",
            "                [-d DROPOUT] [-e EMBEDDING_DIM] [-hd HIDDEN_DIM] [-l N_LAYERS]\n",
            "                [-lr LEARNING_RATE] [-n EPOCHS] [-batch BATCH_SIZE]\n",
            "                [-f FREEZE_EMBEDDINGS] [-t {multi,single}]\n",
            "                [-l2 L2_REGULARIZATION]\n",
            "                [-m {RNNHiddenClassifier,RNNMaxpoolClassifier,CNN2dClassifier,CNN1dClassifier}]\n",
            "\n",
            "Utility to train the Model\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -s SEED, --seed SEED  Set custom seed for reproducibility\n",
            "  -loc MODEL_LOCATION, --model-location MODEL_LOCATION\n",
            "                        Give an already trained model location to use and\n",
            "                        train more epochs on it\n",
            "  -b BIDIRECTIONAL, --bidirectional BIDIRECTIONAL\n",
            "                        Makes the model Bidirectional\n",
            "  -d DROPOUT, --dropout DROPOUT\n",
            "                        Dropout count for the model\n",
            "  -e EMBEDDING_DIM, --embedding-dim EMBEDDING_DIM\n",
            "                        Embedding Dimensions\n",
            "  -hd HIDDEN_DIM, --hidden-dim HIDDEN_DIM\n",
            "                        Hidden dimensions of the RNN\n",
            "  -l N_LAYERS, --n-layers N_LAYERS\n",
            "                        Number of layers in RNN\n",
            "  -lr LEARNING_RATE, --learning-rate LEARNING_RATE\n",
            "                        Learning rate of Adam Optimizer\n",
            "  -n EPOCHS, --epochs EPOCHS\n",
            "                        Number of Epochs to train model\n",
            "  -batch BATCH_SIZE, --batch_size BATCH_SIZE\n",
            "                        Number of Epochs to train model\n",
            "  -f FREEZE_EMBEDDINGS, --freeze-embeddings FREEZE_EMBEDDINGS\n",
            "                        Freeze Embeddings of Model\n",
            "  -t {multi,single}, --tag {multi,single}\n",
            "                        Use two different dataset type, multi type and single\n",
            "                        type where all are merged into same key\n",
            "  -l2 L2_REGULARIZATION, --l2-regularization L2_REGULARIZATION\n",
            "                        Value of alpha in l2 regularization 0 means no\n",
            "                        regularization\n",
            "  -m {RNNHiddenClassifier,RNNMaxpoolClassifier,CNN2dClassifier,CNN1dClassifier}, --model {RNNHiddenClassifier,RNNMaxpoolClassifier,CNN2dClassifier,CNN1dClassifier}\n",
            "                        select the classifier to train on\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd6-Cp6UiuT8",
        "colab_type": "text"
      },
      "source": [
        "## RNNClassifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adzPuBh7NbLC",
        "colab_type": "text"
      },
      "source": [
        "### RNNHiddenClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNHpPoyGcz9H",
        "colab_type": "code",
        "outputId": "1997c067-a2d8-4af3-cec5-34344e46aa35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py -n 30 --freeze-embeddings 0"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[DEBUG | train.py:268 -             <module>() ] Namespace(batch_size=64, bidirectional=True, dropout=0.7, embedding_dim=300, epochs=30, freeze_embeddings=0, hidden_dim=128, l2_regularization=0.001, learning_rate=0.001, model='RNNHiddenClassifier', model_location=None, n_layers=1, seed=1234, tag='multi')\n",
            "[DEBUG | train.py:269 -             <module>() ] Custom seed set with: 1234\n",
            "[INFO | train.py:271 -             <module>() ] Loading Dataset\n",
            "[DEBUG | datasetloader.py:81 -        get_iterators() ] Data Loaded Successfully!\n",
            "[INFO | vocab.py:386 -                cache() ] Loading vectors from .vector_cache/glove.6B.300d.txt.pt\n",
            "[DEBUG | datasetloader.py:95 -        get_iterators() ] Vocabulary Loaded\n",
            "[DEBUG | datasetloader.py:103 -        get_iterators() ] Created Iterators\n",
            "[INFO | train.py:278 -             <module>() ] Dataset Loaded Successfully\n",
            "[DEBUG | train.py:68 - initialize_new_model() ] Initializing Model\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[DEBUG | train.py:134 - initialize_new_model() ] Freeze Embeddings Value 0: True\n",
            "[INFO | train.py:140 - initialize_new_model() ] Model Initialized with 635,147 trainiable parameters\n",
            "[DEBUG | train.py:152 - initialize_new_model() ] Copied PreTrained Embeddings\n",
            "[INFO | train.py:303 -             <module>() ] RNNHiddenClassifier(\n",
            "  (embedding): Embedding(640, 300, padding_idx=1)\n",
            "  (rnn): LSTM(300, 128, dropout=0.7, bidirectional=True)\n",
            "  (fc): Linear(in_features=256, out_features=11, bias=True)\n",
            "  (dropout): Dropout(p=0.7, inplace=False)\n",
            ")\n",
            "100% 9/9 [00:00<00:00, 45.65it/s]\n",
            "100% 2/2 [00:00<00:00, 134.86it/s]\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.377 | Train Acc: 13.24%\n",
            "\t Val. Loss: 2.239 |  Val. Acc: 29.50%\n",
            "100% 9/9 [00:00<00:00, 61.87it/s]\n",
            "100% 2/2 [00:00<00:00, 139.64it/s]\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.268 | Train Acc: 18.47%\n",
            "\t Val. Loss: 2.187 |  Val. Acc: 27.79%\n",
            "100% 9/9 [00:00<00:00, 59.67it/s]\n",
            "100% 2/2 [00:00<00:00, 142.25it/s]\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.237 | Train Acc: 18.29%\n",
            "\t Val. Loss: 2.179 |  Val. Acc: 7.81%\n",
            "100% 9/9 [00:00<00:00, 63.03it/s]\n",
            "100% 2/2 [00:00<00:00, 140.00it/s]\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.198 | Train Acc: 20.09%\n",
            "\t Val. Loss: 2.143 |  Val. Acc: 10.94%\n",
            "100% 9/9 [00:00<00:00, 64.09it/s]\n",
            "100% 2/2 [00:00<00:00, 141.44it/s]\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.129 | Train Acc: 22.68%\n",
            "\t Val. Loss: 2.101 |  Val. Acc: 19.47%\n",
            "100% 9/9 [00:00<00:00, 62.27it/s]\n",
            "100% 2/2 [00:00<00:00, 144.67it/s]\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.093 | Train Acc: 29.14%\n",
            "\t Val. Loss: 2.012 |  Val. Acc: 25.08%\n",
            "100% 9/9 [00:00<00:00, 60.24it/s]\n",
            "100% 2/2 [00:00<00:00, 142.06it/s]\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.009 | Train Acc: 28.80%\n",
            "\t Val. Loss: 1.903 |  Val. Acc: 30.34%\n",
            "100% 9/9 [00:00<00:00, 64.10it/s]\n",
            "100% 2/2 [00:00<00:00, 148.39it/s]\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.915 | Train Acc: 35.63%\n",
            "\t Val. Loss: 1.695 |  Val. Acc: 47.97%\n",
            "100% 9/9 [00:00<00:00, 64.25it/s]\n",
            "100% 2/2 [00:00<00:00, 142.97it/s]\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.725 | Train Acc: 42.85%\n",
            "\t Val. Loss: 1.623 |  Val. Acc: 44.28%\n",
            "100% 9/9 [00:00<00:00, 64.25it/s]\n",
            "100% 2/2 [00:00<00:00, 145.46it/s]\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.574 | Train Acc: 46.28%\n",
            "\t Val. Loss: 1.517 |  Val. Acc: 46.62%\n",
            "100% 9/9 [00:00<00:00, 63.02it/s]\n",
            "100% 2/2 [00:00<00:00, 140.01it/s]\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.455 | Train Acc: 50.82%\n",
            "\t Val. Loss: 1.492 |  Val. Acc: 44.28%\n",
            "100% 9/9 [00:00<00:00, 63.69it/s]\n",
            "100% 2/2 [00:00<00:00, 146.64it/s]\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.298 | Train Acc: 57.37%\n",
            "\t Val. Loss: 1.297 |  Val. Acc: 54.94%\n",
            "100% 9/9 [00:00<00:00, 63.45it/s]\n",
            "100% 2/2 [00:00<00:00, 142.44it/s]\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.217 | Train Acc: 57.22%\n",
            "\t Val. Loss: 1.429 |  Val. Acc: 49.32%\n",
            "100% 9/9 [00:00<00:00, 65.27it/s]\n",
            "100% 2/2 [00:00<00:00, 147.24it/s]\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.090 | Train Acc: 61.14%\n",
            "\t Val. Loss: 1.159 |  Val. Acc: 59.06%\n",
            "100% 9/9 [00:00<00:00, 62.13it/s]\n",
            "100% 2/2 [00:00<00:00, 142.14it/s]\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.995 | Train Acc: 69.39%\n",
            "\t Val. Loss: 1.230 |  Val. Acc: 57.14%\n",
            "100% 9/9 [00:00<00:00, 65.59it/s]\n",
            "100% 2/2 [00:00<00:00, 144.54it/s]\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.883 | Train Acc: 72.12%\n",
            "\t Val. Loss: 1.038 |  Val. Acc: 66.60%\n",
            "100% 9/9 [00:00<00:00, 65.80it/s]\n",
            "100% 2/2 [00:00<00:00, 138.37it/s]\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.822 | Train Acc: 72.90%\n",
            "\t Val. Loss: 1.029 |  Val. Acc: 64.67%\n",
            "100% 9/9 [00:00<00:00, 61.98it/s]\n",
            "100% 2/2 [00:00<00:00, 146.60it/s]\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.726 | Train Acc: 77.35%\n",
            "\t Val. Loss: 0.904 |  Val. Acc: 70.86%\n",
            "100% 9/9 [00:00<00:00, 63.12it/s]\n",
            "100% 2/2 [00:00<00:00, 140.03it/s]\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.695 | Train Acc: 79.00%\n",
            "\t Val. Loss: 0.928 |  Val. Acc: 66.24%\n",
            "100% 9/9 [00:00<00:00, 65.11it/s]\n",
            "100% 2/2 [00:00<00:00, 140.59it/s]\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.660 | Train Acc: 80.41%\n",
            "\t Val. Loss: 0.842 |  Val. Acc: 70.86%\n",
            "100% 9/9 [00:00<00:00, 62.36it/s]\n",
            "100% 2/2 [00:00<00:00, 143.00it/s]\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.564 | Train Acc: 83.17%\n",
            "\t Val. Loss: 0.877 |  Val. Acc: 70.86%\n",
            "100% 9/9 [00:00<00:00, 65.71it/s]\n",
            "100% 2/2 [00:00<00:00, 148.85it/s]\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.540 | Train Acc: 83.60%\n",
            "\t Val. Loss: 0.825 |  Val. Acc: 69.51%\n",
            "100% 9/9 [00:00<00:00, 63.27it/s]\n",
            "100% 2/2 [00:00<00:00, 137.35it/s]\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.517 | Train Acc: 84.47%\n",
            "\t Val. Loss: 0.869 |  Val. Acc: 70.86%\n",
            "100% 9/9 [00:00<00:00, 57.36it/s]\n",
            "100% 2/2 [00:00<00:00, 144.71it/s]\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.502 | Train Acc: 85.21%\n",
            "\t Val. Loss: 0.875 |  Val. Acc: 74.56%\n",
            "100% 9/9 [00:00<00:00, 66.31it/s]\n",
            "100% 2/2 [00:00<00:00, 140.33it/s]\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.473 | Train Acc: 85.25%\n",
            "\t Val. Loss: 0.763 |  Val. Acc: 72.99%\n",
            "100% 9/9 [00:00<00:00, 59.54it/s]\n",
            "100% 2/2 [00:00<00:00, 129.88it/s]\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.484 | Train Acc: 84.60%\n",
            "\t Val. Loss: 0.760 |  Val. Acc: 74.35%\n",
            "100% 9/9 [00:00<00:00, 64.11it/s]\n",
            "100% 2/2 [00:00<00:00, 139.02it/s]\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.421 | Train Acc: 86.42%\n",
            "\t Val. Loss: 0.891 |  Val. Acc: 70.86%\n",
            "100% 9/9 [00:00<00:00, 64.76it/s]\n",
            "100% 2/2 [00:00<00:00, 140.41it/s]\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.395 | Train Acc: 87.68%\n",
            "\t Val. Loss: 0.796 |  Val. Acc: 73.78%\n",
            "100% 9/9 [00:00<00:00, 62.23it/s]\n",
            "100% 2/2 [00:00<00:00, 141.41it/s]\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.395 | Train Acc: 88.92%\n",
            "\t Val. Loss: 0.939 |  Val. Acc: 67.95%\n",
            "100% 9/9 [00:00<00:00, 63.92it/s]\n",
            "100% 2/2 [00:00<00:00, 114.85it/s]\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.361 | Train Acc: 88.81%\n",
            "\t Val. Loss: 0.815 |  Val. Acc: 71.64%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hQXMDrqis75",
        "colab_type": "text"
      },
      "source": [
        "### RNNMaxpoolClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7QpzdKfir48",
        "colab_type": "code",
        "outputId": "1ea7eefd-4d17-4f45-9e92-a63810cd2780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py -n 30 -m RNNMaxpoolClassifier  --freeze-embeddings 0"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[DEBUG | train.py:268 -             <module>() ] Namespace(batch_size=64, bidirectional=True, dropout=0.7, embedding_dim=300, epochs=30, freeze_embeddings=0, hidden_dim=128, l2_regularization=0.001, learning_rate=0.001, model='RNNMaxpoolClassifier', model_location=None, n_layers=1, seed=1234, tag='multi')\n",
            "[DEBUG | train.py:269 -             <module>() ] Custom seed set with: 1234\n",
            "[INFO | train.py:271 -             <module>() ] Loading Dataset\n",
            "[DEBUG | datasetloader.py:81 -        get_iterators() ] Data Loaded Successfully!\n",
            "[INFO | vocab.py:386 -                cache() ] Loading vectors from .vector_cache/glove.6B.300d.txt.pt\n",
            "[DEBUG | datasetloader.py:95 -        get_iterators() ] Vocabulary Loaded\n",
            "[DEBUG | datasetloader.py:103 -        get_iterators() ] Created Iterators\n",
            "[INFO | train.py:278 -             <module>() ] Dataset Loaded Successfully\n",
            "[DEBUG | train.py:68 - initialize_new_model() ] Initializing Model\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[DEBUG | train.py:134 - initialize_new_model() ] Freeze Embeddings Value 0: True\n",
            "[INFO | train.py:140 - initialize_new_model() ] Model Initialized with 633,739 trainiable parameters\n",
            "[DEBUG | train.py:152 - initialize_new_model() ] Copied PreTrained Embeddings\n",
            "[INFO | train.py:303 -             <module>() ] RNNMaxpoolClassifier(\n",
            "  (embedding): Embedding(640, 300, padding_idx=1)\n",
            "  (rnn): LSTM(300, 128, dropout=0.7, bidirectional=True)\n",
            "  (fc): Linear(in_features=128, out_features=11, bias=True)\n",
            "  (dropout): Dropout(p=0.7, inplace=False)\n",
            ")\n",
            "100% 9/9 [00:00<00:00, 45.96it/s]\n",
            "100% 2/2 [00:00<00:00, 128.16it/s]\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.359 | Train Acc: 14.19%\n",
            "\t Val. Loss: 2.261 |  Val. Acc: 21.75%\n",
            "100% 9/9 [00:00<00:00, 59.39it/s]\n",
            "100% 2/2 [00:00<00:00, 128.92it/s]\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.261 | Train Acc: 19.05%\n",
            "\t Val. Loss: 2.185 |  Val. Acc: 26.44%\n",
            "100% 9/9 [00:00<00:00, 61.31it/s]\n",
            "100% 2/2 [00:00<00:00, 111.88it/s]\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.183 | Train Acc: 22.81%\n",
            "\t Val. Loss: 2.153 |  Val. Acc: 18.12%\n",
            "100% 9/9 [00:00<00:00, 60.23it/s]\n",
            "100% 2/2 [00:00<00:00, 132.06it/s]\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.138 | Train Acc: 24.63%\n",
            "\t Val. Loss: 2.094 |  Val. Acc: 24.51%\n",
            "100% 9/9 [00:00<00:00, 59.33it/s]\n",
            "100% 2/2 [00:00<00:00, 129.69it/s]\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.071 | Train Acc: 36.28%\n",
            "\t Val. Loss: 2.018 |  Val. Acc: 33.04%\n",
            "100% 9/9 [00:00<00:00, 56.95it/s]\n",
            "100% 2/2 [00:00<00:00, 130.43it/s]\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.978 | Train Acc: 38.02%\n",
            "\t Val. Loss: 1.898 |  Val. Acc: 33.61%\n",
            "100% 9/9 [00:00<00:00, 60.96it/s]\n",
            "100% 2/2 [00:00<00:00, 133.89it/s]\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.852 | Train Acc: 42.64%\n",
            "\t Val. Loss: 1.771 |  Val. Acc: 39.23%\n",
            "100% 9/9 [00:00<00:00, 62.05it/s]\n",
            "100% 2/2 [00:00<00:00, 137.62it/s]\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.704 | Train Acc: 44.63%\n",
            "\t Val. Loss: 1.613 |  Val. Acc: 44.64%\n",
            "100% 9/9 [00:00<00:00, 61.60it/s]\n",
            "100% 2/2 [00:00<00:00, 135.85it/s]\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.522 | Train Acc: 49.88%\n",
            "\t Val. Loss: 1.482 |  Val. Acc: 50.89%\n",
            "100% 9/9 [00:00<00:00, 60.74it/s]\n",
            "100% 2/2 [00:00<00:00, 136.99it/s]\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.362 | Train Acc: 56.00%\n",
            "\t Val. Loss: 1.364 |  Val. Acc: 55.93%\n",
            "100% 9/9 [00:00<00:00, 58.66it/s]\n",
            "100% 2/2 [00:00<00:00, 131.28it/s]\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.194 | Train Acc: 62.49%\n",
            "\t Val. Loss: 1.290 |  Val. Acc: 58.07%\n",
            "100% 9/9 [00:00<00:00, 60.97it/s]\n",
            "100% 2/2 [00:00<00:00, 131.78it/s]\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.994 | Train Acc: 69.76%\n",
            "\t Val. Loss: 1.124 |  Val. Acc: 56.93%\n",
            "100% 9/9 [00:00<00:00, 61.20it/s]\n",
            "100% 2/2 [00:00<00:00, 136.04it/s]\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.835 | Train Acc: 76.70%\n",
            "\t Val. Loss: 1.074 |  Val. Acc: 63.11%\n",
            "100% 9/9 [00:00<00:00, 61.56it/s]\n",
            "100% 2/2 [00:00<00:00, 130.80it/s]\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.698 | Train Acc: 81.06%\n",
            "\t Val. Loss: 0.943 |  Val. Acc: 68.16%\n",
            "100% 9/9 [00:00<00:00, 60.74it/s]\n",
            "100% 2/2 [00:00<00:00, 128.97it/s]\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.580 | Train Acc: 83.58%\n",
            "\t Val. Loss: 0.970 |  Val. Acc: 63.68%\n",
            "100% 9/9 [00:00<00:00, 62.34it/s]\n",
            "100% 2/2 [00:00<00:00, 135.35it/s]\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.547 | Train Acc: 84.62%\n",
            "\t Val. Loss: 1.049 |  Val. Acc: 65.24%\n",
            "100% 9/9 [00:00<00:00, 62.47it/s]\n",
            "100% 2/2 [00:00<00:00, 137.99it/s]\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.550 | Train Acc: 83.67%\n",
            "\t Val. Loss: 0.862 |  Val. Acc: 69.51%\n",
            "100% 9/9 [00:00<00:00, 56.97it/s]\n",
            "100% 2/2 [00:00<00:00, 138.13it/s]\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.446 | Train Acc: 88.15%\n",
            "\t Val. Loss: 0.884 |  Val. Acc: 67.95%\n",
            "100% 9/9 [00:00<00:00, 61.13it/s]\n",
            "100% 2/2 [00:00<00:00, 127.91it/s]\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.432 | Train Acc: 86.64%\n",
            "\t Val. Loss: 0.787 |  Val. Acc: 69.51%\n",
            "100% 9/9 [00:00<00:00, 66.66it/s]\n",
            "100% 2/2 [00:00<00:00, 141.37it/s]\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.377 | Train Acc: 88.96%\n",
            "\t Val. Loss: 0.798 |  Val. Acc: 71.64%\n",
            "100% 9/9 [00:00<00:00, 65.58it/s]\n",
            "100% 2/2 [00:00<00:00, 136.74it/s]\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.347 | Train Acc: 91.45%\n",
            "\t Val. Loss: 0.813 |  Val. Acc: 70.86%\n",
            "100% 9/9 [00:00<00:00, 66.60it/s]\n",
            "100% 2/2 [00:00<00:00, 147.67it/s]\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.284 | Train Acc: 95.25%\n",
            "\t Val. Loss: 0.791 |  Val. Acc: 75.13%\n",
            "100% 9/9 [00:00<00:00, 65.68it/s]\n",
            "100% 2/2 [00:00<00:00, 150.11it/s]\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.293 | Train Acc: 92.60%\n",
            "\t Val. Loss: 0.771 |  Val. Acc: 74.56%\n",
            "100% 9/9 [00:00<00:00, 62.09it/s]\n",
            "100% 2/2 [00:00<00:00, 144.34it/s]\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.291 | Train Acc: 92.21%\n",
            "\t Val. Loss: 0.823 |  Val. Acc: 72.78%\n",
            "100% 9/9 [00:00<00:00, 67.12it/s]\n",
            "100% 2/2 [00:00<00:00, 147.93it/s]\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.252 | Train Acc: 94.71%\n",
            "\t Val. Loss: 0.803 |  Val. Acc: 71.64%\n",
            "100% 9/9 [00:00<00:00, 65.78it/s]\n",
            "100% 2/2 [00:00<00:00, 151.76it/s]\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.241 | Train Acc: 93.80%\n",
            "\t Val. Loss: 0.767 |  Val. Acc: 73.78%\n",
            "100% 9/9 [00:00<00:00, 65.63it/s]\n",
            "100% 2/2 [00:00<00:00, 148.93it/s]\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.231 | Train Acc: 94.82%\n",
            "\t Val. Loss: 0.855 |  Val. Acc: 70.86%\n",
            "100% 9/9 [00:00<00:00, 68.89it/s]\n",
            "100% 2/2 [00:00<00:00, 145.39it/s]\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.222 | Train Acc: 94.79%\n",
            "\t Val. Loss: 0.769 |  Val. Acc: 74.13%\n",
            "100% 9/9 [00:00<00:00, 67.76it/s]\n",
            "100% 2/2 [00:00<00:00, 146.70it/s]\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.190 | Train Acc: 95.42%\n",
            "\t Val. Loss: 0.818 |  Val. Acc: 75.13%\n",
            "100% 9/9 [00:00<00:00, 67.80it/s]\n",
            "100% 2/2 [00:00<00:00, 147.92it/s]\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.175 | Train Acc: 96.14%\n",
            "\t Val. Loss: 0.755 |  Val. Acc: 77.05%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4szDjOF303wC",
        "colab_type": "text"
      },
      "source": [
        "## CNNClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAVWP8U5kpmj",
        "colab_type": "text"
      },
      "source": [
        "### CNN2D Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2otPOBv06rZ",
        "colab_type": "code",
        "outputId": "b64bf9f2-8503-495a-8887-dce186ec5c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py -n 30 -m CNN2dClassifier --freeze-embeddings 1"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[DEBUG | train.py:268 -             <module>() ] Namespace(batch_size=64, bidirectional=True, dropout=0.7, embedding_dim=300, epochs=30, freeze_embeddings=1, hidden_dim=128, l2_regularization=0.001, learning_rate=0.001, model='CNN2dClassifier', model_location=None, n_layers=1, seed=1234, tag='multi')\n",
            "[DEBUG | train.py:269 -             <module>() ] Custom seed set with: 1234\n",
            "[INFO | train.py:271 -             <module>() ] Loading Dataset\n",
            "[DEBUG | datasetloader.py:81 -        get_iterators() ] Data Loaded Successfully!\n",
            "[INFO | vocab.py:386 -                cache() ] Loading vectors from .vector_cache/glove.6B.300d.txt.pt\n",
            "[DEBUG | datasetloader.py:95 -        get_iterators() ] Vocabulary Loaded\n",
            "[DEBUG | datasetloader.py:103 -        get_iterators() ] Created Iterators\n",
            "[INFO | train.py:278 -             <module>() ] Dataset Loaded Successfully\n",
            "[DEBUG | train.py:68 - initialize_new_model() ] Initializing Model\n",
            "[DEBUG | train.py:134 - initialize_new_model() ] Freeze Embeddings Value 1: False\n",
            "[INFO | train.py:140 - initialize_new_model() ] Model Initialized with 117,515 trainiable parameters\n",
            "[DEBUG | train.py:152 - initialize_new_model() ] Copied PreTrained Embeddings\n",
            "[INFO | train.py:303 -             <module>() ] CNN2dClassifier(\n",
            "  (embedding): Embedding(640, 300, padding_idx=1)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv2d(1, 64, kernel_size=(1, 300), stride=(1, 1))\n",
            "    (1): Conv2d(1, 64, kernel_size=(2, 300), stride=(1, 1))\n",
            "    (2): Conv2d(1, 64, kernel_size=(3, 300), stride=(1, 1))\n",
            "  )\n",
            "  (fc): Linear(in_features=192, out_features=11, bias=True)\n",
            "  (dropout): Dropout(p=0.7, inplace=False)\n",
            ")\n",
            "100% 9/9 [00:00<00:00, 106.04it/s]\n",
            "100% 2/2 [00:00<00:00, 292.33it/s]\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.512 | Train Acc: 16.73%\n",
            "\t Val. Loss: 1.978 |  Val. Acc: 28.93%\n",
            "100% 9/9 [00:00<00:00, 125.24it/s]\n",
            "100% 2/2 [00:00<00:00, 243.90it/s]\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.151 | Train Acc: 23.50%\n",
            "\t Val. Loss: 1.839 |  Val. Acc: 33.97%\n",
            "100% 9/9 [00:00<00:00, 123.03it/s]\n",
            "100% 2/2 [00:00<00:00, 224.00it/s]\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.016 | Train Acc: 29.23%\n",
            "\t Val. Loss: 1.759 |  Val. Acc: 37.25%\n",
            "100% 9/9 [00:00<00:00, 132.64it/s]\n",
            "100% 2/2 [00:00<00:00, 298.23it/s]\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.862 | Train Acc: 32.94%\n",
            "\t Val. Loss: 1.637 |  Val. Acc: 47.91%\n",
            "100% 9/9 [00:00<00:00, 133.21it/s]\n",
            "100% 2/2 [00:00<00:00, 296.02it/s]\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.781 | Train Acc: 35.32%\n",
            "\t Val. Loss: 1.645 |  Val. Acc: 41.15%\n",
            "100% 9/9 [00:00<00:00, 132.98it/s]\n",
            "100% 2/2 [00:00<00:00, 306.70it/s]\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.706 | Train Acc: 40.18%\n",
            "\t Val. Loss: 1.578 |  Val. Acc: 44.64%\n",
            "100% 9/9 [00:00<00:00, 128.00it/s]\n",
            "100% 2/2 [00:00<00:00, 309.45it/s]\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.650 | Train Acc: 38.86%\n",
            "\t Val. Loss: 1.499 |  Val. Acc: 50.68%\n",
            "100% 9/9 [00:00<00:00, 129.25it/s]\n",
            "100% 2/2 [00:00<00:00, 297.82it/s]\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.540 | Train Acc: 45.74%\n",
            "\t Val. Loss: 1.429 |  Val. Acc: 53.38%\n",
            "100% 9/9 [00:00<00:00, 129.67it/s]\n",
            "100% 2/2 [00:00<00:00, 291.39it/s]\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.456 | Train Acc: 48.04%\n",
            "\t Val. Loss: 1.402 |  Val. Acc: 51.46%\n",
            "100% 9/9 [00:00<00:00, 126.57it/s]\n",
            "100% 2/2 [00:00<00:00, 290.65it/s]\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.366 | Train Acc: 53.07%\n",
            "\t Val. Loss: 1.378 |  Val. Acc: 53.59%\n",
            "100% 9/9 [00:00<00:00, 123.97it/s]\n",
            "100% 2/2 [00:00<00:00, 267.18it/s]\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.285 | Train Acc: 55.05%\n",
            "\t Val. Loss: 1.304 |  Val. Acc: 56.50%\n",
            "100% 9/9 [00:00<00:00, 130.34it/s]\n",
            "100% 2/2 [00:00<00:00, 305.90it/s]\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.262 | Train Acc: 56.50%\n",
            "\t Val. Loss: 1.249 |  Val. Acc: 59.42%\n",
            "100% 9/9 [00:00<00:00, 129.84it/s]\n",
            "100% 2/2 [00:00<00:00, 247.76it/s]\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.161 | Train Acc: 62.55%\n",
            "\t Val. Loss: 1.173 |  Val. Acc: 59.84%\n",
            "100% 9/9 [00:00<00:00, 126.39it/s]\n",
            "100% 2/2 [00:00<00:00, 158.49it/s]\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.145 | Train Acc: 62.80%\n",
            "\t Val. Loss: 1.146 |  Val. Acc: 58.49%\n",
            "100% 9/9 [00:00<00:00, 128.71it/s]\n",
            "100% 2/2 [00:00<00:00, 306.50it/s]\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.051 | Train Acc: 66.87%\n",
            "\t Val. Loss: 1.065 |  Val. Acc: 63.32%\n",
            "100% 9/9 [00:00<00:00, 129.01it/s]\n",
            "100% 2/2 [00:00<00:00, 295.20it/s]\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.018 | Train Acc: 68.17%\n",
            "\t Val. Loss: 1.026 |  Val. Acc: 61.40%\n",
            "100% 9/9 [00:00<00:00, 131.21it/s]\n",
            "100% 2/2 [00:00<00:00, 281.96it/s]\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.940 | Train Acc: 69.26%\n",
            "\t Val. Loss: 0.969 |  Val. Acc: 66.45%\n",
            "100% 9/9 [00:00<00:00, 131.54it/s]\n",
            "100% 2/2 [00:00<00:00, 302.15it/s]\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.918 | Train Acc: 69.84%\n",
            "\t Val. Loss: 0.920 |  Val. Acc: 72.07%\n",
            "100% 9/9 [00:00<00:00, 128.10it/s]\n",
            "100% 2/2 [00:00<00:00, 287.62it/s]\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.865 | Train Acc: 70.75%\n",
            "\t Val. Loss: 0.883 |  Val. Acc: 73.06%\n",
            "100% 9/9 [00:00<00:00, 128.16it/s]\n",
            "100% 2/2 [00:00<00:00, 307.01it/s]\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.788 | Train Acc: 76.46%\n",
            "\t Val. Loss: 0.854 |  Val. Acc: 73.63%\n",
            "100% 9/9 [00:00<00:00, 126.15it/s]\n",
            "100% 2/2 [00:00<00:00, 288.38it/s]\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.776 | Train Acc: 74.51%\n",
            "\t Val. Loss: 0.823 |  Val. Acc: 75.76%\n",
            "100% 9/9 [00:00<00:00, 126.39it/s]\n",
            "100% 2/2 [00:00<00:00, 288.35it/s]\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.742 | Train Acc: 74.35%\n",
            "\t Val. Loss: 0.777 |  Val. Acc: 76.54%\n",
            "100% 9/9 [00:00<00:00, 129.52it/s]\n",
            "100% 2/2 [00:00<00:00, 298.12it/s]\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.692 | Train Acc: 79.28%\n",
            "\t Val. Loss: 0.755 |  Val. Acc: 77.32%\n",
            "100% 9/9 [00:00<00:00, 126.88it/s]\n",
            "100% 2/2 [00:00<00:00, 161.02it/s]\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.700 | Train Acc: 79.24%\n",
            "\t Val. Loss: 0.738 |  Val. Acc: 77.32%\n",
            "100% 9/9 [00:00<00:00, 124.94it/s]\n",
            "100% 2/2 [00:00<00:00, 268.12it/s]\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.620 | Train Acc: 81.78%\n",
            "\t Val. Loss: 0.698 |  Val. Acc: 79.46%\n",
            "100% 9/9 [00:00<00:00, 125.42it/s]\n",
            "100% 2/2 [00:00<00:00, 272.40it/s]\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.609 | Train Acc: 82.38%\n",
            "\t Val. Loss: 0.679 |  Val. Acc: 78.89%\n",
            "100% 9/9 [00:00<00:00, 128.62it/s]\n",
            "100% 2/2 [00:00<00:00, 219.14it/s]\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.552 | Train Acc: 83.81%\n",
            "\t Val. Loss: 0.646 |  Val. Acc: 80.03%\n",
            "100% 9/9 [00:00<00:00, 126.02it/s]\n",
            "100% 2/2 [00:00<00:00, 274.96it/s]\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.566 | Train Acc: 82.54%\n",
            "\t Val. Loss: 0.625 |  Val. Acc: 80.03%\n",
            "100% 9/9 [00:00<00:00, 130.33it/s]\n",
            "100% 2/2 [00:00<00:00, 308.82it/s]\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.538 | Train Acc: 84.79%\n",
            "\t Val. Loss: 0.624 |  Val. Acc: 79.46%\n",
            "100% 9/9 [00:00<00:00, 130.97it/s]\n",
            "100% 2/2 [00:00<00:00, 299.64it/s]\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.546 | Train Acc: 83.99%\n",
            "\t Val. Loss: 0.607 |  Val. Acc: 80.24%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6JUYoTTk19_",
        "colab_type": "text"
      },
      "source": [
        "### CNN1DClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukseycMBk4NK",
        "colab_type": "code",
        "outputId": "2cdc7d99-93fb-440d-fc22-ebd75138558e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py -n 30 -m CNN1dClassifier --freeze-embeddings 0"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[DEBUG | train.py:268 -             <module>() ] Namespace(batch_size=64, bidirectional=True, dropout=0.7, embedding_dim=300, epochs=30, freeze_embeddings=0, hidden_dim=256, l2_regularization=0.001, learning_rate=0.001, model='CNN1dClassifier', model_location=None, n_layers=2, seed=1234, tag='multi')\n",
            "[DEBUG | train.py:269 -             <module>() ] Custom seed set with: 1234\n",
            "[INFO | train.py:271 -             <module>() ] Loading Dataset\n",
            "[DEBUG | datasetloader.py:81 -        get_iterators() ] Data Loaded Successfully!\n",
            "[INFO | vocab.py:386 -                cache() ] Loading vectors from .vector_cache/glove.6B.300d.txt.pt\n",
            "[DEBUG | datasetloader.py:95 -        get_iterators() ] Vocabulary Loaded\n",
            "[DEBUG | datasetloader.py:103 -        get_iterators() ] Created Iterators\n",
            "[INFO | train.py:278 -             <module>() ] Dataset Loaded Successfully\n",
            "[DEBUG | train.py:68 - initialize_new_model() ] Initializing Model\n",
            "[DEBUG | train.py:134 - initialize_new_model() ] Freeze Embeddings Value 0: True\n",
            "[INFO | train.py:140 - initialize_new_model() ] Model Initialized with 561,911 trainiable parameters\n",
            "[DEBUG | train.py:152 - initialize_new_model() ] Copied PreTrained Embeddings\n",
            "[INFO | train.py:303 -             <module>() ] CNN1dClassifier(\n",
            "  (embedding): Embedding(661, 300, padding_idx=1)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(300, 100, kernel_size=(3,), stride=(1,))\n",
            "    (1): Conv1d(300, 100, kernel_size=(4,), stride=(1,))\n",
            "    (2): Conv1d(300, 100, kernel_size=(5,), stride=(1,))\n",
            "  )\n",
            "  (fc): Linear(in_features=300, out_features=11, bias=True)\n",
            "  (dropout): Dropout(p=0.7, inplace=False)\n",
            ")\n",
            "100% 9/9 [00:00<00:00, 118.72it/s]\n",
            "100% 2/2 [00:00<00:00, 374.46it/s]\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.518 | Train Acc: 20.98%\n",
            "\t Val. Loss: 2.094 |  Val. Acc: 18.12%\n",
            "100% 9/9 [00:00<00:00, 137.71it/s]\n",
            "100% 2/2 [00:00<00:00, 413.86it/s]\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.073 | Train Acc: 26.60%\n",
            "\t Val. Loss: 1.735 |  Val. Acc: 22.38%\n",
            "100% 9/9 [00:00<00:00, 141.31it/s]\n",
            "100% 2/2 [00:00<00:00, 415.11it/s]\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.816 | Train Acc: 36.30%\n",
            "\t Val. Loss: 1.721 |  Val. Acc: 26.86%\n",
            "100% 9/9 [00:00<00:00, 149.37it/s]\n",
            "100% 2/2 [00:00<00:00, 427.27it/s]\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.717 | Train Acc: 39.73%\n",
            "\t Val. Loss: 1.545 |  Val. Acc: 39.80%\n",
            "100% 9/9 [00:00<00:00, 154.58it/s]\n",
            "100% 2/2 [00:00<00:00, 433.16it/s]\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.459 | Train Acc: 49.82%\n",
            "\t Val. Loss: 1.466 |  Val. Acc: 47.19%\n",
            "100% 9/9 [00:00<00:00, 149.93it/s]\n",
            "100% 2/2 [00:00<00:00, 352.97it/s]\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.310 | Train Acc: 55.05%\n",
            "\t Val. Loss: 1.313 |  Val. Acc: 48.75%\n",
            "100% 9/9 [00:00<00:00, 161.52it/s]\n",
            "100% 2/2 [00:00<00:00, 266.94it/s]\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.221 | Train Acc: 56.37%\n",
            "\t Val. Loss: 1.184 |  Val. Acc: 61.55%\n",
            "100% 9/9 [00:00<00:00, 159.76it/s]\n",
            "100% 2/2 [00:00<00:00, 444.90it/s]\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.144 | Train Acc: 62.06%\n",
            "\t Val. Loss: 1.109 |  Val. Acc: 63.32%\n",
            "100% 9/9 [00:00<00:00, 165.00it/s]\n",
            "100% 2/2 [00:00<00:00, 455.73it/s]\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.010 | Train Acc: 67.93%\n",
            "\t Val. Loss: 1.083 |  Val. Acc: 61.55%\n",
            "100% 9/9 [00:00<00:00, 160.78it/s]\n",
            "100% 2/2 [00:00<00:00, 444.29it/s]\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.942 | Train Acc: 68.78%\n",
            "\t Val. Loss: 0.946 |  Val. Acc: 71.07%\n",
            "100% 9/9 [00:00<00:00, 163.31it/s]\n",
            "100% 2/2 [00:00<00:00, 450.30it/s]\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.866 | Train Acc: 71.84%\n",
            "\t Val. Loss: 0.867 |  Val. Acc: 79.60%\n",
            "100% 9/9 [00:00<00:00, 164.43it/s]\n",
            "100% 2/2 [00:00<00:00, 439.22it/s]\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.727 | Train Acc: 77.63%\n",
            "\t Val. Loss: 0.844 |  Val. Acc: 73.99%\n",
            "100% 9/9 [00:00<00:00, 155.38it/s]\n",
            "100% 2/2 [00:00<00:00, 438.16it/s]\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.669 | Train Acc: 79.76%\n",
            "\t Val. Loss: 0.758 |  Val. Acc: 74.77%\n",
            "100% 9/9 [00:00<00:00, 158.33it/s]\n",
            "100% 2/2 [00:00<00:00, 432.78it/s]\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.585 | Train Acc: 84.19%\n",
            "\t Val. Loss: 0.704 |  Val. Acc: 80.17%\n",
            "100% 9/9 [00:00<00:00, 161.87it/s]\n",
            "100% 2/2 [00:00<00:00, 447.97it/s]\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.559 | Train Acc: 85.08%\n",
            "\t Val. Loss: 0.632 |  Val. Acc: 82.88%\n",
            "100% 9/9 [00:00<00:00, 162.41it/s]\n",
            "100% 2/2 [00:00<00:00, 327.00it/s]\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.494 | Train Acc: 87.24%\n",
            "\t Val. Loss: 0.606 |  Val. Acc: 82.88%\n",
            "100% 9/9 [00:00<00:00, 157.42it/s]\n",
            "100% 2/2 [00:00<00:00, 384.92it/s]\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.469 | Train Acc: 86.53%\n",
            "\t Val. Loss: 0.586 |  Val. Acc: 81.74%\n",
            "100% 9/9 [00:00<00:00, 161.84it/s]\n",
            "100% 2/2 [00:00<00:00, 406.92it/s]\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.405 | Train Acc: 89.24%\n",
            "\t Val. Loss: 0.532 |  Val. Acc: 84.44%\n",
            "100% 9/9 [00:00<00:00, 162.57it/s]\n",
            "100% 2/2 [00:00<00:00, 444.69it/s]\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.425 | Train Acc: 88.33%\n",
            "\t Val. Loss: 0.514 |  Val. Acc: 84.44%\n",
            "100% 9/9 [00:00<00:00, 155.00it/s]\n",
            "100% 2/2 [00:00<00:00, 441.74it/s]\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.354 | Train Acc: 89.95%\n",
            "\t Val. Loss: 0.485 |  Val. Acc: 84.44%\n",
            "100% 9/9 [00:00<00:00, 154.75it/s]\n",
            "100% 2/2 [00:00<00:00, 421.22it/s]\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.334 | Train Acc: 89.91%\n",
            "\t Val. Loss: 0.486 |  Val. Acc: 84.44%\n",
            "100% 9/9 [00:00<00:00, 165.33it/s]\n",
            "100% 2/2 [00:00<00:00, 315.82it/s]\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.312 | Train Acc: 91.22%\n",
            "\t Val. Loss: 0.468 |  Val. Acc: 86.00%\n",
            "100% 9/9 [00:00<00:00, 160.77it/s]\n",
            "100% 2/2 [00:00<00:00, 431.93it/s]\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.286 | Train Acc: 92.21%\n",
            "\t Val. Loss: 0.430 |  Val. Acc: 89.27%\n",
            "100% 9/9 [00:00<00:00, 161.05it/s]\n",
            "100% 2/2 [00:00<00:00, 450.81it/s]\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.298 | Train Acc: 92.19%\n",
            "\t Val. Loss: 0.420 |  Val. Acc: 90.62%\n",
            "100% 9/9 [00:00<00:00, 156.48it/s]\n",
            "100% 2/2 [00:00<00:00, 441.32it/s]\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.311 | Train Acc: 92.19%\n",
            "\t Val. Loss: 0.409 |  Val. Acc: 90.05%\n",
            "100% 9/9 [00:00<00:00, 163.79it/s]\n",
            "100% 2/2 [00:00<00:00, 451.24it/s]\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.256 | Train Acc: 94.05%\n",
            "\t Val. Loss: 0.386 |  Val. Acc: 91.41%\n",
            "100% 9/9 [00:00<00:00, 161.52it/s]\n",
            "100% 2/2 [00:00<00:00, 445.44it/s]\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.246 | Train Acc: 93.47%\n",
            "\t Val. Loss: 0.371 |  Val. Acc: 90.62%\n",
            "100% 9/9 [00:00<00:00, 151.40it/s]\n",
            "100% 2/2 [00:00<00:00, 445.35it/s]\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.230 | Train Acc: 94.16%\n",
            "\t Val. Loss: 0.383 |  Val. Acc: 90.62%\n",
            "100% 9/9 [00:00<00:00, 164.58it/s]\n",
            "100% 2/2 [00:00<00:00, 449.24it/s]\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.219 | Train Acc: 94.53%\n",
            "\t Val. Loss: 0.375 |  Val. Acc: 90.62%\n",
            "100% 9/9 [00:00<00:00, 161.51it/s]\n",
            "100% 2/2 [00:00<00:00, 342.22it/s]\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.216 | Train Acc: 94.73%\n",
            "\t Val. Loss: 0.357 |  Val. Acc: 90.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzn_oZuLhKqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}