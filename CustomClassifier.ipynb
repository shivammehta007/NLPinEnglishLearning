{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CustomClassifier",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1PQCpSDGct4BTv3x9oH8GD1HIdNihgWj0",
      "authorship_tag": "ABX9TyOT3EV/dknhFxtjsEQDfN2/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivammehta007/QuestionGenerator/blob/master/CustomClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaCToCs_b4d1",
        "colab_type": "text"
      },
      "source": [
        "# Testing Classifier Deep Learning Architecture Based"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b9CNpxNblqe",
        "colab_type": "code",
        "outputId": "5cfd3fe7-a6dc-44b9-f6d5-db39dd283199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!rm -rf QuestionGenerator\n",
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "# repo_name = input('Repo name: ')\n",
        "\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/{0}/{2}.git'.format(user, password, 'QuestionGenerator')\n",
        "os.system(cmd_string)\n",
        "cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: shivammehta007\n",
            "Password: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW_iNs97b9e9",
        "colab_type": "code",
        "outputId": "62acb060-5cac-44bd-f02c-a63b51f0facd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!rm -rf QuestionGenerator/FromScratch\n",
        "%cd QuestionGenerator/classifier/\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/QuestionGenerator/classifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxftkthaPIGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf data/processed/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAatXS64cdOR",
        "colab_type": "code",
        "outputId": "6b370aa2-b79d-4a6a-b04a-20376ff25123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!python preprocessdata.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[DEBUG | preprocessdata.py:83 -           preprocess() ] Saving the file preprocessed files to : processed\n",
            "[DEBUG | preprocessdata.py:108 -             <module>() ] Utility Finished Execution in: 0.1638ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC0OzHqrpJEx",
        "colab_type": "code",
        "outputId": "5b4a94c9-f93a-4921-cff2-de578b277552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%ls -a"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m.\u001b[0m/   \u001b[01;34mconfig\u001b[0m/  datasetloader.py    \u001b[01;34mmodel\u001b[0m/             \u001b[01;34mtrained\u001b[0m/  utility.py\n",
            "\u001b[01;34m..\u001b[0m/  \u001b[01;34mdata\u001b[0m/    helperfunctions.py  preprocessdata.py  train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvlCMl-LJI1H",
        "colab_type": "text"
      },
      "source": [
        "## Download Glove from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzMieNSOJIFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "kaggle_info = json.load(open(\"/content/drive/My Drive/kaggle.json\"))\n",
        "os.environ['KAGGLE_USERNAME'] = kaggle_info[\"username\"]\n",
        "os.environ['KAGGLE_KEY'] = kaggle_info[\"key\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPfYshuJKWLJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1af9cbdc-439d-48e9-deef-33a429ab04ad"
      },
      "source": [
        "!kaggle datasets list --user thanakomsn"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                        title               size  lastUpdated          downloadCount  \n",
            "-------------------------  -----------------  -----  -------------------  -------------  \n",
            "thanakomsn/glove6b300dtxt  glove.6B.300d.txt  386MB  2017-11-28 07:19:43           2590  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oksPtO8LpYP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "39cf1c83-e2f4-4025-809d-20d8b0b5de76"
      },
      "source": [
        "!kaggle datasets download thanakomsn/glove6b300dtxt "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading glove6b300dtxt.zip to /content/QuestionGenerator/classifier\n",
            " 98% 379M/386M [00:06<00:00, 23.8MB/s]\n",
            "100% 386M/386M [00:07<00:00, 57.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRjCEyqsL_8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mkdir .vector_cache\n",
        "%mv glove6b300dtxt.zip .vector_cache/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haCNqeqHMUDs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c4a935e5-d2ab-47b6-af06-34dd56494195"
      },
      "source": [
        "!unzip .vector_cache/glove6b300dtxt.zip\n",
        "%ls -a .vector_cache/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  .vector_cache/glove6b300dtxt.zip\n",
            "  inflating: glove.6B.300d.txt       \n",
            "\u001b[0m\u001b[01;34m.\u001b[0m/  \u001b[01;34m..\u001b[0m/  glove6b300dtxt.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nhgkJx_ne2G",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIWmWDYBxNI7",
        "colab_type": "code",
        "outputId": "175ba263-f994-4c67-ffe6-71ad4f9350e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "!python train.py -h"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: train.py [-h] [-s SEED] [-loc MODEL_LOCATION] [-b BIDIRECTIONAL]\n",
            "                [-d DROPOUT] [-e EMBEDDING_DIM] [-hd HIDDEN_DIM] [-l N_LAYERS]\n",
            "                [-lr LEARNING_RATE] [-n EPOCHS] [-batch BATCH_SIZE]\n",
            "                [-f FREEZE_EMBEDDINGS] [-t {multi,single}]\n",
            "                [-l2 L2_REGULARIZATION]\n",
            "                [-m {RNNHiddenClassifier,RNNMaxpoolClassifier,CNN2dClassifier,CNN1dClassifier}]\n",
            "\n",
            "Utility to train the Model\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -s SEED, --seed SEED  Set custom seed for reproducibility\n",
            "  -loc MODEL_LOCATION, --model-location MODEL_LOCATION\n",
            "                        Give an already trained model location to use and\n",
            "                        train more epochs on it\n",
            "  -b BIDIRECTIONAL, --bidirectional BIDIRECTIONAL\n",
            "                        Makes the model Bidirectional\n",
            "  -d DROPOUT, --dropout DROPOUT\n",
            "                        Dropout count for the model\n",
            "  -e EMBEDDING_DIM, --embedding-dim EMBEDDING_DIM\n",
            "                        Embedding Dimensions\n",
            "  -hd HIDDEN_DIM, --hidden-dim HIDDEN_DIM\n",
            "                        Hidden dimensions of the RNN\n",
            "  -l N_LAYERS, --n-layers N_LAYERS\n",
            "                        Number of layers in RNN\n",
            "  -lr LEARNING_RATE, --learning-rate LEARNING_RATE\n",
            "                        Learning rate of Adam Optimizer\n",
            "  -n EPOCHS, --epochs EPOCHS\n",
            "                        Number of Epochs to train model\n",
            "  -batch BATCH_SIZE, --batch_size BATCH_SIZE\n",
            "                        Number of Epochs to train model\n",
            "  -f FREEZE_EMBEDDINGS, --freeze-embeddings FREEZE_EMBEDDINGS\n",
            "                        Freeze Embeddings of Model\n",
            "  -t {multi,single}, --tag {multi,single}\n",
            "                        Use two different dataset type, multi type and single\n",
            "                        type where all are merged into same key\n",
            "  -l2 L2_REGULARIZATION, --l2-regularization L2_REGULARIZATION\n",
            "                        Value of alpha in l2 regularization 0 means no\n",
            "                        regularization\n",
            "  -m {RNNHiddenClassifier,RNNMaxpoolClassifier,CNN2dClassifier,CNN1dClassifier}, --model {RNNHiddenClassifier,RNNMaxpoolClassifier,CNN2dClassifier,CNN1dClassifier}\n",
            "                        select the classifier to train on\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd6-Cp6UiuT8",
        "colab_type": "text"
      },
      "source": [
        "## RNNHiddenClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNHpPoyGcz9H",
        "colab_type": "code",
        "outputId": "62675fb0-e34f-4bb5-c399-853c7568c10a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py -n 30 --model RNNHiddenClassifier\n",
        "# 2,725,387\n",
        "# 2,794,387"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[DEBUG | train.py:268 -             <module>() ] Namespace(batch_size=64, bidirectional=True, dropout=0.7, embedding_dim=300, epochs=30, freeze_embeddings=1, hidden_dim=256, l2_regularization=0.001, learning_rate=0.001, model='RNNHiddenClassifier', model_location=None, n_layers=2, seed=1234, tag='multi')\n",
            "[DEBUG | train.py:269 -             <module>() ] Custom seed set with: 1234\n",
            "[INFO | train.py:271 -             <module>() ] Loading Dataset\n",
            "[DEBUG | datasetloader.py:81 -        get_iterators() ] Data Loaded Successfully!\n",
            "[INFO | vocab.py:386 -                cache() ] Loading vectors from .vector_cache/glove.6B.300d.txt.pt\n",
            "[DEBUG | datasetloader.py:95 -        get_iterators() ] Vocabulary Loaded\n",
            "[DEBUG | datasetloader.py:103 -        get_iterators() ] Created Iterators\n",
            "[INFO | train.py:278 -             <module>() ] Dataset Loaded Successfully\n",
            "[DEBUG | train.py:68 - initialize_new_model() ] Initializing Model\n",
            "[DEBUG | train.py:134 - initialize_new_model() ] Freeze Embeddings Value 1: False\n",
            "[INFO | train.py:140 - initialize_new_model() ] Model Initialized with 2,725,387 trainiable parameters\n",
            "[DEBUG | train.py:152 - initialize_new_model() ] Copied PreTrained Embeddings\n",
            "[INFO | train.py:303 -             <module>() ] RNNHiddenClassifier(\n",
            "  (embedding): Embedding(636, 300, padding_idx=1)\n",
            "  (rnn): LSTM(300, 256, num_layers=2, dropout=0.7, bidirectional=True)\n",
            "  (fc): Linear(in_features=512, out_features=11, bias=True)\n",
            "  (dropout): Dropout(p=0.7, inplace=False)\n",
            ")\n",
            "100% 9/9 [00:00<00:00, 48.39it/s]\n",
            "100% 2/2 [00:00<00:00, 172.05it/s]\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.352 | Train Acc: 14.17%\n",
            "\t Val. Loss: 2.208 |  Val. Acc: 27.58%\n",
            "100% 9/9 [00:00<00:00, 63.32it/s]\n",
            "100% 2/2 [00:00<00:00, 175.01it/s]\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.210 | Train Acc: 20.03%\n",
            "\t Val. Loss: 2.099 |  Val. Acc: 21.81%\n",
            "100% 9/9 [00:00<00:00, 65.60it/s]\n",
            "100% 2/2 [00:00<00:00, 175.80it/s]\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.038 | Train Acc: 25.97%\n",
            "\t Val. Loss: 1.937 |  Val. Acc: 35.33%\n",
            "100% 9/9 [00:00<00:00, 65.76it/s]\n",
            "100% 2/2 [00:00<00:00, 168.45it/s]\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.884 | Train Acc: 29.79%\n",
            "\t Val. Loss: 1.868 |  Val. Acc: 34.76%\n",
            "100% 9/9 [00:00<00:00, 64.05it/s]\n",
            "100% 2/2 [00:00<00:00, 176.02it/s]\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.792 | Train Acc: 31.42%\n",
            "\t Val. Loss: 1.788 |  Val. Acc: 36.11%\n",
            "100% 9/9 [00:00<00:00, 66.17it/s]\n",
            "100% 2/2 [00:00<00:00, 173.96it/s]\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.664 | Train Acc: 37.24%\n",
            "\t Val. Loss: 1.674 |  Val. Acc: 37.46%\n",
            "100% 9/9 [00:00<00:00, 64.36it/s]\n",
            "100% 2/2 [00:00<00:00, 168.66it/s]\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.507 | Train Acc: 42.55%\n",
            "\t Val. Loss: 1.522 |  Val. Acc: 41.79%\n",
            "100% 9/9 [00:00<00:00, 65.27it/s]\n",
            "100% 2/2 [00:00<00:00, 129.69it/s]\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.404 | Train Acc: 48.71%\n",
            "\t Val. Loss: 1.470 |  Val. Acc: 49.81%\n",
            "100% 9/9 [00:00<00:00, 62.20it/s]\n",
            "100% 2/2 [00:00<00:00, 169.59it/s]\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.153 | Train Acc: 61.25%\n",
            "\t Val. Loss: 1.401 |  Val. Acc: 51.94%\n",
            "100% 9/9 [00:00<00:00, 65.08it/s]\n",
            "100% 2/2 [00:00<00:00, 178.69it/s]\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.055 | Train Acc: 60.95%\n",
            "\t Val. Loss: 1.241 |  Val. Acc: 53.86%\n",
            "100% 9/9 [00:00<00:00, 64.21it/s]\n",
            "100% 2/2 [00:00<00:00, 169.75it/s]\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.851 | Train Acc: 71.02%\n",
            "\t Val. Loss: 1.167 |  Val. Acc: 59.48%\n",
            "100% 9/9 [00:00<00:00, 65.75it/s]\n",
            "100% 2/2 [00:00<00:00, 124.88it/s]\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.821 | Train Acc: 69.17%\n",
            "\t Val. Loss: 1.015 |  Val. Acc: 66.03%\n",
            "100% 9/9 [00:00<00:00, 64.34it/s]\n",
            "100% 2/2 [00:00<00:00, 176.34it/s]\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.723 | Train Acc: 74.16%\n",
            "\t Val. Loss: 1.000 |  Val. Acc: 58.91%\n",
            "100% 9/9 [00:00<00:00, 65.86it/s]\n",
            "100% 2/2 [00:00<00:00, 169.04it/s]\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.678 | Train Acc: 75.20%\n",
            "\t Val. Loss: 0.903 |  Val. Acc: 65.88%\n",
            "100% 9/9 [00:00<00:00, 64.95it/s]\n",
            "100% 2/2 [00:00<00:00, 141.40it/s]\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.587 | Train Acc: 80.54%\n",
            "\t Val. Loss: 0.948 |  Val. Acc: 67.80%\n",
            "100% 9/9 [00:00<00:00, 63.89it/s]\n",
            "100% 2/2 [00:00<00:00, 151.88it/s]\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.545 | Train Acc: 79.98%\n",
            "\t Val. Loss: 0.880 |  Val. Acc: 71.28%\n",
            "100% 9/9 [00:00<00:00, 65.25it/s]\n",
            "100% 2/2 [00:00<00:00, 169.35it/s]\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.531 | Train Acc: 83.23%\n",
            "\t Val. Loss: 1.066 |  Val. Acc: 61.97%\n",
            "100% 9/9 [00:00<00:00, 65.18it/s]\n",
            "100% 2/2 [00:00<00:00, 179.83it/s]\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.487 | Train Acc: 83.73%\n",
            "\t Val. Loss: 0.845 |  Val. Acc: 70.14%\n",
            "100% 9/9 [00:00<00:00, 64.07it/s]\n",
            "100% 2/2 [00:00<00:00, 182.93it/s]\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.482 | Train Acc: 83.47%\n",
            "\t Val. Loss: 0.914 |  Val. Acc: 70.14%\n",
            "100% 9/9 [00:00<00:00, 64.42it/s]\n",
            "100% 2/2 [00:00<00:00, 178.98it/s]\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.457 | Train Acc: 84.23%\n",
            "\t Val. Loss: 0.732 |  Val. Acc: 71.28%\n",
            "100% 9/9 [00:00<00:00, 65.66it/s]\n",
            "100% 2/2 [00:00<00:00, 166.38it/s]\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.416 | Train Acc: 85.66%\n",
            "\t Val. Loss: 0.959 |  Val. Acc: 69.57%\n",
            "100% 9/9 [00:00<00:00, 65.20it/s]\n",
            "100% 2/2 [00:00<00:00, 167.73it/s]\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.412 | Train Acc: 84.88%\n",
            "\t Val. Loss: 0.901 |  Val. Acc: 68.58%\n",
            "100% 9/9 [00:00<00:00, 66.24it/s]\n",
            "100% 2/2 [00:00<00:00, 171.71it/s]\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.382 | Train Acc: 85.18%\n",
            "\t Val. Loss: 0.956 |  Val. Acc: 65.31%\n",
            "100% 9/9 [00:00<00:00, 65.12it/s]\n",
            "100% 2/2 [00:00<00:00, 159.22it/s]\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.411 | Train Acc: 86.22%\n",
            "\t Val. Loss: 1.003 |  Val. Acc: 61.34%\n",
            "100% 9/9 [00:00<00:00, 63.54it/s]\n",
            "100% 2/2 [00:00<00:00, 175.36it/s]\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.359 | Train Acc: 87.07%\n",
            "\t Val. Loss: 0.818 |  Val. Acc: 69.57%\n",
            "100% 9/9 [00:00<00:00, 66.23it/s]\n",
            "100% 2/2 [00:00<00:00, 166.22it/s]\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.325 | Train Acc: 89.02%\n",
            "\t Val. Loss: 0.744 |  Val. Acc: 70.14%\n",
            "100% 9/9 [00:00<00:00, 66.81it/s]\n",
            "100% 2/2 [00:00<00:00, 175.72it/s]\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.300 | Train Acc: 90.45%\n",
            "\t Val. Loss: 0.897 |  Val. Acc: 68.01%\n",
            "100% 9/9 [00:00<00:00, 65.51it/s]\n",
            "100% 2/2 [00:00<00:00, 156.40it/s]\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.321 | Train Acc: 88.85%\n",
            "\t Val. Loss: 0.734 |  Val. Acc: 73.63%\n",
            "100% 9/9 [00:00<00:00, 63.77it/s]\n",
            "100% 2/2 [00:00<00:00, 143.65it/s]\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.357 | Train Acc: 88.09%\n",
            "\t Val. Loss: 0.839 |  Val. Acc: 72.28%\n",
            "100% 9/9 [00:00<00:00, 65.29it/s]\n",
            "100% 2/2 [00:00<00:00, 176.86it/s]\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.277 | Train Acc: 91.47%\n",
            "\t Val. Loss: 1.018 |  Val. Acc: 64.46%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hQXMDrqis75",
        "colab_type": "text"
      },
      "source": [
        "## RNNMaxpoolClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7QpzdKfir48",
        "colab_type": "code",
        "outputId": "ccd948e9-f8b7-4529-9f65-0a313c243c45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py -n 30 -m RNNMaxpoolClassifier --freeze-embeddings 0"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[DEBUG | train.py:268 -             <module>() ] Namespace(batch_size=64, bidirectional=True, dropout=0.7, embedding_dim=300, epochs=30, freeze_embeddings=0, hidden_dim=256, l2_regularization=0.001, learning_rate=0.001, model='RNNMaxpoolClassifier', model_location=None, n_layers=2, seed=1234, tag='multi')\n",
            "[DEBUG | train.py:269 -             <module>() ] Custom seed set with: 1234\n",
            "[INFO | train.py:271 -             <module>() ] Loading Dataset\n",
            "[DEBUG | datasetloader.py:81 -        get_iterators() ] Data Loaded Successfully!\n",
            "[INFO | vocab.py:386 -                cache() ] Loading vectors from .vector_cache/glove.6B.300d.txt.pt\n",
            "[DEBUG | datasetloader.py:95 -        get_iterators() ] Vocabulary Loaded\n",
            "[DEBUG | datasetloader.py:103 -        get_iterators() ] Created Iterators\n",
            "[INFO | train.py:278 -             <module>() ] Dataset Loaded Successfully\n",
            "[DEBUG | train.py:68 - initialize_new_model() ] Initializing Model\n",
            "[DEBUG | train.py:134 - initialize_new_model() ] Freeze Embeddings Value 0: True\n",
            "[INFO | train.py:140 - initialize_new_model() ] Model Initialized with 2,913,371 trainiable parameters\n",
            "[DEBUG | train.py:152 - initialize_new_model() ] Copied PreTrained Embeddings\n",
            "[INFO | train.py:303 -             <module>() ] RNNMaxpoolClassifier(\n",
            "  (embedding): Embedding(636, 300, padding_idx=1)\n",
            "  (rnn): LSTM(300, 256, num_layers=2, dropout=0.7, bidirectional=True)\n",
            "  (fc): Linear(in_features=256, out_features=11, bias=True)\n",
            "  (dropout): Dropout(p=0.7, inplace=False)\n",
            ")\n",
            "100% 9/9 [00:00<00:00, 45.13it/s]\n",
            "100% 2/2 [00:00<00:00, 123.83it/s]\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.331 | Train Acc: 17.77%\n",
            "\t Val. Loss: 2.175 |  Val. Acc: 19.62%\n",
            "100% 9/9 [00:00<00:00, 57.03it/s]\n",
            "100% 2/2 [00:00<00:00, 175.75it/s]\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.193 | Train Acc: 24.99%\n",
            "\t Val. Loss: 2.089 |  Val. Acc: 23.16%\n",
            "100% 9/9 [00:00<00:00, 58.90it/s]\n",
            "100% 2/2 [00:00<00:00, 181.71it/s]\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.092 | Train Acc: 27.19%\n",
            "\t Val. Loss: 1.963 |  Val. Acc: 37.88%\n",
            "100% 9/9 [00:00<00:00, 58.70it/s]\n",
            "100% 2/2 [00:00<00:00, 180.93it/s]\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.931 | Train Acc: 34.22%\n",
            "\t Val. Loss: 1.877 |  Val. Acc: 35.33%\n",
            "100% 9/9 [00:00<00:00, 57.61it/s]\n",
            "100% 2/2 [00:00<00:00, 186.51it/s]\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.782 | Train Acc: 35.45%\n",
            "\t Val. Loss: 1.794 |  Val. Acc: 33.97%\n",
            "100% 9/9 [00:00<00:00, 58.79it/s]\n",
            "100% 2/2 [00:00<00:00, 184.49it/s]\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.667 | Train Acc: 39.75%\n",
            "\t Val. Loss: 1.664 |  Val. Acc: 37.67%\n",
            "100% 9/9 [00:00<00:00, 59.14it/s]\n",
            "100% 2/2 [00:00<00:00, 181.76it/s]\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.533 | Train Acc: 46.91%\n",
            "\t Val. Loss: 1.551 |  Val. Acc: 44.85%\n",
            "100% 9/9 [00:00<00:00, 58.68it/s]\n",
            "100% 2/2 [00:00<00:00, 173.74it/s]\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.340 | Train Acc: 51.01%\n",
            "\t Val. Loss: 1.514 |  Val. Acc: 46.68%\n",
            "100% 9/9 [00:00<00:00, 56.80it/s]\n",
            "100% 2/2 [00:00<00:00, 181.36it/s]\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.167 | Train Acc: 61.60%\n",
            "\t Val. Loss: 1.434 |  Val. Acc: 51.73%\n",
            "100% 9/9 [00:00<00:00, 59.87it/s]\n",
            "100% 2/2 [00:00<00:00, 178.95it/s]\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.025 | Train Acc: 68.00%\n",
            "\t Val. Loss: 1.184 |  Val. Acc: 62.96%\n",
            "100% 9/9 [00:00<00:00, 57.37it/s]\n",
            "100% 2/2 [00:00<00:00, 178.60it/s]\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.807 | Train Acc: 74.49%\n",
            "\t Val. Loss: 1.047 |  Val. Acc: 66.45%\n",
            "100% 9/9 [00:00<00:00, 58.85it/s]\n",
            "100% 2/2 [00:00<00:00, 183.23it/s]\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.669 | Train Acc: 79.26%\n",
            "\t Val. Loss: 1.080 |  Val. Acc: 58.91%\n",
            "100% 9/9 [00:00<00:00, 59.41it/s]\n",
            "100% 2/2 [00:00<00:00, 190.36it/s]\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.599 | Train Acc: 81.48%\n",
            "\t Val. Loss: 0.985 |  Val. Acc: 65.67%\n",
            "100% 9/9 [00:00<00:00, 59.74it/s]\n",
            "100% 2/2 [00:00<00:00, 182.31it/s]\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.502 | Train Acc: 85.42%\n",
            "\t Val. Loss: 0.976 |  Val. Acc: 64.32%\n",
            "100% 9/9 [00:00<00:00, 58.10it/s]\n",
            "100% 2/2 [00:00<00:00, 178.69it/s]\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.449 | Train Acc: 85.96%\n",
            "\t Val. Loss: 0.884 |  Val. Acc: 68.58%\n",
            "100% 9/9 [00:00<00:00, 57.26it/s]\n",
            "100% 2/2 [00:00<00:00, 177.08it/s]\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.385 | Train Acc: 89.57%\n",
            "\t Val. Loss: 0.795 |  Val. Acc: 74.20%\n",
            "100% 9/9 [00:00<00:00, 59.50it/s]\n",
            "100% 2/2 [00:00<00:00, 185.91it/s]\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.383 | Train Acc: 90.76%\n",
            "\t Val. Loss: 0.962 |  Val. Acc: 63.53%\n",
            "100% 9/9 [00:00<00:00, 60.01it/s]\n",
            "100% 2/2 [00:00<00:00, 183.47it/s]\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.306 | Train Acc: 90.61%\n",
            "\t Val. Loss: 0.880 |  Val. Acc: 70.92%\n",
            "100% 9/9 [00:00<00:00, 60.05it/s]\n",
            "100% 2/2 [00:00<00:00, 157.99it/s]\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.316 | Train Acc: 90.28%\n",
            "\t Val. Loss: 0.843 |  Val. Acc: 68.58%\n",
            "100% 9/9 [00:00<00:00, 60.11it/s]\n",
            "100% 2/2 [00:00<00:00, 173.39it/s]\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.292 | Train Acc: 92.34%\n",
            "\t Val. Loss: 0.976 |  Val. Acc: 65.46%\n",
            "100% 9/9 [00:00<00:00, 59.34it/s]\n",
            "100% 2/2 [00:00<00:00, 171.01it/s]\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.268 | Train Acc: 92.95%\n",
            "\t Val. Loss: 0.791 |  Val. Acc: 69.36%\n",
            "100% 9/9 [00:00<00:00, 57.90it/s]\n",
            "100% 2/2 [00:00<00:00, 144.63it/s]\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.302 | Train Acc: 91.00%\n",
            "\t Val. Loss: 0.866 |  Val. Acc: 67.02%\n",
            "100% 9/9 [00:00<00:00, 59.65it/s]\n",
            "100% 2/2 [00:00<00:00, 186.27it/s]\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.218 | Train Acc: 95.18%\n",
            "\t Val. Loss: 0.724 |  Val. Acc: 70.71%\n",
            "100% 9/9 [00:00<00:00, 57.06it/s]\n",
            "100% 2/2 [00:00<00:00, 163.89it/s]\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.239 | Train Acc: 93.47%\n",
            "\t Val. Loss: 0.797 |  Val. Acc: 67.59%\n",
            "100% 9/9 [00:00<00:00, 56.93it/s]\n",
            "100% 2/2 [00:00<00:00, 178.37it/s]\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.186 | Train Acc: 94.92%\n",
            "\t Val. Loss: 0.819 |  Val. Acc: 71.28%\n",
            "100% 9/9 [00:00<00:00, 59.77it/s]\n",
            "100% 2/2 [00:00<00:00, 178.87it/s]\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.196 | Train Acc: 93.49%\n",
            "\t Val. Loss: 0.843 |  Val. Acc: 68.58%\n",
            "100% 9/9 [00:00<00:00, 59.42it/s]\n",
            "100% 2/2 [00:00<00:00, 183.69it/s]\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.153 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.841 |  Val. Acc: 68.58%\n",
            "100% 9/9 [00:00<00:00, 59.08it/s]\n",
            "100% 2/2 [00:00<00:00, 177.82it/s]\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.156 | Train Acc: 96.77%\n",
            "\t Val. Loss: 0.808 |  Val. Acc: 70.35%\n",
            "100% 9/9 [00:00<00:00, 60.28it/s]\n",
            "100% 2/2 [00:00<00:00, 184.73it/s]\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.192 | Train Acc: 95.21%\n",
            "\t Val. Loss: 0.797 |  Val. Acc: 68.58%\n",
            "100% 9/9 [00:00<00:00, 59.32it/s]\n",
            "100% 2/2 [00:00<00:00, 179.62it/s]\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.156 | Train Acc: 96.31%\n",
            "\t Val. Loss: 0.811 |  Val. Acc: 71.28%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4szDjOF303wC",
        "colab_type": "text"
      },
      "source": [
        "## CNNClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAVWP8U5kpmj",
        "colab_type": "text"
      },
      "source": [
        "### CNN2D Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2otPOBv06rZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c38dc9f2-ae30-40e5-fced-6e04eb3b6c4e"
      },
      "source": [
        "!python train.py -n 30 -m CNN2dClassifier --freeze-embeddings 0"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[DEBUG | train.py:268 -             <module>() ] Namespace(batch_size=64, bidirectional=True, dropout=0.7, embedding_dim=300, epochs=30, freeze_embeddings=0, hidden_dim=256, l2_regularization=0.001, learning_rate=0.001, model='CNN2dClassifier', model_location=None, n_layers=2, seed=1234, tag='multi')\n",
            "[DEBUG | train.py:269 -             <module>() ] Custom seed set with: 1234\n",
            "[INFO | train.py:271 -             <module>() ] Loading Dataset\n",
            "[DEBUG | datasetloader.py:81 -        get_iterators() ] Data Loaded Successfully!\n",
            "[INFO | vocab.py:386 -                cache() ] Loading vectors from .vector_cache/glove.6B.300d.txt.pt\n",
            "[DEBUG | datasetloader.py:95 -        get_iterators() ] Vocabulary Loaded\n",
            "[DEBUG | datasetloader.py:103 -        get_iterators() ] Created Iterators\n",
            "[INFO | train.py:278 -             <module>() ] Dataset Loaded Successfully\n",
            "[DEBUG | train.py:68 - initialize_new_model() ] Initializing Model\n",
            "[DEBUG | train.py:134 - initialize_new_model() ] Freeze Embeddings Value 0: True\n",
            "[INFO | train.py:140 - initialize_new_model() ] Model Initialized with 308,315 trainiable parameters\n",
            "[DEBUG | train.py:152 - initialize_new_model() ] Copied PreTrained Embeddings\n",
            "[INFO | train.py:303 -             <module>() ] CNN2dClassifier(\n",
            "  (embedding): Embedding(636, 300, padding_idx=1)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv2d(1, 64, kernel_size=(1, 300), stride=(1, 1))\n",
            "    (1): Conv2d(1, 64, kernel_size=(2, 300), stride=(1, 1))\n",
            "    (2): Conv2d(1, 64, kernel_size=(3, 300), stride=(1, 1))\n",
            "  )\n",
            "  (fc): Linear(in_features=192, out_features=11, bias=True)\n",
            "  (dropout): Dropout(p=0.7, inplace=False)\n",
            ")\n",
            "100% 9/9 [00:00<00:00, 58.38it/s]\n",
            "100% 2/2 [00:00<00:00, 432.25it/s]\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.507 | Train Acc: 16.58%\n",
            "\t Val. Loss: 1.936 |  Val. Acc: 32.41%\n",
            "100% 9/9 [00:00<00:00, 63.51it/s]\n",
            "100% 2/2 [00:00<00:00, 418.70it/s]\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.091 | Train Acc: 25.02%\n",
            "\t Val. Loss: 1.890 |  Val. Acc: 23.37%\n",
            "100% 9/9 [00:00<00:00, 64.61it/s]\n",
            "100% 2/2 [00:00<00:00, 494.87it/s]\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.943 | Train Acc: 28.38%\n",
            "\t Val. Loss: 1.826 |  Val. Acc: 34.54%\n",
            "100% 9/9 [00:00<00:00, 66.76it/s]\n",
            "100% 2/2 [00:00<00:00, 386.96it/s]\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.834 | Train Acc: 35.67%\n",
            "\t Val. Loss: 1.755 |  Val. Acc: 36.89%\n",
            "100% 9/9 [00:00<00:00, 66.39it/s]\n",
            "100% 2/2 [00:00<00:00, 481.47it/s]\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.734 | Train Acc: 37.30%\n",
            "\t Val. Loss: 1.718 |  Val. Acc: 40.79%\n",
            "100% 9/9 [00:00<00:00, 66.25it/s]\n",
            "100% 2/2 [00:00<00:00, 521.91it/s]\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.649 | Train Acc: 41.29%\n",
            "\t Val. Loss: 1.674 |  Val. Acc: 40.79%\n",
            "100% 9/9 [00:00<00:00, 66.81it/s]\n",
            "100% 2/2 [00:00<00:00, 480.09it/s]\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.576 | Train Acc: 42.18%\n",
            "\t Val. Loss: 1.616 |  Val. Acc: 43.92%\n",
            "100% 9/9 [00:00<00:00, 66.86it/s]\n",
            "100% 2/2 [00:00<00:00, 357.40it/s]\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.541 | Train Acc: 43.98%\n",
            "\t Val. Loss: 1.563 |  Val. Acc: 44.28%\n",
            "100% 9/9 [00:00<00:00, 65.29it/s]\n",
            "100% 2/2 [00:00<00:00, 465.46it/s]\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.422 | Train Acc: 48.82%\n",
            "\t Val. Loss: 1.489 |  Val. Acc: 49.54%\n",
            "100% 9/9 [00:00<00:00, 66.07it/s]\n",
            "100% 2/2 [00:00<00:00, 499.98it/s]\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.354 | Train Acc: 54.22%\n",
            "\t Val. Loss: 1.460 |  Val. Acc: 52.09%\n",
            "100% 9/9 [00:00<00:00, 64.70it/s]\n",
            "100% 2/2 [00:00<00:00, 501.08it/s]\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.297 | Train Acc: 55.46%\n",
            "\t Val. Loss: 1.363 |  Val. Acc: 59.48%\n",
            "100% 9/9 [00:00<00:00, 66.85it/s]\n",
            "100% 2/2 [00:00<00:00, 490.16it/s]\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.219 | Train Acc: 60.38%\n",
            "\t Val. Loss: 1.282 |  Val. Acc: 58.49%\n",
            "100% 9/9 [00:00<00:00, 65.57it/s]\n",
            "100% 2/2 [00:00<00:00, 491.22it/s]\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.161 | Train Acc: 61.49%\n",
            "\t Val. Loss: 1.235 |  Val. Acc: 56.57%\n",
            "100% 9/9 [00:00<00:00, 66.09it/s]\n",
            "100% 2/2 [00:00<00:00, 424.83it/s]\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.104 | Train Acc: 65.07%\n",
            "\t Val. Loss: 1.147 |  Val. Acc: 61.04%\n",
            "100% 9/9 [00:00<00:00, 65.37it/s]\n",
            "100% 2/2 [00:00<00:00, 502.82it/s]\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.052 | Train Acc: 65.96%\n",
            "\t Val. Loss: 1.088 |  Val. Acc: 62.96%\n",
            "100% 9/9 [00:00<00:00, 66.94it/s]\n",
            "100% 2/2 [00:00<00:00, 465.67it/s]\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.002 | Train Acc: 68.63%\n",
            "\t Val. Loss: 1.041 |  Val. Acc: 63.75%\n",
            "100% 9/9 [00:00<00:00, 66.17it/s]\n",
            "100% 2/2 [00:00<00:00, 397.58it/s]\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.930 | Train Acc: 70.75%\n",
            "\t Val. Loss: 0.995 |  Val. Acc: 65.10%\n",
            "100% 9/9 [00:00<00:00, 65.86it/s]\n",
            "100% 2/2 [00:00<00:00, 491.05it/s]\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.877 | Train Acc: 71.82%\n",
            "\t Val. Loss: 0.927 |  Val. Acc: 71.71%\n",
            "100% 9/9 [00:00<00:00, 67.48it/s]\n",
            "100% 2/2 [00:00<00:00, 468.85it/s]\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.819 | Train Acc: 72.64%\n",
            "\t Val. Loss: 0.897 |  Val. Acc: 72.49%\n",
            "100% 9/9 [00:00<00:00, 66.68it/s]\n",
            "100% 2/2 [00:00<00:00, 361.14it/s]\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.769 | Train Acc: 77.15%\n",
            "\t Val. Loss: 0.839 |  Val. Acc: 71.71%\n",
            "100% 9/9 [00:00<00:00, 63.28it/s]\n",
            "100% 2/2 [00:00<00:00, 492.81it/s]\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.759 | Train Acc: 75.44%\n",
            "\t Val. Loss: 0.787 |  Val. Acc: 75.97%\n",
            "100% 9/9 [00:00<00:00, 66.28it/s]\n",
            "100% 2/2 [00:00<00:00, 522.49it/s]\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.690 | Train Acc: 79.04%\n",
            "\t Val. Loss: 0.746 |  Val. Acc: 76.75%\n",
            "100% 9/9 [00:00<00:00, 65.81it/s]\n",
            "100% 2/2 [00:00<00:00, 361.52it/s]\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.680 | Train Acc: 82.01%\n",
            "\t Val. Loss: 0.700 |  Val. Acc: 78.67%\n",
            "100% 9/9 [00:00<00:00, 66.85it/s]\n",
            "100% 2/2 [00:00<00:00, 498.22it/s]\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.638 | Train Acc: 80.91%\n",
            "\t Val. Loss: 0.676 |  Val. Acc: 80.81%\n",
            "100% 9/9 [00:00<00:00, 66.64it/s]\n",
            "100% 2/2 [00:00<00:00, 494.93it/s]\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.619 | Train Acc: 83.12%\n",
            "\t Val. Loss: 0.646 |  Val. Acc: 79.46%\n",
            "100% 9/9 [00:00<00:00, 66.64it/s]\n",
            "100% 2/2 [00:00<00:00, 521.87it/s]\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.572 | Train Acc: 83.75%\n",
            "\t Val. Loss: 0.609 |  Val. Acc: 79.24%\n",
            "100% 9/9 [00:00<00:00, 67.38it/s]\n",
            "100% 2/2 [00:00<00:00, 488.96it/s]\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.539 | Train Acc: 82.95%\n",
            "\t Val. Loss: 0.581 |  Val. Acc: 80.03%\n",
            "100% 9/9 [00:00<00:00, 65.12it/s]\n",
            "100% 2/2 [00:00<00:00, 493.68it/s]\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.547 | Train Acc: 82.10%\n",
            "\t Val. Loss: 0.556 |  Val. Acc: 81.38%\n",
            "100% 9/9 [00:00<00:00, 66.30it/s]\n",
            "100% 2/2 [00:00<00:00, 436.97it/s]\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.528 | Train Acc: 83.40%\n",
            "\t Val. Loss: 0.545 |  Val. Acc: 80.03%\n",
            "100% 9/9 [00:00<00:00, 66.80it/s]\n",
            "100% 2/2 [00:00<00:00, 472.28it/s]\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.495 | Train Acc: 82.90%\n",
            "\t Val. Loss: 0.524 |  Val. Acc: 80.81%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6JUYoTTk19_",
        "colab_type": "text"
      },
      "source": [
        "### CNN1DClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukseycMBk4NK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b98318fc-aef6-4a9c-99a7-837be4f3201e"
      },
      "source": [
        "!python train.py -n 30 -m CNN1dClassifier --freeze-embeddings 0"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[DEBUG | train.py:268 -             <module>() ] Namespace(batch_size=64, bidirectional=True, dropout=0.7, embedding_dim=300, epochs=30, freeze_embeddings=0, hidden_dim=256, l2_regularization=0.001, learning_rate=0.001, model='CNN1dClassifier', model_location=None, n_layers=2, seed=1234, tag='multi')\n",
            "[DEBUG | train.py:269 -             <module>() ] Custom seed set with: 1234\n",
            "[INFO | train.py:271 -             <module>() ] Loading Dataset\n",
            "[DEBUG | datasetloader.py:81 -        get_iterators() ] Data Loaded Successfully!\n",
            "[INFO | vocab.py:386 -                cache() ] Loading vectors from .vector_cache/glove.6B.300d.txt.pt\n",
            "[DEBUG | datasetloader.py:95 -        get_iterators() ] Vocabulary Loaded\n",
            "[DEBUG | datasetloader.py:103 -        get_iterators() ] Created Iterators\n",
            "[INFO | train.py:278 -             <module>() ] Dataset Loaded Successfully\n",
            "[DEBUG | train.py:68 - initialize_new_model() ] Initializing Model\n",
            "[DEBUG | train.py:134 - initialize_new_model() ] Freeze Embeddings Value 0: True\n",
            "[INFO | train.py:140 - initialize_new_model() ] Model Initialized with 308,315 trainiable parameters\n",
            "[DEBUG | train.py:152 - initialize_new_model() ] Copied PreTrained Embeddings\n",
            "[INFO | train.py:303 -             <module>() ] CNN1dClassifier(\n",
            "  (embedding): Embedding(636, 300, padding_idx=1)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(300, 64, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d(300, 64, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d(300, 64, kernel_size=(3,), stride=(1,))\n",
            "  )\n",
            "  (fc): Linear(in_features=192, out_features=11, bias=True)\n",
            "  (dropout): Dropout(p=0.7, inplace=False)\n",
            ")\n",
            "100% 9/9 [00:00<00:00, 130.92it/s]\n",
            "100% 2/2 [00:00<00:00, 453.44it/s]\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.491 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.960 |  Val. Acc: 31.63%\n",
            "100% 9/9 [00:00<00:00, 159.04it/s]\n",
            "100% 2/2 [00:00<00:00, 458.67it/s]\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.151 | Train Acc: 23.87%\n",
            "\t Val. Loss: 1.896 |  Val. Acc: 32.26%\n",
            "100% 9/9 [00:00<00:00, 159.95it/s]\n",
            "100% 2/2 [00:00<00:00, 453.34it/s]\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.959 | Train Acc: 30.16%\n",
            "\t Val. Loss: 1.847 |  Val. Acc: 30.28%\n",
            "100% 9/9 [00:00<00:00, 156.41it/s]\n",
            "100% 2/2 [00:00<00:00, 444.34it/s]\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.845 | Train Acc: 36.39%\n",
            "\t Val. Loss: 1.741 |  Val. Acc: 38.24%\n",
            "100% 9/9 [00:00<00:00, 160.81it/s]\n",
            "100% 2/2 [00:00<00:00, 448.66it/s]\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.724 | Train Acc: 38.60%\n",
            "\t Val. Loss: 1.686 |  Val. Acc: 40.58%\n",
            "100% 9/9 [00:00<00:00, 165.18it/s]\n",
            "100% 2/2 [00:00<00:00, 451.51it/s]\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.636 | Train Acc: 43.44%\n",
            "\t Val. Loss: 1.625 |  Val. Acc: 45.84%\n",
            "100% 9/9 [00:00<00:00, 166.87it/s]\n",
            "100% 2/2 [00:00<00:00, 482.16it/s]\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.556 | Train Acc: 44.70%\n",
            "\t Val. Loss: 1.570 |  Val. Acc: 51.10%\n",
            "100% 9/9 [00:00<00:00, 153.03it/s]\n",
            "100% 2/2 [00:00<00:00, 476.82it/s]\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.527 | Train Acc: 43.24%\n",
            "\t Val. Loss: 1.521 |  Val. Acc: 47.97%\n",
            "100% 9/9 [00:00<00:00, 164.24it/s]\n",
            "100% 2/2 [00:00<00:00, 476.68it/s]\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.366 | Train Acc: 53.83%\n",
            "\t Val. Loss: 1.429 |  Val. Acc: 55.00%\n",
            "100% 9/9 [00:00<00:00, 167.19it/s]\n",
            "100% 2/2 [00:00<00:00, 461.78it/s]\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.301 | Train Acc: 55.54%\n",
            "\t Val. Loss: 1.400 |  Val. Acc: 55.00%\n",
            "100% 9/9 [00:00<00:00, 162.98it/s]\n",
            "100% 2/2 [00:00<00:00, 472.20it/s]\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.230 | Train Acc: 59.02%\n",
            "\t Val. Loss: 1.289 |  Val. Acc: 63.75%\n",
            "100% 9/9 [00:00<00:00, 146.49it/s]\n",
            "100% 2/2 [00:00<00:00, 242.18it/s]\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.191 | Train Acc: 61.30%\n",
            "\t Val. Loss: 1.194 |  Val. Acc: 63.75%\n",
            "100% 9/9 [00:00<00:00, 163.21it/s]\n",
            "100% 2/2 [00:00<00:00, 450.30it/s]\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.105 | Train Acc: 64.16%\n",
            "\t Val. Loss: 1.134 |  Val. Acc: 65.31%\n",
            "100% 9/9 [00:00<00:00, 158.99it/s]\n",
            "100% 2/2 [00:00<00:00, 456.15it/s]\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.037 | Train Acc: 66.20%\n",
            "\t Val. Loss: 1.056 |  Val. Acc: 65.31%\n",
            "100% 9/9 [00:00<00:00, 148.22it/s]\n",
            "100% 2/2 [00:00<00:00, 464.36it/s]\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.978 | Train Acc: 67.81%\n",
            "\t Val. Loss: 0.991 |  Val. Acc: 67.44%\n",
            "100% 9/9 [00:00<00:00, 168.37it/s]\n",
            "100% 2/2 [00:00<00:00, 495.14it/s]\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.929 | Train Acc: 71.43%\n",
            "\t Val. Loss: 0.937 |  Val. Acc: 69.57%\n",
            "100% 9/9 [00:00<00:00, 155.21it/s]\n",
            "100% 2/2 [00:00<00:00, 421.94it/s]\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.879 | Train Acc: 70.23%\n",
            "\t Val. Loss: 0.891 |  Val. Acc: 70.57%\n",
            "100% 9/9 [00:00<00:00, 145.88it/s]\n",
            "100% 2/2 [00:00<00:00, 463.33it/s]\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.786 | Train Acc: 74.10%\n",
            "\t Val. Loss: 0.818 |  Val. Acc: 73.27%\n",
            "100% 9/9 [00:00<00:00, 159.48it/s]\n",
            "100% 2/2 [00:00<00:00, 459.15it/s]\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.775 | Train Acc: 75.20%\n",
            "\t Val. Loss: 0.783 |  Val. Acc: 73.27%\n",
            "100% 9/9 [00:00<00:00, 168.13it/s]\n",
            "100% 2/2 [00:00<00:00, 476.38it/s]\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.725 | Train Acc: 79.06%\n",
            "\t Val. Loss: 0.743 |  Val. Acc: 75.97%\n",
            "100% 9/9 [00:00<00:00, 167.65it/s]\n",
            "100% 2/2 [00:00<00:00, 492.43it/s]\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.709 | Train Acc: 77.65%\n",
            "\t Val. Loss: 0.710 |  Val. Acc: 79.24%\n",
            "100% 9/9 [00:00<00:00, 166.77it/s]\n",
            "100% 2/2 [00:00<00:00, 467.20it/s]\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.653 | Train Acc: 80.58%\n",
            "\t Val. Loss: 0.670 |  Val. Acc: 79.24%\n",
            "100% 9/9 [00:00<00:00, 167.94it/s]\n",
            "100% 2/2 [00:00<00:00, 452.80it/s]\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.617 | Train Acc: 81.90%\n",
            "\t Val. Loss: 0.625 |  Val. Acc: 80.03%\n",
            "100% 9/9 [00:00<00:00, 167.50it/s]\n",
            "100% 2/2 [00:00<00:00, 466.24it/s]\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.607 | Train Acc: 79.78%\n",
            "\t Val. Loss: 0.605 |  Val. Acc: 80.60%\n",
            "100% 9/9 [00:00<00:00, 159.09it/s]\n",
            "100% 2/2 [00:00<00:00, 463.48it/s]\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.612 | Train Acc: 79.74%\n",
            "\t Val. Loss: 0.591 |  Val. Acc: 81.38%\n",
            "100% 9/9 [00:00<00:00, 151.96it/s]\n",
            "100% 2/2 [00:00<00:00, 356.26it/s]\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.571 | Train Acc: 81.17%\n",
            "\t Val. Loss: 0.548 |  Val. Acc: 80.60%\n",
            "100% 9/9 [00:00<00:00, 167.70it/s]\n",
            "100% 2/2 [00:00<00:00, 474.68it/s]\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.526 | Train Acc: 83.64%\n",
            "\t Val. Loss: 0.525 |  Val. Acc: 80.60%\n",
            "100% 9/9 [00:00<00:00, 164.59it/s]\n",
            "100% 2/2 [00:00<00:00, 451.29it/s]\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.493 | Train Acc: 83.60%\n",
            "\t Val. Loss: 0.503 |  Val. Acc: 83.30%\n",
            "100% 9/9 [00:00<00:00, 146.08it/s]\n",
            "100% 2/2 [00:00<00:00, 450.20it/s]\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.511 | Train Acc: 84.81%\n",
            "\t Val. Loss: 0.497 |  Val. Acc: 82.73%\n",
            "100% 9/9 [00:00<00:00, 165.19it/s]\n",
            "100% 2/2 [00:00<00:00, 330.57it/s]\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.458 | Train Acc: 86.16%\n",
            "\t Val. Loss: 0.492 |  Val. Acc: 83.51%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST6OPu42JyJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a641c26f-c1b8-454b-e65d-6ce68a348a80"
      },
      "source": [
        "%%writefile config/hyperparameters.py\n",
        "MAX_VOCAB = 10000\n",
        "BATCH_SIZE = 64\n",
        "# Keep it 300 since we are using glove 300d vectors\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 256\n",
        "N_LAYERS = 2\n",
        "BIDIRECTION = True\n",
        "DROPOUT = 0.7\n",
        "LR = 0.001\n",
        "EPOCHS = 5\n",
        "FREEZE_EMBEDDINGS = 1\n",
        "WEIGHT_DECAY = 0.001\n",
        "CNN_FILTER_SIZES = [1, 2, 3]\n",
        "CNN_N_FILTER = 64"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting config/hyperparameters.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1yN0S74U6Th",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05ab0e5c-2e46-4df2-e8fa-b7d686a88e30"
      },
      "source": [
        "%%writefile train.py\n",
        "\"\"\"\n",
        "Training script for the model\n",
        "\"\"\"\n",
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from config.hyperparameters import (\n",
        "    BATCH_SIZE,\n",
        "    BIDIRECTION,\n",
        "    DROPOUT,\n",
        "    EMBEDDING_DIM,\n",
        "    EPOCHS,\n",
        "    FREEZE_EMBEDDINGS,\n",
        "    HIDDEN_DIM,\n",
        "    LR,\n",
        "    N_LAYERS,\n",
        "    WEIGHT_DECAY,\n",
        "    CNN_N_FILTER,\n",
        "    CNN_FILTER_SIZES,\n",
        ")\n",
        "from config.root import (\n",
        "    LOGGING_FORMAT,\n",
        "    LOGGING_LEVEL,\n",
        "    TRAINED_CLASSIFIER_FOLDER,\n",
        "    TRAINED_CLASSIFIER_RNNHIDDEN,\n",
        "    device,\n",
        "    seed_all,\n",
        ")\n",
        "from datasetloader import GrammarDasetMultiTag, GrammarDasetSingleTag\n",
        "from helperfunctions import evaluate, train\n",
        "from model import RNNHiddenClassifier, RNNMaxpoolClassifier, CNNClassifier\n",
        "from utility import categorical_accuracy, epoch_time\n",
        "\n",
        "# Initialize logger for this file\n",
        "logger = logging.getLogger(__name__)\n",
        "logging.basicConfig(level=LOGGING_LEVEL, format=LOGGING_FORMAT)\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    \"\"\"Method to count the number of parameters\"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def initialize_new_model(\n",
        "    classifier_type,\n",
        "    dataset,\n",
        "    embedding_dim,\n",
        "    hidden_dim,\n",
        "    n_layers,\n",
        "    bidirectional,\n",
        "    dropout,\n",
        "    freeze_embeddings,\n",
        "    dataset_tag,\n",
        "):\n",
        "    \"\"\"Method to initialise new model, takes in dataset object and hyperparameters as parameter\"\"\"\n",
        "    logger.debug(\"Initializing Model\")\n",
        "    if dataset_tag == \"multi\":\n",
        "        VOCAB_SIZE = len(dataset.question.vocab)\n",
        "        PAD_IDX = dataset.question.vocab.stoi[dataset.question.pad_token]\n",
        "        pretrained_embeddings = dataset.question.vocab.vectors\n",
        "        UNK_IDX = dataset.question.vocab.stoi[dataset.question.unk_token]\n",
        "    else:\n",
        "        VOCAB_SIZE = len(dataset.text.vocab)\n",
        "        PAD_IDX = dataset.text.vocab.stoi[dataset.text.pad_token]\n",
        "        pretrained_embeddings = dataset.text.vocab.vectors\n",
        "        UNK_IDX = dataset.text.vocab.stoi[dataset.text.unk_token]\n",
        "\n",
        "    OUTPUT_LAYERS = len(dataset.label.vocab)\n",
        "\n",
        "    if classifier_type == \"RNNHiddenClassifier\":\n",
        "\n",
        "        model = RNNHiddenClassifier(\n",
        "            VOCAB_SIZE,\n",
        "            embedding_dim,\n",
        "            hidden_dim,\n",
        "            OUTPUT_LAYERS,\n",
        "            n_layers,\n",
        "            bidirectional,\n",
        "            dropout,\n",
        "            PAD_IDX,\n",
        "        )\n",
        "\n",
        "    elif classifier_type == \"RNNMaxpoolClassifier\":\n",
        "        model = RNNMaxpoolClassifier(\n",
        "            VOCAB_SIZE,\n",
        "            embedding_dim,\n",
        "            hidden_dim,\n",
        "            OUTPUT_LAYERS,\n",
        "            n_layers,\n",
        "            bidirectional,\n",
        "            dropout,\n",
        "            PAD_IDX,\n",
        "        )\n",
        "    elif classifier_type == \"CNNClassifier\":\n",
        "        model = CNNClassifier(\n",
        "            VOCAB_SIZE,\n",
        "            embedding_dim,\n",
        "            CNN_N_FILTER,\n",
        "            CNN_FILTER_SIZES,\n",
        "            OUTPUT_LAYERS,\n",
        "            dropout,\n",
        "            PAD_IDX,\n",
        "        )\n",
        "    else:\n",
        "        raise TypeError(\"Invalid Classifier selected\")\n",
        "\n",
        "    if freeze_embeddings:\n",
        "        model.embedding.weight.requires_grad = False\n",
        "\n",
        "    logger.debug(\n",
        "        \"Freeze Embeddings Value {}: {}\".format(\n",
        "            freeze_embeddings, model.embedding.weight.requires_grad\n",
        "        )\n",
        "    )\n",
        "\n",
        "    logger.info(\n",
        "        \"Model Initialized with {:,} trainiable parameters\".format(\n",
        "            count_parameters(model)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Initialize pretrained word embeddings\n",
        "\n",
        "    model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "    # Initialize Padding and Unknown as 0\n",
        "    model.embedding.weight.data[UNK_IDX] = torch.zeros(embedding_dim)\n",
        "    model.embedding.weight.data[PAD_IDX] = torch.zeros(embedding_dim)\n",
        "\n",
        "    logger.debug(\"Copied PreTrained Embeddings\")\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"Utility to train the Model\")\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"-s\",\n",
        "        \"--seed\",\n",
        "        default=1234,\n",
        "        help=\"Set custom seed for reproducibility\",\n",
        "        type=int,\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"-loc\",\n",
        "        \"--model-location\",\n",
        "        default=None,\n",
        "        help=\"Give an already trained model location to use and train more epochs on it\",\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"-b\",\n",
        "        \"--bidirectional\",\n",
        "        default=BIDIRECTION,\n",
        "        help=\"Makes the model Bidirectional\",\n",
        "        type=bool,\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-d\",\n",
        "        \"--dropout\",\n",
        "        default=DROPOUT,\n",
        "        help=\"Dropout count for the model\",\n",
        "        type=float,\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-e\",\n",
        "        \"--embedding-dim\",\n",
        "        default=EMBEDDING_DIM,\n",
        "        help=\"Embedding Dimensions\",\n",
        "        type=int,\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-hd\",\n",
        "        \"--hidden-dim\",\n",
        "        default=HIDDEN_DIM,\n",
        "        help=\"Hidden dimensions of the RNN\",\n",
        "        type=int,\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-l\", \"--n-layers\", default=N_LAYERS, help=\"Number of layers in RNN\", type=int\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-lr\",\n",
        "        \"--learning-rate\",\n",
        "        default=LR,\n",
        "        help=\"Learning rate of Adam Optimizer\",\n",
        "        type=float,\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-n\",\n",
        "        \"--epochs\",\n",
        "        default=EPOCHS,\n",
        "        help=\"Number of Epochs to train model\",\n",
        "        type=int,\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-batch\",\n",
        "        \"--batch_size\",\n",
        "        default=BATCH_SIZE,\n",
        "        help=\"Number of Epochs to train model\",\n",
        "        type=int,\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"-f\",\n",
        "        \"--freeze-embeddings\",\n",
        "        default=FREEZE_EMBEDDINGS,\n",
        "        help=\"Freeze Embeddings of Model\",\n",
        "        type=int,\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"-t\",\n",
        "        \"--tag\",\n",
        "        default=\"multi\",\n",
        "        choices=[\"multi\", \"single\"],\n",
        "        help=\"Use two different dataset type, multi type and single type where all are merged into same key \",\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"-l2\",\n",
        "        \"--l2-regularization\",\n",
        "        default=WEIGHT_DECAY,\n",
        "        help=\"Value of alpha in l2 regularization 0 means no regularization \",\n",
        "        type=float,\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"-m\",\n",
        "        \"--model\",\n",
        "        default=\"RNNHiddenClassifier\",\n",
        "        choices=[\"RNNHiddenClassifier\", \"RNNMaxpoolClassifier\", \"CNNClassifier\"],\n",
        "        help=\"select the classifier to train on\",\n",
        "    )\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    seed_all(args.seed)\n",
        "    logger.debug(args)\n",
        "    logger.debug(\"Custom seed set with: {}\".format(args.seed))\n",
        "\n",
        "    logger.info(\"Loading Dataset\")\n",
        "\n",
        "    if args.tag == \"multi\":\n",
        "        dataset = GrammarDasetMultiTag.get_iterators(args.batch_size)\n",
        "    else:\n",
        "        dataset = GrammarDasetSingleTag.get_iterators(args.batch_size)\n",
        "\n",
        "    logger.info(\"Dataset Loaded Successfully\")\n",
        "\n",
        "    if args.model_location:\n",
        "        model = torch.load(args.model_location)\n",
        "    else:\n",
        "        model = initialize_new_model(\n",
        "            args.model,\n",
        "            dataset,\n",
        "            args.embedding_dim,\n",
        "            args.hidden_dim,\n",
        "            args.n_layers,\n",
        "            args.bidirectional,\n",
        "            args.dropout,\n",
        "            args.freeze_embeddings,\n",
        "            args.tag,\n",
        "        )\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(\n",
        "        model.parameters(), lr=LR, weight_decay=args.l2_regularization\n",
        "    )\n",
        "\n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    logger.info(model)\n",
        "\n",
        "    if not os.path.exists(TRAINED_CLASSIFIER_FOLDER):\n",
        "        os.mkdir(TRAINED_CLASSIFIER_FOLDER)\n",
        "\n",
        "    best_test_loss = float(\"inf\")\n",
        "    for epoch in range(int(args.epochs)):\n",
        "        start_time = time.time()\n",
        "        train_loss, train_acc = train(\n",
        "            model, dataset.train_iterator, optimizer, criterion, args.tag\n",
        "        )\n",
        "        test_loss, test_acc = evaluate(\n",
        "            model, dataset.test_iterator, criterion, args.tag\n",
        "        )\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "        if test_loss < best_test_loss:\n",
        "            best_test_loss = test_loss\n",
        "            torch.save(\n",
        "                model,\n",
        "                os.path.join(TRAINED_CLASSIFIER_FOLDER, TRAINED_CLASSIFIER_RNNHIDDEN),\n",
        "            )\n",
        "\n",
        "        print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
        "        print(f\"\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%\")\n",
        "        print(f\"\\t Val. Loss: {test_loss:.3f} |  Val. Acc: {test_acc*100:.2f}%\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COTPk7O3W0rP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}