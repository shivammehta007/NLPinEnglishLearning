{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivammehta007/QuestionGenerator/blob/master/QGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLtWBqUscOtx",
        "colab_type": "text"
      },
      "source": [
        "# Question Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T808ilq_g2bm",
        "colab_type": "text"
      },
      "source": [
        "Additional Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LU58nY0cTuk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "4c147942-cfd4-4908-d9eb-7edc1a4a70d2"
      },
      "source": [
        "!pip install fairseq\n",
        "!pip install sacremoses subword_nmt\n",
        "!pip install -U tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fairseq in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.17.5)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.4.4)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.43.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.15)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq) (3.6.6)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq) (1.5.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.19)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (0.0.38)\n",
            "Requirement already satisfied: subword_nmt in /usr/local/lib/python3.6/dist-packages (0.3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.43.0)\n",
            "Requirement already up-to-date: tqdm in /usr/local/lib/python3.6/dist-packages (4.43.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSk9ez44VPd2",
        "colab_type": "code",
        "outputId": "819522a2-58c8-4494-8690-9be514127019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbHwJtHvqrvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGJ7wyH392a7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For results duplication\n",
        "SEED=1234\n",
        "random.seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71OqW0Y1BbN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "logging.basicConfig(level=logging.DEBUG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewFG2QxZqhdN",
        "colab_type": "text"
      },
      "source": [
        "## DataSet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdsWbBBCSfcy",
        "colab_type": "text"
      },
      "source": [
        "#### Using Author's Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y1ECwdHRtY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/drive/My\\ Drive/Data/data/processed processed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfbxDyslR7_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv processed/src-train.txt train.paragraphs\n",
        "!mv processed/src-test.txt test.paragraphs\n",
        "!mv processed/src-dev.txt valid.paragraphs\n",
        "!mv processed/tgt-train.txt train.questions\n",
        "!mv processed/tgt-test.txt test.questions\n",
        "!mv processed/tgt-dev.txt valid.questions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m3li7z-SmIU",
        "colab_type": "text"
      },
      "source": [
        "Now I can skip preprocessing and go directly to the generating binary for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr1X0hSTSiUX",
        "colab_type": "text"
      },
      "source": [
        "#### Using Myself"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCxOp7LEcGlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SQUAD_DIR = '/content/drive/My Drive/Colab Notebooks/SQuAD'\n",
        "SQUAD_TRAIN = os.path.join(SQUAD_DIR, 'train_v2.json')\n",
        "# SQUAD_DEV = os.path.join(SQUAD_DIR, 'dev.json')\n",
        "SQUAD_TEST = os.path.join(SQUAD_DIR, 'test_v2.json')\n",
        "print(SQUAD_TRAIN, SQUAD_TEST) # , SQUAD_DEV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTVjKnG6q4qR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(SQUAD_TRAIN) as train_file:\n",
        "    train_data = json.load(train_file)\n",
        "    train_data = train_data['data']\n",
        "\n",
        "with open(SQUAD_TEST) as test_file:\n",
        "    test_data = json.load(test_file)\n",
        "    test_data = test_data['data']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrg9adeKTgZk",
        "colab_type": "text"
      },
      "source": [
        "### PreProcessing Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsZ0jvvqTfIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_file_without_answers(dataset, dataset_type='train', get_impossible=False):\n",
        "    \"\"\"\n",
        "    Takes an input json and generates dataset_type.paragraphs and dataset_type.questions\n",
        "    Input:\n",
        "    dataset : string -> Name of json input\n",
        "    dataset_type: string -> Type of dataset like (Train, test, valid)\n",
        "    get_impossible: boolean -> Flag to get unanswerable questions\n",
        "    \"\"\"\n",
        "    para_output = open(dataset_type + '.paragraphs', 'w')\n",
        "    question_output = open(dataset_type + '.questions', 'w')\n",
        "    d = []\n",
        "    for paragraphs in tqdm(dataset):\n",
        "        paragraphs = paragraphs['paragraphs']\n",
        "        for i, paragraph in enumerate(paragraphs):\n",
        "            para = paragraph['context']\n",
        "            for questionanswers in paragraph['qas']:\n",
        "                if questionanswers['is_impossible']:\n",
        "                    continue\n",
        "                question = questionanswers['question']\n",
        "                para = para.replace('\\n', ' ')\n",
        "                para_output.write(para.strip().lower() + '\\n')\n",
        "                question_output.write(question.strip().lower() + '\\n')\n",
        "                d.append(i)\n",
        "    print(len(d))\n",
        "    para_output.close()\n",
        "    question_output.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOVyuJg2Tfe-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convert_to_file_without_answers(train_data, 'train')\n",
        "convert_to_file_without_answers(test_data, 'test')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3XnQgaS-Y_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_train_valid(filename_paragraph='train.paragraphs', filename_questions='train.questions', split_ratio=0.8):\n",
        "    \"\"\"Splits the train set to a validation set\"\"\"\n",
        "\n",
        "    with open(filename_paragraph) as paragraphs_file, open(filename_questions) as questions_file:\n",
        "        data_paragraphs = paragraphs_file.readlines()\n",
        "        data_questions = questions_file.readlines()\n",
        "    \n",
        "    # Output files\n",
        "    train_paragraphs_file = open('train.paragraphs', 'w')\n",
        "    valid_paragraphs_file = open('valid.paragraphs', 'w')\n",
        "    train_questions_file = open('train.questions', 'w')\n",
        "    valid_questions_file = open('valid.questions', 'w')\n",
        "\n",
        "    train_count, valid_count = 0, 0\n",
        "\n",
        "    for i in tqdm(range(len(data_paragraphs))):\n",
        "        if random.random() < split_ratio:\n",
        "            train_paragraphs_file.write(data_paragraphs[i].strip() + '\\n')\n",
        "            train_questions_file.write(data_questions[i].strip() + '\\n')\n",
        "            train_count += 1\n",
        "        else:\n",
        "            valid_paragraphs_file.write(data_paragraphs[i].strip() + '\\n')\n",
        "            valid_questions_file.write(data_questions[i].strip() + '\\n')\n",
        "            valid_count += 1\n",
        "\n",
        "    logger.info('Total Trainset: {} | Total ValidSet: {}'.format(train_count, valid_count))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTlUUJoABrrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split_train_valid()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHjI0mvZDa7g",
        "colab_type": "text"
      },
      "source": [
        "### Generate Binary of Dataset for FairSeq to process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahWXypAOTfc2",
        "colab_type": "code",
        "outputId": "0d9f976a-106f-400b-e8f5-b2fd91646a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "!fairseq-preprocess --source-lang paragraphs --target-lang questions \\\n",
        "     --trainpref train --testpref test --validpref valid\\\n",
        "     --destdir preprocessed_data --seed 1234 --nwordssrc 45000 --nwordstgt 28000"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(align_suffix=None, alignfile=None, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='preprocessed_data', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=1000, lr_scheduler='fixed', memory_efficient_fp16=False, min_loss_scale=0.0001, no_progress_bar=False, nwordssrc=45000, nwordstgt=28000, only_source=False, optimizer='nag', padding_factor=8, seed=1234, source_lang='paragraphs', srcdict=None, target_lang='questions', task='translation', tensorboard_logdir='', testpref='test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, trainpref='train', user_dir=None, validpref='valid', workers=1)\n",
            "| [paragraphs] Dictionary: 44999 types\n",
            "| [paragraphs] train.paragraphs: 70484 sents, 2386532 tokens, 1.32% replaced by <unk>\n",
            "| [paragraphs] Dictionary: 44999 types\n",
            "| [paragraphs] valid.paragraphs: 10570 sents, 368586 tokens, 5.17% replaced by <unk>\n",
            "| [paragraphs] Dictionary: 44999 types\n",
            "| [paragraphs] test.paragraphs: 11877 sents, 397472 tokens, 5.35% replaced by <unk>\n",
            "| [questions] Dictionary: 27999 types\n",
            "| [questions] train.questions: 70484 sents, 866317 tokens, 0.85% replaced by <unk>\n",
            "| [questions] Dictionary: 27999 types\n",
            "| [questions] valid.questions: 10570 sents, 131365 tokens, 4.72% replaced by <unk>\n",
            "| [questions] Dictionary: 27999 types\n",
            "| [questions] test.questions: 11877 sents, 149804 tokens, 5.33% replaced by <unk>\n",
            "| Wrote preprocessed data to preprocessed_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFfiV_VuDgGA",
        "colab_type": "text"
      },
      "source": [
        "### Training ConvSeq2Seq Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcJ8LG6-TfaF",
        "colab_type": "code",
        "outputId": "089ddcc8-1e1d-4f3f-b5d2-da7c2cf6f1ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 fairseq-train preprocessed_data/ \\\n",
        "     --lr 0.001 --clip-norm 0.1 --dropout 0.3 --max-epoch 15 --optimizer adam\\\n",
        "     --arch fconv_iwslt_de_en --save-dir checkpoints/fconv --batch-size 128 --no-epoch-checkpoints \\\n",
        "     --encoder-embed-path glove.840B.300d.txt \\\n",
        "     --encoder-embed-dim 300 --decoder-embed-dim 300 --decoder-embed-path glove.840B.300d.txt --decoder-out-embed-dim 300 --num-workers 3"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(adam_betas='(0.9, 0.999)', adam_eps=1e-08, arch='fconv_iwslt_de_en', best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.1, cpu=False, criterion='cross_entropy', curriculum=0, data='preprocessed_data/', dataset_impl=None, ddp_backend='c10d', decoder_attention='True', decoder_embed_dim=300, decoder_embed_path='glove.840B.300d.txt', decoder_layers='[(256, 3)] * 3', decoder_out_embed_dim=300, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_embed_dim=300, encoder_embed_path='glove.840B.300d.txt', encoder_layers='[(256, 3)] * 4', fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format=None, log_interval=1000, lr=[0.001], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=15, max_sentences=128, max_sentences_valid=128, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, num_workers=3, optimizer='adam', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/fconv', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_updates=0, weight_decay=0.0)\n",
            "| [paragraphs] dictionary: 45000 types\n",
            "| [questions] dictionary: 28000 types\n",
            "| loaded 10570 examples from: preprocessed_data/valid.paragraphs-questions.paragraphs\n",
            "| loaded 10570 examples from: preprocessed_data/valid.paragraphs-questions.questions\n",
            "| preprocessed_data/ valid paragraphs-questions 10570 examples\n",
            "| Found 37484/45000 types in embedding file.\n",
            "| Found 24430/28000 types in embedding file.\n",
            "FConvModel(\n",
            "  (encoder): FConvEncoder(\n",
            "    (embed_tokens): Embedding(45000, 300, padding_idx=1)\n",
            "    (embed_positions): LearnedPositionalEmbedding(1024, 300, padding_idx=1)\n",
            "    (fc1): Linear(in_features=300, out_features=256, bias=True)\n",
            "    (projections): ModuleList(\n",
            "      (0): None\n",
            "      (1): None\n",
            "      (2): None\n",
            "      (3): None\n",
            "    )\n",
            "    (convolutions): ModuleList(\n",
            "      (0): ConvTBC(256, 512, kernel_size=(3,), padding=(1,))\n",
            "      (1): ConvTBC(256, 512, kernel_size=(3,), padding=(1,))\n",
            "      (2): ConvTBC(256, 512, kernel_size=(3,), padding=(1,))\n",
            "      (3): ConvTBC(256, 512, kernel_size=(3,), padding=(1,))\n",
            "    )\n",
            "    (fc2): Linear(in_features=256, out_features=300, bias=True)\n",
            "  )\n",
            "  (decoder): FConvDecoder(\n",
            "    (embed_tokens): Embedding(28000, 300, padding_idx=1)\n",
            "    (embed_positions): LearnedPositionalEmbedding(1024, 300, padding_idx=1)\n",
            "    (fc1): Linear(in_features=300, out_features=256, bias=True)\n",
            "    (projections): ModuleList(\n",
            "      (0): None\n",
            "      (1): None\n",
            "      (2): None\n",
            "    )\n",
            "    (convolutions): ModuleList(\n",
            "      (0): LinearizedConvolution(256, 512, kernel_size=(3,), padding=(2,))\n",
            "      (1): LinearizedConvolution(256, 512, kernel_size=(3,), padding=(2,))\n",
            "      (2): LinearizedConvolution(256, 512, kernel_size=(3,), padding=(2,))\n",
            "    )\n",
            "    (attention): ModuleList(\n",
            "      (0): AttentionLayer(\n",
            "        (in_projection): Linear(in_features=256, out_features=300, bias=True)\n",
            "        (out_projection): Linear(in_features=300, out_features=256, bias=True)\n",
            "      )\n",
            "      (1): AttentionLayer(\n",
            "        (in_projection): Linear(in_features=256, out_features=300, bias=True)\n",
            "        (out_projection): Linear(in_features=300, out_features=256, bias=True)\n",
            "      )\n",
            "      (2): AttentionLayer(\n",
            "        (in_projection): Linear(in_features=256, out_features=300, bias=True)\n",
            "        (out_projection): Linear(in_features=300, out_features=256, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (fc2): Linear(in_features=256, out_features=300, bias=True)\n",
            "    (fc3): Linear(in_features=300, out_features=28000, bias=True)\n",
            "  )\n",
            ")\n",
            "| model fconv_iwslt_de_en, criterion CrossEntropyCriterion\n",
            "| num. model params: 34503640 (num. trained: 34503640)\n",
            "| training on 1 GPUs\n",
            "| max tokens per GPU = None and max sentences per GPU = 128\n",
            "| no existing checkpoint found checkpoints/fconv/checkpoint_last.pt\n",
            "| loading train data for epoch 0\n",
            "| loaded 70484 examples from: preprocessed_data/train.paragraphs-questions.paragraphs\n",
            "| loaded 70484 examples from: preprocessed_data/train.paragraphs-questions.questions\n",
            "| preprocessed_data/ train paragraphs-questions 70484 examples\n",
            "| epoch 001 | loss 7.608 | ppl 195.08 | wps 13884 | ups 9 | wpb 1572.263 | bsz 127.920 | num_updates 551 | lr 0.001 | gnorm 1.411 | clip 1.000 | oom 0.000 | wall 64 | train_wall 61\n",
            "| epoch 001 | valid on 'valid' subset | loss 6.092 | ppl 68.2 | num_updates 551\n",
            "| saved checkpoint checkpoints/fconv/checkpoint_best.pt (epoch 1 @ 551 updates) (writing took 2.6290364265441895 seconds)\n",
            "| epoch 002 | loss 5.657 | ppl 50.44 | wps 13822 | ups 9 | wpb 1572.263 | bsz 127.920 | num_updates 1102 | lr 0.001 | gnorm 0.948 | clip 1.000 | oom 0.000 | wall 134 | train_wall 122\n",
            "| epoch 002 | valid on 'valid' subset | loss 5.321 | ppl 39.96 | num_updates 1102 | best_loss 5.32058\n",
            "| saved checkpoint checkpoints/fconv/checkpoint_best.pt (epoch 2 @ 1102 updates) (writing took 2.6153838634490967 seconds)\n",
            "| epoch 003 | loss 4.875 | ppl 29.34 | wps 13727 | ups 9 | wpb 1572.263 | bsz 127.920 | num_updates 1653 | lr 0.001 | gnorm 0.916 | clip 1.000 | oom 0.000 | wall 204 | train_wall 183\n",
            "| epoch 003 | valid on 'valid' subset | loss 4.990 | ppl 31.77 | num_updates 1653 | best_loss 4.9896\n",
            "| saved checkpoint checkpoints/fconv/checkpoint_best.pt (epoch 3 @ 1653 updates) (writing took 2.6048669815063477 seconds)\n",
            "| epoch 004 | loss 4.377 | ppl 20.78 | wps 13660 | ups 9 | wpb 1572.263 | bsz 127.920 | num_updates 2204 | lr 0.001 | gnorm 0.904 | clip 1.000 | oom 0.000 | wall 275 | train_wall 245\n",
            "| epoch 004 | valid on 'valid' subset | loss 4.853 | ppl 28.9 | num_updates 2204 | best_loss 4.85276\n",
            "| saved checkpoint checkpoints/fconv/checkpoint_best.pt (epoch 4 @ 2204 updates) (writing took 2.648815155029297 seconds)\n",
            "| epoch 005 | loss 4.024 | ppl 16.27 | wps 13608 | ups 9 | wpb 1572.263 | bsz 127.920 | num_updates 2755 | lr 0.001 | gnorm 0.892 | clip 1.000 | oom 0.000 | wall 345 | train_wall 307\n",
            "| epoch 005 | valid on 'valid' subset | loss 4.752 | ppl 26.94 | num_updates 2755 | best_loss 4.75189\n",
            "| saved checkpoint checkpoints/fconv/checkpoint_best.pt (epoch 5 @ 2755 updates) (writing took 2.6468420028686523 seconds)\n",
            "| epoch 006 | loss 3.745 | ppl 13.4 | wps 13595 | ups 9 | wpb 1572.263 | bsz 127.920 | num_updates 3306 | lr 0.001 | gnorm 0.864 | clip 1.000 | oom 0.000 | wall 416 | train_wall 369\n",
            "| epoch 006 | valid on 'valid' subset | loss 4.729 | ppl 26.52 | num_updates 3306 | best_loss 4.72899\n",
            "| saved checkpoint checkpoints/fconv/checkpoint_best.pt (epoch 6 @ 3306 updates) (writing took 2.5526745319366455 seconds)\n",
            "| epoch 007 | loss 3.515 | ppl 11.43 | wps 13580 | ups 9 | wpb 1572.263 | bsz 127.920 | num_updates 3857 | lr 0.001 | gnorm 0.838 | clip 1.000 | oom 0.000 | wall 487 | train_wall 431\n",
            "| epoch 007 | valid on 'valid' subset | loss 4.774 | ppl 27.36 | num_updates 3857 | best_loss 4.72899\n",
            "| saved checkpoint checkpoints/fconv/checkpoint_last.pt (epoch 7 @ 3857 updates) (writing took 1.0216925144195557 seconds)\n",
            "| epoch 008 | loss 3.332 | ppl 10.07 | wps 13606 | ups 9 | wpb 1572.263 | bsz 127.920 | num_updates 4408 | lr 0.001 | gnorm 0.837 | clip 1.000 | oom 0.000 | wall 556 | train_wall 493\n",
            "| epoch 008 | valid on 'valid' subset | loss 4.781 | ppl 27.5 | num_updates 4408 | best_loss 4.72899\n",
            "| saved checkpoint checkpoints/fconv/checkpoint_last.pt (epoch 8 @ 4408 updates) (writing took 1.0575261116027832 seconds)\n",
            "| epoch 009 | loss 3.176 | ppl 9.04 | wps 13588 | ups 9 | wpb 1572.263 | bsz 127.920 | num_updates 4959 | lr 0.001 | gnorm 0.828 | clip 1.000 | oom 0.000 | wall 625 | train_wall 556\n",
            "| epoch 009 | valid on 'valid' subset | loss 4.835 | ppl 28.55 | num_updates 4959 | best_loss 4.72899\n",
            "| saved checkpoint checkpoints/fconv/checkpoint_last.pt (epoch 9 @ 4959 updates) (writing took 1.014547348022461 seconds)\n",
            "| epoch 010 | loss 3.034 | ppl 8.19 | wps 13575 | ups 9 | wpb 1572.263 | bsz 127.920 | num_updates 5510 | lr 0.001 | gnorm 0.820 | clip 1.000 | oom 0.000 | wall 694 | train_wall 618\n",
            "| epoch 010 | valid on 'valid' subset | loss 4.829 | ppl 28.43 | num_updates 5510 | best_loss 4.72899\n",
            "| saved checkpoint checkpoints/fconv/checkpoint_last.pt (epoch 10 @ 5510 updates) (writing took 1.0862302780151367 seconds)\n",
            "| epoch 011 | loss 2.909 | ppl 7.51 | wps 13567 | ups 9 | wpb 1572.263 | bsz 127.920 | num_updates 6061 | lr 0.001 | gnorm 0.804 | clip 1.000 | oom 0.000 | wall 763 | train_wall 680\n",
            "| epoch 011 | valid on 'valid' subset | loss 4.864 | ppl 29.13 | num_updates 6061 | best_loss 4.72899\n",
            "| saved checkpoint checkpoints/fconv/checkpoint_last.pt (epoch 11 @ 6061 updates) (writing took 1.0401837825775146 seconds)\n",
            "| epoch 012 | loss 2.793 | ppl 6.93 | wps 13598 | ups 9 | wpb 1572.263 | bsz 127.920 | num_updates 6612 | lr 0.001 | gnorm 0.796 | clip 1.000 | oom 0.000 | wall 832 | train_wall 742\n",
            "| epoch 012 | valid on 'valid' subset | loss 4.933 | ppl 30.55 | num_updates 6612 | best_loss 4.72899\n",
            "| saved checkpoint checkpoints/fconv/checkpoint_last.pt (epoch 12 @ 6612 updates) (writing took 1.051774501800537 seconds)\n",
            "| epoch 013 | loss 2.691 | ppl 6.46 | wps 13599 | ups 9 | wpb 1572.263 | bsz 127.920 | num_updates 7163 | lr 0.001 | gnorm 0.797 | clip 1.000 | oom 0.000 | wall 901 | train_wall 804\n",
            "| epoch 013 | valid on 'valid' subset | loss 4.995 | ppl 31.89 | num_updates 7163 | best_loss 4.72899\n",
            "| saved checkpoint checkpoints/fconv/checkpoint_last.pt (epoch 13 @ 7163 updates) (writing took 0.9651138782501221 seconds)\n",
            "| epoch 014 | loss 2.598 | ppl 6.05 | wps 13581 | ups 9 | wpb 1572.263 | bsz 127.920 | num_updates 7714 | lr 0.001 | gnorm 0.790 | clip 1.000 | oom 0.000 | wall 970 | train_wall 866\n",
            "| epoch 014 | valid on 'valid' subset | loss 4.994 | ppl 31.86 | num_updates 7714 | best_loss 4.72899\n",
            "| saved checkpoint checkpoints/fconv/checkpoint_last.pt (epoch 14 @ 7714 updates) (writing took 1.0407395362854004 seconds)\n",
            "| epoch 015 | loss 2.506 | ppl 5.68 | wps 13584 | ups 9 | wpb 1572.263 | bsz 127.920 | num_updates 8265 | lr 0.001 | gnorm 0.775 | clip 1.000 | oom 0.000 | wall 1039 | train_wall 928\n",
            "| epoch 015 | valid on 'valid' subset | loss 5.099 | ppl 34.28 | num_updates 8265 | best_loss 4.72899\n",
            "| saved checkpoint checkpoints/fconv/checkpoint_last.pt (epoch 15 @ 8265 updates) (writing took 1.8796594142913818 seconds)\n",
            "| done training in 1044.3 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWcZSBfETfWi",
        "colab_type": "code",
        "outputId": "7d919ed9-c689-41dc-c8cf-1e79ee50aef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "!fairseq-generate preprocessed_data \\\n",
        "    --path checkpoints/fconv/checkpoint_last.pt \\\n",
        "    --batch-size 128 > last_gen.out"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUHuS4_64RkV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "b6f1c538-eeab-4f80-e841-bcfeff9553fe"
      },
      "source": [
        "!tail last_gen.out"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "S-10485\tcardinals have in canon law a `` privilege of forum '' -lrb- i.e. , exemption from being judged by ecclesiastical <unk> of ordinary rank -rrb- : only the pope is competent to judge them in matters subject to ecclesiastical jurisdiction -lrb- cases that refer to matters that are spiritual or linked with the spiritual , or with regard to infringement of ecclesiastical laws and whatever contains an element of sin , where culpability must be determined and the appropriate ecclesiastical penalty imposed -rrb- .\n",
            "T-10485\twho is the only person who can judge a cardinal in regards to laws of the church ?\n",
            "H-10485\t-0.8387119770050049\twhat is the title given to matters that are considered to judge ?\n",
            "P-10485\t-0.7391 -1.5841 -1.1289 -0.9351 -0.5712 -0.2948 -1.8041 -0.0796 -0.2706 -1.3786 -0.5791 -0.0106 -2.3660 -0.0000\n",
            "S-5194\ttajikistan -lrb- <unk> <unk> / , / <unk> / , or / <unk> / ; persian : <unk> <unk> -lsb- <unk> -rsb- -rrb- , officially the republic of tajikistan -lrb- persian : <unk> <unk> tajik : <unk> <unk> , <unk> <unk> / <unk> <unk> ; russian : <unk> <unk> , <unk> <unk> -rrb- , is a mountainous , landlocked country in central asia with an estimated 8 million people in 2013 , and an area of <unk> km2 -lrb- <unk> sq mi -rrb- .\n",
            "T-5194\twhat is the area of <<unk>> ?\n",
            "H-5194\t-0.3709655702114105\twhat is iran 's total population in 2013 ?\n",
            "P-5194\t-0.5069 -0.5722 -0.5252 -0.1427 -0.5196 -0.6184 -0.7549 -0.0580 -0.0118 0.0000\n",
            "| Translated 11877 sentences (135997 tokens) in 29.9s (397.73 sentences/s, 4554.15 tokens/s)\n",
            "| Generate test with beam=5: BLEU4 = 7.78, 37.4/10.9/5.3/2.7 (BP=0.895, ratio=0.900, syslen=124120, reflen=137927)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8pYFKiQbjQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp checkpoints/fconv/checkpoint_last.pt /content/drive/My\\ Drive/Data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp-u_Y6C4kV6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "44e82cc0-c0e5-4141-d1f1-0cdce24fd24a"
      },
      "source": [
        "!grep ^H gen.out | cut -f3- > gen.out.sys\n",
        "!grep ^T gen.out | cut -f2- > gen.out.ref\n",
        "!fairseq-score --sys gen.out.sys --ref gen.out.ref"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(ignore_case=False, order=4, ref='gen.out.ref', sacrebleu=False, sentence_bleu=False, sys='gen.out.sys')\n",
            "BLEU4 = 7.49, 39.8/11.5/5.6/2.7 (BP=0.819, ratio=0.834, syslen=114971, reflen=137927)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv7roXL5_tra",
        "colab_type": "code",
        "outputId": "8379c0f0-513e-4ed2-deb2-43d0b45e4335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!grep ^H last_gen.out | cut -f3- > last_gen.out.sys\n",
        "!grep ^T last_gen.out | cut -f2- > last_gen.out.ref\n",
        "!fairseq-score --sys last_gen.out.sys --ref last_gen.out.ref"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(ignore_case=False, order=4, ref='last_gen.out.ref', sacrebleu=False, sentence_bleu=False, sys='last_gen.out.sys')\n",
            "BLEU4 = 7.78, 37.4/10.9/5.3/2.7 (BP=0.895, ratio=0.900, syslen=124120, reflen=137927)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u_JkoWBAt7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %cd fairseq/examples/translation/\n",
        "# !bash prepare-iwslt14.sh\n",
        "# !fairseq-preprocess --source-lang de --target-lang en \\\n",
        "#     --trainpref examples/translation/iwslt14.tokenized.de-en/train --validpref examples/translation/iwslt14.tokenized.de-en/valid --testpref examples/translation/iwslt14.tokenized.de-en/test \\\n",
        "#     --destdir data-bin/iwslt14.tokenized.de-en\n",
        "# !mkdir -p checkpoints/fconv\n",
        "# !fairseq-train data-bin/iwslt14.tokenized.de-en \\\n",
        "#     --lr 0.25 --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 \\\n",
        "#     --arch fconv_iwslt_de_en --save-dir checkpoints/fconv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kDLHksIJ4Ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !fairseq-generate data-bin/iwslt14.tokenized.de-en \\\n",
        "#     --path checkpoints/fconv/checkpoint20.pt \\\n",
        "#     --batch-size 128 --beam 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuCn_Bdhx8X_",
        "colab_type": "text"
      },
      "source": [
        "### Trying Baseline LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe_OwaIVx-sR",
        "colab_type": "code",
        "outputId": "b3a0a0e3-e096-44b9-e600-8cb9aa9bb6e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-12 11:46:12--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2020-03-12 11:46:12--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2020-03-12 11:46:12--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  2.04MB/s    in 16m 54s \n",
            "\n",
            "2020-03-12 12:03:06 (2.05 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiDL6tdskOrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YngekyqK47M0",
        "colab_type": "code",
        "outputId": "141fbb40-506b-4057-b878-b69f64682fea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip glove.840B.300d.zip"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.840B.300d.zip\n",
            "  inflating: glove.840B.300d.txt     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XIKQSKebTR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --lr 0.001. --lr-shrink\n",
        "! rm -rf checkpoints\n",
        "# --lr 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.5,0.25,0.125,0.0625,0.03125,0.015625,0.0078125"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0BnmaSfKNLy",
        "colab_type": "code",
        "outputId": "30b77811-b2a1-4f05-d487-5d22f1ee8f23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 fairseq-train preprocessed_data/ \\\n",
        "     --clip-norm 5 --batch-size 64 \\\n",
        "     --save-dir checkpoints/lstm \\\n",
        "     --arch lstm --max-epoch 15 --encoder-hidden-size 600 --encoder-layers 2 \\\n",
        "     --decoder-hidden-size 600 --decoder-layers 2 --optimizer adam --lr 0.001  --dropout 0.3 --encoder-embed-path glove.840B.300d.txt \\\n",
        "     --encoder-bidirectional --encoder-embed-dim 300 --decoder-embed-dim 300 --no-epoch-checkpoints --decoder-embed-path glove.840B.300d.txt --decoder-out-embed-dim 300 --num-workers 3\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(adam_betas='(0.9, 0.999)', adam_eps=1e-08, adaptive_softmax_cutoff='10000,50000,200000', arch='lstm', best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=5.0, cpu=False, criterion='cross_entropy', curriculum=0, data='preprocessed_data/', dataset_impl=None, ddp_backend='c10d', decoder_attention='1', decoder_dropout_in=0.3, decoder_dropout_out=0.3, decoder_embed_dim=300, decoder_embed_path='glove.840B.300d.txt', decoder_freeze_embed=False, decoder_hidden_size=600, decoder_layers=2, decoder_out_embed_dim=300, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_bidirectional=True, encoder_dropout_in=0.3, encoder_dropout_out=0.3, encoder_embed_dim=300, encoder_embed_path='glove.840B.300d.txt', encoder_freeze_embed=False, encoder_hidden_size=600, encoder_layers=2, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format=None, log_interval=1000, lr=[0.001], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=15, max_sentences=64, max_sentences_valid=64, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, num_workers=3, optimizer='adam', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/lstm', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_updates=0, weight_decay=0.0)\n",
            "| [paragraphs] dictionary: 45000 types\n",
            "| [questions] dictionary: 28000 types\n",
            "| loaded 10570 examples from: preprocessed_data/valid.paragraphs-questions.paragraphs\n",
            "| loaded 10570 examples from: preprocessed_data/valid.paragraphs-questions.questions\n",
            "| preprocessed_data/ valid paragraphs-questions 10570 examples\n",
            "| Found 37484/45000 types in embedding file.\n",
            "| Found 24430/28000 types in embedding file.\n",
            "LSTMModel(\n",
            "  (encoder): LSTMEncoder(\n",
            "    (embed_tokens): Embedding(45000, 300, padding_idx=1)\n",
            "    (lstm): LSTM(300, 600, num_layers=2, dropout=0.3, bidirectional=True)\n",
            "  )\n",
            "  (decoder): LSTMDecoder(\n",
            "    (embed_tokens): Embedding(28000, 300, padding_idx=1)\n",
            "    (encoder_hidden_proj): Linear(in_features=1200, out_features=600, bias=True)\n",
            "    (encoder_cell_proj): Linear(in_features=1200, out_features=600, bias=True)\n",
            "    (layers): ModuleList(\n",
            "      (0): LSTMCell(900, 600)\n",
            "      (1): LSTMCell(600, 600)\n",
            "    )\n",
            "    (attention): AttentionLayer(\n",
            "      (input_proj): Linear(in_features=600, out_features=1200, bias=False)\n",
            "      (output_proj): Linear(in_features=1800, out_features=600, bias=False)\n",
            "    )\n",
            "    (additional_fc): Linear(in_features=600, out_features=300, bias=True)\n",
            "    (fc_out): Linear(in_features=300, out_features=28000, bias=True)\n",
            "  )\n",
            ")\n",
            "| model lstm, criterion CrossEntropyCriterion\n",
            "| num. model params: 53218300 (num. trained: 53218300)\n",
            "| training on 1 GPUs\n",
            "| max tokens per GPU = None and max sentences per GPU = 64\n",
            "| no existing checkpoint found checkpoints/lstm/checkpoint_last.pt\n",
            "| loading train data for epoch 0\n",
            "| loaded 70484 examples from: preprocessed_data/train.paragraphs-questions.paragraphs\n",
            "| loaded 70484 examples from: preprocessed_data/train.paragraphs-questions.questions\n",
            "| preprocessed_data/ train paragraphs-questions 70484 examples\n",
            "| epoch 001:   4% 46/1102 [00:09<02:57,  5.96it/s, loss=10.164, ppl=1147.29, wps=4276, ups=5, wpb=802.283, bsz=64.000, num_updates=46, lr=0.001, gnorm=2.595, clip=0.043, oom=0.000, wall=10, train_wall=9]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [73] is 73 which does not match the computed number of elements 97. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (97,).\n",
            "| epoch 001:   7% 79/1102 [00:15<02:55,  5.84it/s, loss=9.503, ppl=725.78, wps=4160, ups=5, wpb=768.810, bsz=64.000, num_updates=79, lr=0.001, gnorm=2.064, clip=0.025, oom=0.000, wall=16, train_wall=15]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [97] is 97 which does not match the computed number of elements 432. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (432,).\n",
            "| epoch 001 | loss 7.195 | ppl 146.51 | wps 4194 | ups 5 | wpb 786.132 | bsz 63.960 | num_updates 1102 | lr 0.001 | gnorm 0.954 | clip 0.002 | oom 0.000 | wall 208 | train_wall 203\n",
            "| epoch 001 | valid on 'valid' subset | loss 5.987 | ppl 63.43 | num_updates 1102\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_best.pt (epoch 1 @ 1102 updates) (writing took 4.516843795776367 seconds)\n",
            "| epoch 002 | loss 5.606 | ppl 48.7 | wps 4132 | ups 5 | wpb 786.132 | bsz 63.960 | num_updates 2204 | lr 0.001 | gnorm 0.851 | clip 0.000 | oom 0.000 | wall 433 | train_wall 410\n",
            "| epoch 002 | valid on 'valid' subset | loss 5.302 | ppl 39.46 | num_updates 2204 | best_loss 5.30227\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_best.pt (epoch 2 @ 2204 updates) (writing took 4.630067825317383 seconds)\n",
            "| epoch 003 | loss 4.856 | ppl 28.96 | wps 4130 | ups 5 | wpb 786.132 | bsz 63.960 | num_updates 3306 | lr 0.001 | gnorm 0.869 | clip 0.000 | oom 0.000 | wall 659 | train_wall 616\n",
            "| epoch 003 | valid on 'valid' subset | loss 4.946 | ppl 30.82 | num_updates 3306 | best_loss 4.94574\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_best.pt (epoch 3 @ 3306 updates) (writing took 4.585777282714844 seconds)\n",
            "| epoch 004 | loss 4.371 | ppl 20.69 | wps 4122 | ups 5 | wpb 786.132 | bsz 63.960 | num_updates 4408 | lr 0.001 | gnorm 0.878 | clip 0.000 | oom 0.000 | wall 885 | train_wall 823\n",
            "| epoch 004 | valid on 'valid' subset | loss 4.811 | ppl 28.07 | num_updates 4408 | best_loss 4.81108\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_best.pt (epoch 4 @ 4408 updates) (writing took 4.540258169174194 seconds)\n",
            "| epoch 005 | loss 4.011 | ppl 16.12 | wps 4127 | ups 5 | wpb 786.132 | bsz 63.960 | num_updates 5510 | lr 0.001 | gnorm 0.886 | clip 0.000 | oom 0.000 | wall 1110 | train_wall 1029\n",
            "| epoch 005 | valid on 'valid' subset | loss 4.792 | ppl 27.7 | num_updates 5510 | best_loss 4.79194\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_best.pt (epoch 5 @ 5510 updates) (writing took 4.566051959991455 seconds)\n",
            "| epoch 006 | loss 3.735 | ppl 13.31 | wps 4130 | ups 5 | wpb 786.132 | bsz 63.960 | num_updates 6612 | lr 0.001 | gnorm 0.889 | clip 0.000 | oom 0.000 | wall 1336 | train_wall 1236\n",
            "| epoch 006 | valid on 'valid' subset | loss 4.791 | ppl 27.69 | num_updates 6612 | best_loss 4.79133\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_best.pt (epoch 6 @ 6612 updates) (writing took 4.4345996379852295 seconds)\n",
            "| epoch 007 | loss 3.514 | ppl 11.42 | wps 4126 | ups 5 | wpb 786.132 | bsz 63.960 | num_updates 7714 | lr 0.001 | gnorm 0.893 | clip 0.000 | oom 0.000 | wall 1561 | train_wall 1442\n",
            "| epoch 007 | valid on 'valid' subset | loss 4.739 | ppl 26.71 | num_updates 7714 | best_loss 4.73924\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_best.pt (epoch 7 @ 7714 updates) (writing took 4.682582855224609 seconds)\n",
            "| epoch 008 | loss 3.325 | ppl 10.02 | wps 4124 | ups 5 | wpb 786.132 | bsz 63.960 | num_updates 8816 | lr 0.001 | gnorm 0.893 | clip 0.000 | oom 0.000 | wall 1787 | train_wall 1649\n",
            "| epoch 008 | valid on 'valid' subset | loss 4.792 | ppl 27.7 | num_updates 8816 | best_loss 4.73924\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_last.pt (epoch 8 @ 8816 updates) (writing took 2.0153398513793945 seconds)\n",
            "| epoch 009 | loss 3.162 | ppl 8.95 | wps 4129 | ups 5 | wpb 786.132 | bsz 63.960 | num_updates 9918 | lr 0.001 | gnorm 0.890 | clip 0.000 | oom 0.000 | wall 2010 | train_wall 1856\n",
            "| epoch 009 | valid on 'valid' subset | loss 4.849 | ppl 28.83 | num_updates 9918 | best_loss 4.73924\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_last.pt (epoch 9 @ 9918 updates) (writing took 2.100045919418335 seconds)\n",
            "| epoch 010 | loss 3.025 | ppl 8.14 | wps 4131 | ups 5 | wpb 786.132 | bsz 63.960 | num_updates 11020 | lr 0.001 | gnorm 0.886 | clip 0.000 | oom 0.000 | wall 2233 | train_wall 2062\n",
            "| epoch 010 | valid on 'valid' subset | loss 4.890 | ppl 29.65 | num_updates 11020 | best_loss 4.73924\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_last.pt (epoch 10 @ 11020 updates) (writing took 2.1311306953430176 seconds)\n",
            "| epoch 011 | loss 2.906 | ppl 7.49 | wps 4125 | ups 5 | wpb 786.132 | bsz 63.960 | num_updates 12122 | lr 0.001 | gnorm 0.885 | clip 0.000 | oom 0.000 | wall 2456 | train_wall 2269\n",
            "| epoch 011 | valid on 'valid' subset | loss 4.990 | ppl 31.78 | num_updates 12122 | best_loss 4.73924\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_last.pt (epoch 11 @ 12122 updates) (writing took 2.0893561840057373 seconds)\n",
            "| epoch 012 | loss 2.797 | ppl 6.95 | wps 4125 | ups 5 | wpb 786.132 | bsz 63.960 | num_updates 13224 | lr 0.001 | gnorm 0.878 | clip 0.000 | oom 0.000 | wall 2680 | train_wall 2476\n",
            "| epoch 012 | valid on 'valid' subset | loss 4.963 | ppl 31.19 | num_updates 13224 | best_loss 4.73924\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_last.pt (epoch 12 @ 13224 updates) (writing took 2.0324859619140625 seconds)\n",
            "| epoch 013 | loss 2.700 | ppl 6.5 | wps 4128 | ups 5 | wpb 786.132 | bsz 63.960 | num_updates 14326 | lr 0.001 | gnorm 0.875 | clip 0.000 | oom 0.000 | wall 2903 | train_wall 2682\n",
            "| epoch 013 | valid on 'valid' subset | loss 5.045 | ppl 33.02 | num_updates 14326 | best_loss 4.73924\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_last.pt (epoch 13 @ 14326 updates) (writing took 2.014249324798584 seconds)\n",
            "| epoch 014 | loss 2.607 | ppl 6.09 | wps 4128 | ups 5 | wpb 786.132 | bsz 63.960 | num_updates 15428 | lr 0.001 | gnorm 0.870 | clip 0.000 | oom 0.000 | wall 3126 | train_wall 2889\n",
            "| epoch 014 | valid on 'valid' subset | loss 5.260 | ppl 38.33 | num_updates 15428 | best_loss 4.73924\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_last.pt (epoch 14 @ 15428 updates) (writing took 2.021806240081787 seconds)\n",
            "| epoch 015 | loss 2.532 | ppl 5.78 | wps 4129 | ups 5 | wpb 786.132 | bsz 63.960 | num_updates 16530 | lr 0.001 | gnorm 0.871 | clip 0.000 | oom 0.000 | wall 3349 | train_wall 3096\n",
            "| epoch 015 | valid on 'valid' subset | loss 5.110 | ppl 34.54 | num_updates 16530 | best_loss 4.73924\n",
            "| saved checkpoint checkpoints/lstm/checkpoint_last.pt (epoch 15 @ 16530 updates) (writing took 2.3795547485351562 seconds)\n",
            "| done training in 3361.3 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLdpT2pXMpq8",
        "colab_type": "code",
        "outputId": "cb5c7ed7-6e7c-47b8-c0de-3e9e0d9ab3ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!fairseq-generate preprocessed_data \\\n",
        "    --path checkpoints/lstm/checkpoint_best.pt \\\n",
        "    --batch-size 64 --beam 3 > lstm.out"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1% 1/186 [00:01<03:09,  1.02s/it, wps=581]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [9] is 9 which does not match the computed number of elements 10. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (10,).\n",
            "  1% 2/186 [00:01<02:35,  1.18it/s, wps=897]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [10] is 10 which does not match the computed number of elements 11. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (11,).\n",
            "  2% 4/186 [00:02<01:43,  1.76it/s, wps=1274]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [11] is 11 which does not match the computed number of elements 12. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (12,).\n",
            "  3% 5/186 [00:02<01:30,  2.01it/s, wps=1367]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [12] is 12 which does not match the computed number of elements 13. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (13,).\n",
            "  4% 7/186 [00:03<01:14,  2.39it/s, wps=1520]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [13] is 13 which does not match the computed number of elements 14. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (14,).\n",
            "  5% 10/186 [00:04<01:05,  2.69it/s, wps=1643]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [14] is 14 which does not match the computed number of elements 15. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (15,).\n",
            "  7% 13/186 [00:05<01:03,  2.74it/s, wps=1695]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [15] is 15 which does not match the computed number of elements 16. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (16,).\n",
            "  9% 17/186 [00:06<01:02,  2.70it/s, wps=1737]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [16] is 16 which does not match the computed number of elements 17. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (17,).\n",
            " 11% 21/186 [00:08<01:03,  2.59it/s, wps=1760]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [17] is 17 which does not match the computed number of elements 18. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (18,).\n",
            " 13% 25/186 [00:09<01:02,  2.57it/s, wps=1776]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [18] is 18 which does not match the computed number of elements 19. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (19,).\n",
            " 16% 30/186 [00:11<01:01,  2.53it/s, wps=1781]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [19] is 19 which does not match the computed number of elements 20. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (20,).\n",
            " 18% 34/186 [00:13<01:00,  2.52it/s, wps=1777]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [20] is 20 which does not match the computed number of elements 21. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (21,).\n",
            " 22% 40/186 [00:15<01:01,  2.38it/s, wps=1774]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [21] is 21 which does not match the computed number of elements 22. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (22,).\n",
            " 24% 45/186 [00:17<01:00,  2.35it/s, wps=1765]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [22] is 22 which does not match the computed number of elements 23. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (23,).\n",
            " 27% 51/186 [00:20<01:00,  2.25it/s, wps=1751]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [23] is 23 which does not match the computed number of elements 24. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (24,).\n",
            " 31% 57/186 [00:23<00:59,  2.18it/s, wps=1731]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [24] is 24 which does not match the computed number of elements 25. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (25,).\n",
            " 33% 62/186 [00:25<00:56,  2.19it/s, wps=1716]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [25] is 25 which does not match the computed number of elements 26. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (26,).\n",
            " 37% 69/186 [00:28<00:56,  2.07it/s, wps=1696]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [26] is 26 which does not match the computed number of elements 27. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (27,).\n",
            " 41% 76/186 [00:33<01:10,  1.56it/s, wps=1647]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [27] is 27 which does not match the computed number of elements 28. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (28,).\n",
            " 44% 81/186 [00:35<00:53,  1.98it/s, wps=1635]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [28] is 28 which does not match the computed number of elements 29. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (29,).\n",
            " 47% 87/186 [00:38<00:49,  1.98it/s, wps=1622]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [29] is 29 which does not match the computed number of elements 30. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (30,).\n",
            " 50% 93/186 [00:41<00:48,  1.93it/s, wps=1605]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [30] is 30 which does not match the computed number of elements 31. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (31,).\n",
            " 53% 98/186 [00:44<00:47,  1.85it/s, wps=1583]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [31] is 31 which does not match the computed number of elements 32. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (32,).\n",
            " 55% 102/186 [00:46<00:44,  1.88it/s, wps=1575]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [32] is 32 which does not match the computed number of elements 33. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (33,).\n",
            " 58% 107/186 [00:49<00:41,  1.89it/s, wps=1566]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [33] is 33 which does not match the computed number of elements 34. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (34,).\n",
            " 60% 112/186 [00:52<00:40,  1.82it/s, wps=1555]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [34] is 34 which does not match the computed number of elements 35. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (35,).\n",
            " 63% 117/186 [00:55<00:39,  1.76it/s, wps=1543]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [35] is 35 which does not match the computed number of elements 36. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (36,).\n",
            " 65% 121/186 [00:57<00:37,  1.74it/s, wps=1535]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [36] is 36 which does not match the computed number of elements 37. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (37,).\n",
            " 67% 125/186 [00:59<00:35,  1.72it/s, wps=1524]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [37] is 37 which does not match the computed number of elements 38. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (38,).\n",
            " 70% 130/186 [01:02<00:32,  1.70it/s, wps=1509]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [38] is 38 which does not match the computed number of elements 39. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (39,).\n",
            " 72% 134/186 [01:05<00:31,  1.65it/s, wps=1500]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [39] is 39 which does not match the computed number of elements 40. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (40,).\n",
            " 74% 137/186 [01:06<00:29,  1.66it/s, wps=1492]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [40] is 40 which does not match the computed number of elements 41. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (41,).\n",
            " 75% 140/186 [01:08<00:28,  1.62it/s, wps=1484]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [41] is 41 which does not match the computed number of elements 42. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (42,).\n",
            " 76% 142/186 [01:09<00:27,  1.60it/s, wps=1479]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [42] is 42 which does not match the computed number of elements 43. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (43,).\n",
            " 78% 146/186 [01:12<00:25,  1.56it/s, wps=1470]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [43] is 43 which does not match the computed number of elements 44. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (44,).\n",
            " 80% 148/186 [01:13<00:24,  1.52it/s, wps=1464]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [44] is 44 which does not match the computed number of elements 45. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (45,).\n",
            " 81% 150/186 [01:15<00:23,  1.53it/s, wps=1457]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [45] is 45 which does not match the computed number of elements 46. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (46,).\n",
            " 82% 153/186 [01:17<00:22,  1.49it/s, wps=1447]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [46] is 46 which does not match the computed number of elements 47. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (47,).\n",
            " 84% 156/186 [01:19<00:20,  1.47it/s, wps=1439]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [47] is 47 which does not match the computed number of elements 48. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (48,).\n",
            " 85% 158/186 [01:20<00:19,  1.46it/s, wps=1433]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [48] is 48 which does not match the computed number of elements 49. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (49,).\n",
            " 86% 160/186 [01:22<00:18,  1.44it/s, wps=1427]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [49] is 49 which does not match the computed number of elements 50. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (50,).\n",
            " 87% 162/186 [01:23<00:17,  1.41it/s, wps=1420]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [50] is 50 which does not match the computed number of elements 51. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (51,).\n",
            " 88% 164/186 [01:24<00:15,  1.41it/s, wps=1415]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [51] is 51 which does not match the computed number of elements 52. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (52,).\n",
            " 89% 166/186 [01:26<00:14,  1.39it/s, wps=1408]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [52] is 52 which does not match the computed number of elements 53. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (53,).\n",
            " 90% 167/186 [01:27<00:13,  1.39it/s, wps=1404]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [53] is 53 which does not match the computed number of elements 54. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (54,).\n",
            " 90% 168/186 [01:27<00:12,  1.39it/s, wps=1401]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [54] is 54 which does not match the computed number of elements 55. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (55,).\n",
            " 91% 169/186 [01:28<00:12,  1.36it/s, wps=1397]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [55] is 55 which does not match the computed number of elements 56. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (56,).\n",
            " 92% 171/186 [01:30<00:11,  1.33it/s, wps=1390]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [56] is 56 which does not match the computed number of elements 57. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (57,).\n",
            " 92% 172/186 [01:30<00:10,  1.32it/s, wps=1386]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [57] is 57 which does not match the computed number of elements 58. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (58,).\n",
            " 93% 173/186 [01:31<00:09,  1.30it/s, wps=1382]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [58] is 58 which does not match the computed number of elements 59. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (59,).\n",
            " 94% 174/186 [01:32<00:09,  1.28it/s, wps=1379]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [59] is 59 which does not match the computed number of elements 61. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (61,).\n",
            " 94% 175/186 [01:33<00:08,  1.26it/s, wps=1375]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [61] is 61 which does not match the computed number of elements 62. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (62,).\n",
            " 95% 176/186 [01:34<00:08,  1.25it/s, wps=1371]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [62] is 62 which does not match the computed number of elements 63. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (63,).\n",
            " 95% 177/186 [01:34<00:07,  1.23it/s, wps=1367]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [63] is 63 which does not match the computed number of elements 66. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (66,).\n",
            " 96% 178/186 [01:35<00:06,  1.21it/s, wps=1362]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [66] is 66 which does not match the computed number of elements 68. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (68,).\n",
            " 96% 179/186 [01:36<00:05,  1.19it/s, wps=1357]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [68] is 68 which does not match the computed number of elements 69. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (69,).\n",
            " 97% 180/186 [01:37<00:05,  1.17it/s, wps=1352]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [69] is 69 which does not match the computed number of elements 71. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (71,).\n",
            " 97% 181/186 [01:38<00:04,  1.15it/s, wps=1347]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [71] is 71 which does not match the computed number of elements 74. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (74,).\n",
            " 98% 182/186 [01:39<00:03,  1.13it/s, wps=1342]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [74] is 74 which does not match the computed number of elements 78. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (78,).\n",
            " 98% 183/186 [01:40<00:02,  1.10it/s, wps=1336]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [78] is 78 which does not match the computed number of elements 85. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (85,).\n",
            " 99% 184/186 [01:41<00:01,  1.06it/s, wps=1330]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [85] is 85 which does not match the computed number of elements 110. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (110,).\n",
            " 99% 185/186 [01:42<00:01,  1.00s/it, wps=1322]/pytorch/aten/src/ATen/native/RangeFactories.cpp:170: UserWarning: The number of elements in the out tensor of shape [110] is 110 which does not match the computed number of elements 138. Note that this may occur as a result of rounding error. The out tensor will be resized to a tensor of shape (138,).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0epZNcSNtIM",
        "colab_type": "code",
        "outputId": "817bd775-0617-491e-d13c-6853c799cd5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!grep ^H lstm.out | cut -f3- > lstm.out.sys\n",
        "!grep ^T lstm.out | cut -f2- > lstm.out.ref\n",
        "!fairseq-score --sys lstm.out.sys --ref lstm.out.ref"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(ignore_case=False, order=4, ref='lstm.out.ref', sacrebleu=False, sentence_bleu=False, sys='lstm.out.sys')\n",
            "BLEU4 = 7.86, 37.8/11.1/5.3/2.7 (BP=0.896, ratio=0.901, syslen=124238, reflen=137927)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YbN9QWBkx0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head gen.out.sys \n",
        "print('---------')\n",
        "!head gen.out.ref"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rju5xKia7uNZ",
        "colab_type": "text"
      },
      "source": [
        "### BaseLine LSTM with Sentence Filtered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZKE2N8-_SPD",
        "colab_type": "text"
      },
      "source": [
        "#### Filtering the Squad Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X-BMaGjatfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.lang.en import English\n",
        "\n",
        "nlp_sentence = English()\n",
        "nlp_sentence.add_pipe(nlp_sentence.create_pipe(\"sentencizer\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6DkIIsY_alc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_filtered_sentences(questionanswers, para):\n",
        "    \"\"\"\n",
        "    Method returns filtered sentences from the answers and para for SQUAD\n",
        "    \"\"\"\n",
        "    tokenized_paragraph = nlp_sentence(para)\n",
        "    sentences = [sent.string for sent in tokenized_paragraph.sents]\n",
        "\n",
        "    filtered_sentences = set()\n",
        "\n",
        "    # This iterates over every answer in question\n",
        "    for answer in questionanswers[\"answers\"]:\n",
        "        answer_index = answer[\"answer_start\"]\n",
        "        length = 0\n",
        "\n",
        "        # find sentence that has answer and filter them\n",
        "        for sentence in sentences:\n",
        "            if answer_index <= length + len(sentence):\n",
        "                filtered_sentences.add(sentence.replace(\"\\n\", \" \").strip())\n",
        "                break\n",
        "            length += len(sentence)\n",
        "\n",
        "        if not filtered_sentences:\n",
        "            print(\"Length : {}\".format(length))\n",
        "            raise Exception(\"One of the Answers had no sentence please check the data\")\n",
        "\n",
        "    return \" \".join(filtered_sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rjggDEU_-Tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_sentences_on_answer(dataset, dataset_type=\"train\", get_impossible=False):\n",
        "    \"\"\"\n",
        "    Filter the paragraph with only sentences relevant to answer and generates files\n",
        "    with sentences and questions instead of paragraphs and questions\n",
        "    Input:\n",
        "    dataset: string\n",
        "    dataset_type: string\n",
        "    get_impossible: boolean\n",
        "    \"\"\"\n",
        "\n",
        "    para_output = open(dataset_type + '.paragraphs', 'w')\n",
        "    question_output = open(dataset_type + '.questions', 'w')\n",
        "\n",
        "    dataset_size = 0\n",
        "\n",
        "    logger.debug(\"Starting to filter sentences on answer\")\n",
        "\n",
        "    # This loops iterates over every paragraph\n",
        "    for paragraphs in tqdm(dataset):\n",
        "        paragraphs = paragraphs[\"paragraphs\"]\n",
        "        for i, paragraph in enumerate(paragraphs):\n",
        "            para = paragraph[\"context\"]\n",
        "            # This loop iterates over every question in para\n",
        "            for questionanswers in paragraph[\"qas\"]:\n",
        "                if questionanswers[\"is_impossible\"]:\n",
        "                    continue\n",
        "                question = questionanswers[\"question\"]\n",
        "\n",
        "                filtered_sentences = extract_filtered_sentences(questionanswers, para)\n",
        "\n",
        "                para_output.write(filtered_sentences.strip().lower() + \"\\n\")\n",
        "                question_output.write(question.strip().lower() + \"\\n\")\n",
        "\n",
        "                dataset_size += 1\n",
        "\n",
        "    logger.info(\"Size of the {} dataset: {}\".format(dataset_type, dataset_size))\n",
        "    para_output.close()\n",
        "    question_output.close()\n",
        "\n",
        "    logger.debug(\"Sentences Filtered on Answers\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqfLaOGFA7cU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter_sentences_on_answer(train_data, 'train')\n",
        "filter_sentences_on_answer(test_data, 'test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNuNf4zbBGBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split_train_valid()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx994m7XfqZ5",
        "colab_type": "text"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s42EMgO_B0LA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "!unzip glove.840B.300d.zip\n",
        "!rm -rf checkpoints"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr2-BjtfoQQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r05mZ-JTPcnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!fairseq-preprocess --source-lang paragraphs --target-lang questions \\\n",
        "     --trainpref train --testpref test --validpref valid\\\n",
        "     --destdir preprocessed_data --nwordssrc 45000 --nwordstgt 28000\n",
        "\n",
        "#--nwordssrc 45000 --nwordstgt 28000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STuKi7PuCQdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 fairseq-train preprocessed_data/ \\\n",
        "     --clip-norm 5 --batch-size 64 \\\n",
        "     --arch lstm --max-epoch 15 --encoder-hidden-size 600 --encoder-layers 2 \\\n",
        "     --decoder-hidden-size 600 --decoder-layers 2 --optimizer sgd  --dropout 0.3 --encoder-embed-path glove.840B.300d.txt \\\n",
        "     --encoder-bidirectional --encoder-embed-dim 300 --decoder-embed-dim 300 --no-epoch-checkpoints --decoder-embed-path glove.840B.300d.txt --decoder-out-embed-dim 300 --num-workers 3 \\\n",
        "     --lr 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.5,0.25,0.125,0.0625,0.03125,0.015625,0.0078125"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oikuYprLCRmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!fairseq-generate preprocessed_data \\\n",
        "    --path checkpoints/checkpoint_best.pt \\\n",
        "    --batch-size 64 --beam 3 | tee gen.out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4tNIil8CXrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!grep ^H gen.out | cut -f3- > gen.out.sys\n",
        "!grep ^T gen.out | cut -f2- > gen.out.ref\n",
        "!fairseq-score --sys gen.out.sys --ref gen.out.ref"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN1pyAYLCX-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head -n 100 gen.out.sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_kwuYzobwmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz3z_jTZf0Tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}